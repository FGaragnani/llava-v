Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
[2025-12-09 09:54:31,804] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-12-09 09:54:31,804] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-12-09 09:54:31,804] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-12-09 09:54:31,804] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-12-09 09:54:37,667] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-12-09 09:54:37,667] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-12-09 09:54:37,667] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-12-09 09:54:37,667] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-12-09 09:54:37,667] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-12-09 09:54:48,083] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B
Enabled ddp_find_unused_parameters=True to prevent hangs on unused grads.
[2025-12-09 09:55:10,110] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 682, num_elems = 7.04B
Formatting inputs...Skip in lazy mode
[2025-12-09 09:55:37,797] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 905, num_elems = 7.13B
PatchEmbedder device: cuda
[2025-12-09 09:55:52,922] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown
[2025-12-09 09:55:52,969] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-12-09 09:55:52,971] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-12-09 09:55:52,971] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-12-09 09:55:52,986] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-12-09 09:55:52,986] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-12-09 09:55:52,986] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2025-12-09 09:55:52,986] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2025-12-09 09:55:54,100] [INFO] [utils.py:791:see_memory_usage] Stage 3 initialize beginning
[2025-12-09 09:55:54,101] [INFO] [utils.py:792:see_memory_usage] MA 3.42 GB         Max_MA 3.7 GB         CA 3.62 GB         Max_CA 4 GB 
[2025-12-09 09:55:54,101] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.17 GB, percent = 6.4%
[2025-12-09 09:55:54,103] [INFO] [stage3.py:127:__init__] Reduce bucket size 16777216
[2025-12-09 09:55:54,103] [INFO] [stage3.py:128:__init__] Prefetch bucket size 15099494
[2025-12-09 09:55:55,208] [INFO] [utils.py:791:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-12-09 09:55:55,208] [INFO] [utils.py:792:see_memory_usage] MA 3.42 GB         Max_MA 3.42 GB         CA 3.62 GB         Max_CA 4 GB 
[2025-12-09 09:55:55,208] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.17 GB, percent = 6.4%
Parameter Offload: Total persistent parameters: 599040 in 312 params
[2025-12-09 09:55:56,354] [INFO] [utils.py:791:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-12-09 09:55:56,355] [INFO] [utils.py:792:see_memory_usage] MA 3.43 GB         Max_MA 3.46 GB         CA 3.65 GB         Max_CA 4 GB 
[2025-12-09 09:55:56,355] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.18 GB, percent = 6.4%
[2025-12-09 09:55:57,458] [INFO] [utils.py:791:see_memory_usage] Before creating fp16 partitions
[2025-12-09 09:55:57,459] [INFO] [utils.py:792:see_memory_usage] MA 3.43 GB         Max_MA 3.43 GB         CA 3.65 GB         Max_CA 4 GB 
[2025-12-09 09:55:57,459] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.18 GB, percent = 6.4%
[2025-12-09 09:56:01,924] [INFO] [utils.py:791:see_memory_usage] After creating fp16 partitions: 3
[2025-12-09 09:56:01,924] [INFO] [utils.py:792:see_memory_usage] MA 3.42 GB         Max_MA 3.43 GB         CA 6.28 GB         Max_CA 6 GB 
[2025-12-09 09:56:01,924] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.18 GB, percent = 6.4%
[2025-12-09 09:56:03,028] [INFO] [utils.py:791:see_memory_usage] Before creating fp32 partitions
[2025-12-09 09:56:03,029] [INFO] [utils.py:792:see_memory_usage] MA 3.42 GB         Max_MA 3.42 GB         CA 6.28 GB         Max_CA 6 GB 
[2025-12-09 09:56:03,029] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.18 GB, percent = 6.4%
[2025-12-09 09:56:04,134] [INFO] [utils.py:791:see_memory_usage] After creating fp32 partitions
[2025-12-09 09:56:04,135] [INFO] [utils.py:792:see_memory_usage] MA 9.72 GB         Max_MA 11.0 GB         CA 14.44 GB         Max_CA 14 GB 
[2025-12-09 09:56:04,135] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.18 GB, percent = 6.4%
[2025-12-09 09:56:05,245] [INFO] [utils.py:791:see_memory_usage] Before initializing optimizer states
[2025-12-09 09:56:05,246] [INFO] [utils.py:792:see_memory_usage] MA 9.72 GB         Max_MA 9.72 GB         CA 14.44 GB         Max_CA 14 GB 
[2025-12-09 09:56:05,246] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.19 GB, percent = 6.4%
[2025-12-09 09:56:06,403] [INFO] [utils.py:791:see_memory_usage] After initializing optimizer states
[2025-12-09 09:56:06,403] [INFO] [utils.py:792:see_memory_usage] MA 22.31 GB         Max_MA 28.6 GB         CA 34.5 GB         Max_CA 34 GB 
[2025-12-09 09:56:06,403] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.19 GB, percent = 6.4%
[2025-12-09 09:56:06,403] [INFO] [stage3.py:479:_setup_for_real_optimizer] optimizer state initialized
[2025-12-09 09:56:07,591] [INFO] [utils.py:791:see_memory_usage] After initializing ZeRO optimizer
[2025-12-09 09:56:07,591] [INFO] [utils.py:792:see_memory_usage] MA 25.48 GB         Max_MA 25.97 GB         CA 34.5 GB         Max_CA 34 GB 
[2025-12-09 09:56:07,592] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 32.19 GB, percent = 6.4%
[2025-12-09 09:56:07,592] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2025-12-09 09:56:07,592] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2025-12-09 09:56:07,592] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-12-09 09:56:07,592] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]
[2025-12-09 09:56:07,593] [INFO] [config.py:984:print] DeepSpeedEngine configuration:
[2025-12-09 09:56:07,593] [INFO] [config.py:988:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-12-09 09:56:07,593] [INFO] [config.py:988:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2025-12-09 09:56:07,593] [INFO] [config.py:988:print]   amp_enabled .................. False
[2025-12-09 09:56:07,593] [INFO] [config.py:988:print]   amp_params ................... False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   bfloat16_enabled ............. True
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   checkpoint_parallel_write_pipeline  False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   checkpoint_tag_validation_enabled  True
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   checkpoint_tag_validation_fail  False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x14e4156b9780>
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   communication_data_type ...... None
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   curriculum_enabled_legacy .... False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   curriculum_params_legacy ..... False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   data_efficiency_enabled ...... False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   dataloader_drop_last ......... False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   disable_allgather ............ False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   dump_state ................... False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   dynamic_loss_scale_args ...... None
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   eigenvalue_enabled ........... False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   eigenvalue_gas_boundary_resolution  1
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   eigenvalue_layer_num ......... 0
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   eigenvalue_max_iter .......... 100
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   eigenvalue_stability ......... 1e-06
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   eigenvalue_tol ............... 0.01
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   eigenvalue_verbose ........... False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   elasticity_enabled ........... False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   fp16_auto_cast ............... None
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   fp16_enabled ................. False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   fp16_master_weights_and_gradients  False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   global_rank .................. 0
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   grad_accum_dtype ............. None
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   gradient_accumulation_steps .. 2
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   gradient_clipping ............ 0.0
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   gradient_predivide_factor .... 1.0
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   graph_harvesting ............. False
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-12-09 09:56:07,594] [INFO] [config.py:988:print]   initial_dynamic_scale ........ 1
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   load_universal_checkpoint .... False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   loss_scale ................... 1.0
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   memory_breakdown ............. False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   mics_hierarchial_params_gather  False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   mics_shard_size .............. -1
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   optimizer_legacy_fusion ...... False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   optimizer_name ............... None
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   optimizer_params ............. None
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   pld_enabled .................. False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   pld_params ................... False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   prescale_gradients ........... False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   scheduler_name ............... None
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   scheduler_params ............. None
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   seq_parallel_communication_data_type  torch.float32
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   sparse_attention ............. None
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   sparse_gradients_enabled ..... False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   steps_per_print .............. inf
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   train_batch_size ............. 32
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   train_micro_batch_size_per_gpu  4
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   use_data_before_expert_parallel_  False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   use_node_local_storage ....... False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   wall_clock_breakdown ......... False
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   weight_quantization_config ... None
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   world_size ................... 4
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   zero_allow_untested_optimizer  True
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=16777216 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=15099494 param_persistence_threshold=40960 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   zero_enabled ................. True
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   zero_force_ds_cpu_optimizer .. True
[2025-12-09 09:56:07,595] [INFO] [config.py:988:print]   zero_optimization_stage ...... 3
[2025-12-09 09:56:07,595] [INFO] [config.py:974:print_user_config]   json = {
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "loss_scale_window": 1000, 
        "initial_scale_power": 16, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "bf16": {
        "enabled": true
    }, 
    "train_micro_batch_size_per_gpu": 4, 
    "train_batch_size": 32, 
    "gradient_accumulation_steps": 2, 
    "zero_optimization": {
        "stage": 3, 
        "overlap_comm": true, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09, 
        "reduce_bucket_size": 1.677722e+07, 
        "stage3_prefetch_bucket_size": 1.509949e+07, 
        "stage3_param_persistence_threshold": 4.096000e+04, 
        "stage3_max_live_parameters": 1.000000e+09, 
        "stage3_max_reuse_distance": 1.000000e+09, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "steps_per_print": inf, 
    "zero_allow_untested_optimizer": true
}
{'loss': 1.3368, 'learning_rate': 1.6025641025641025e-07, 'epoch': 0.0}
{'loss': 1.4121, 'learning_rate': 3.205128205128205e-07, 'epoch': 0.0}
{'loss': 1.389, 'learning_rate': 4.807692307692308e-07, 'epoch': 0.0}
{'loss': 1.1092, 'learning_rate': 6.41025641025641e-07, 'epoch': 0.0}
{'loss': 1.2778, 'learning_rate': 8.012820512820515e-07, 'epoch': 0.0}
{'loss': 1.2432, 'learning_rate': 9.615384615384617e-07, 'epoch': 0.0}
{'loss': 1.0079, 'learning_rate': 1.121794871794872e-06, 'epoch': 0.0}
{'loss': 1.0067, 'learning_rate': 1.282051282051282e-06, 'epoch': 0.0}
{'loss': 1.1347, 'learning_rate': 1.4423076923076922e-06, 'epoch': 0.0}
{'loss': 1.0963, 'learning_rate': 1.602564102564103e-06, 'epoch': 0.0}
{'loss': 1.0997, 'learning_rate': 1.7628205128205131e-06, 'epoch': 0.0}
{'loss': 0.9088, 'learning_rate': 1.9230769230769234e-06, 'epoch': 0.0}
{'loss': 1.1069, 'learning_rate': 2.0833333333333334e-06, 'epoch': 0.0}
{'loss': 1.0489, 'learning_rate': 2.243589743589744e-06, 'epoch': 0.0}
{'loss': 1.0412, 'learning_rate': 2.403846153846154e-06, 'epoch': 0.0}
{'loss': 1.0347, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.0}
{'loss': 0.9072, 'learning_rate': 2.7243589743589744e-06, 'epoch': 0.0}
{'loss': 0.8749, 'learning_rate': 2.8846153846153845e-06, 'epoch': 0.0}
{'loss': 0.9689, 'learning_rate': 3.044871794871795e-06, 'epoch': 0.0}
{'loss': 1.0224, 'learning_rate': 3.205128205128206e-06, 'epoch': 0.0}
{'loss': 0.9716, 'learning_rate': 3.365384615384616e-06, 'epoch': 0.01}
{'loss': 1.0153, 'learning_rate': 3.5256410256410263e-06, 'epoch': 0.01}
{'loss': 0.945, 'learning_rate': 3.6858974358974363e-06, 'epoch': 0.01}
{'loss': 0.83, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.01}
{'loss': 0.8253, 'learning_rate': 4.006410256410257e-06, 'epoch': 0.01}
{'loss': 1.0111, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.01}
{'loss': 0.9294, 'learning_rate': 4.326923076923077e-06, 'epoch': 0.01}
{'loss': 0.917, 'learning_rate': 4.487179487179488e-06, 'epoch': 0.01}
{'loss': 0.8515, 'learning_rate': 4.647435897435898e-06, 'epoch': 0.01}
{'loss': 0.979, 'learning_rate': 4.807692307692308e-06, 'epoch': 0.01}
{'loss': 0.9759, 'learning_rate': 4.967948717948718e-06, 'epoch': 0.01}
{'loss': 0.811, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.01}
{'loss': 0.8587, 'learning_rate': 5.288461538461539e-06, 'epoch': 0.01}
{'loss': 0.9645, 'learning_rate': 5.448717948717949e-06, 'epoch': 0.01}
{'loss': 0.8559, 'learning_rate': 5.608974358974359e-06, 'epoch': 0.01}
{'loss': 0.6578, 'learning_rate': 5.769230769230769e-06, 'epoch': 0.01}
{'loss': 0.898, 'learning_rate': 5.92948717948718e-06, 'epoch': 0.01}
{'loss': 0.9884, 'learning_rate': 6.08974358974359e-06, 'epoch': 0.01}
{'loss': 0.9528, 'learning_rate': 6.25e-06, 'epoch': 0.01}
{'loss': 0.9431, 'learning_rate': 6.410256410256412e-06, 'epoch': 0.01}
{'loss': 1.0185, 'learning_rate': 6.570512820512821e-06, 'epoch': 0.01}
{'loss': 0.9326, 'learning_rate': 6.730769230769232e-06, 'epoch': 0.01}
{'loss': 0.9842, 'learning_rate': 6.891025641025641e-06, 'epoch': 0.01}
{'loss': 0.9268, 'learning_rate': 7.051282051282053e-06, 'epoch': 0.01}
{'loss': 0.8658, 'learning_rate': 7.211538461538462e-06, 'epoch': 0.01}
{'loss': 0.9416, 'learning_rate': 7.371794871794873e-06, 'epoch': 0.01}
{'loss': 0.9004, 'learning_rate': 7.532051282051282e-06, 'epoch': 0.01}
{'loss': 0.9326, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.01}
{'loss': 0.9961, 'learning_rate': 7.852564102564102e-06, 'epoch': 0.01}
{'loss': 0.8226, 'learning_rate': 8.012820512820515e-06, 'epoch': 0.01}
{'loss': 0.9586, 'learning_rate': 8.173076923076923e-06, 'epoch': 0.01}
{'loss': 0.8533, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.01}
{'loss': 0.9752, 'learning_rate': 8.493589743589744e-06, 'epoch': 0.01}
{'loss': 0.8086, 'learning_rate': 8.653846153846155e-06, 'epoch': 0.01}
{'loss': 0.9838, 'learning_rate': 8.814102564102565e-06, 'epoch': 0.01}
{'loss': 0.9849, 'learning_rate': 8.974358974358976e-06, 'epoch': 0.01}
{'loss': 0.9321, 'learning_rate': 9.134615384615384e-06, 'epoch': 0.01}
{'loss': 0.8499, 'learning_rate': 9.294871794871796e-06, 'epoch': 0.01}
{'loss': 0.8031, 'learning_rate': 9.455128205128205e-06, 'epoch': 0.01}
{'loss': 0.9748, 'learning_rate': 9.615384615384616e-06, 'epoch': 0.01}
{'loss': 0.8912, 'learning_rate': 9.775641025641026e-06, 'epoch': 0.01}
{'loss': 0.9423, 'learning_rate': 9.935897435897437e-06, 'epoch': 0.01}
{'loss': 0.9114, 'learning_rate': 1.0096153846153847e-05, 'epoch': 0.02}
{'loss': 0.8858, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.02}
{'loss': 0.9729, 'learning_rate': 1.0416666666666668e-05, 'epoch': 0.02}
{'loss': 0.9951, 'learning_rate': 1.0576923076923078e-05, 'epoch': 0.02}
{'loss': 0.9478, 'learning_rate': 1.0737179487179487e-05, 'epoch': 0.02}
{'loss': 0.9477, 'learning_rate': 1.0897435897435898e-05, 'epoch': 0.02}
{'loss': 0.9395, 'learning_rate': 1.105769230769231e-05, 'epoch': 0.02}
{'loss': 0.9918, 'learning_rate': 1.1217948717948719e-05, 'epoch': 0.02}
{'loss': 0.8136, 'learning_rate': 1.1378205128205129e-05, 'epoch': 0.02}
{'loss': 0.8163, 'learning_rate': 1.1538461538461538e-05, 'epoch': 0.02}
{'loss': 0.8087, 'learning_rate': 1.169871794871795e-05, 'epoch': 0.02}
{'loss': 0.9562, 'learning_rate': 1.185897435897436e-05, 'epoch': 0.02}
{'loss': 0.8793, 'learning_rate': 1.201923076923077e-05, 'epoch': 0.02}
{'loss': 0.9552, 'learning_rate': 1.217948717948718e-05, 'epoch': 0.02}
{'loss': 0.9527, 'learning_rate': 1.2339743589743592e-05, 'epoch': 0.02}
{'loss': 0.7902, 'learning_rate': 1.25e-05, 'epoch': 0.02}
{'loss': 0.9358, 'learning_rate': 1.2660256410256411e-05, 'epoch': 0.02}
{'loss': 0.9569, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.02}
{'loss': 0.9449, 'learning_rate': 1.2980769230769232e-05, 'epoch': 0.02}
{'loss': 0.9619, 'learning_rate': 1.3141025641025642e-05, 'epoch': 0.02}
{'loss': 0.9572, 'learning_rate': 1.3301282051282051e-05, 'epoch': 0.02}
{'loss': 0.9738, 'learning_rate': 1.3461538461538463e-05, 'epoch': 0.02}
{'loss': 0.9661, 'learning_rate': 1.3621794871794874e-05, 'epoch': 0.02}
{'loss': 0.9838, 'learning_rate': 1.3782051282051283e-05, 'epoch': 0.02}
{'loss': 0.9346, 'learning_rate': 1.3942307692307693e-05, 'epoch': 0.02}
{'loss': 0.9992, 'learning_rate': 1.4102564102564105e-05, 'epoch': 0.02}
{'loss': 0.9946, 'learning_rate': 1.4262820512820514e-05, 'epoch': 0.02}
{'loss': 0.9558, 'learning_rate': 1.4423076923076924e-05, 'epoch': 0.02}
{'loss': 0.8518, 'learning_rate': 1.4583333333333333e-05, 'epoch': 0.02}
{'loss': 0.8974, 'learning_rate': 1.4743589743589745e-05, 'epoch': 0.02}
{'loss': 0.992, 'learning_rate': 1.4903846153846156e-05, 'epoch': 0.02}
{'loss': 0.9162, 'learning_rate': 1.5064102564102565e-05, 'epoch': 0.02}
{'loss': 0.9766, 'learning_rate': 1.5224358974358975e-05, 'epoch': 0.02}
{'loss': 0.9374, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.02}
{'loss': 0.945, 'learning_rate': 1.5544871794871796e-05, 'epoch': 0.02}
{'loss': 0.9376, 'learning_rate': 1.5705128205128205e-05, 'epoch': 0.02}
{'loss': 0.9811, 'learning_rate': 1.5865384615384617e-05, 'epoch': 0.02}
{'loss': 0.9199, 'learning_rate': 1.602564102564103e-05, 'epoch': 0.02}
[2025-12-09 10:21:01,387] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step500 is about to be saved!
[2025-12-09 10:21:01,420] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 10:21:01,420] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 10:21:01,611] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 10:21:01,734] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 10:21:35,448] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 10:21:35,451] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 10:21:38,271] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
{'loss': 0.9257, 'learning_rate': 1.6185897435897438e-05, 'epoch': 0.02}
{'loss': 0.9237, 'learning_rate': 1.6346153846153847e-05, 'epoch': 0.02}
{'loss': 0.9149, 'learning_rate': 1.6506410256410255e-05, 'epoch': 0.02}
{'loss': 1.0049, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.03}
{'loss': 0.9977, 'learning_rate': 1.682692307692308e-05, 'epoch': 0.03}
{'loss': 0.8422, 'learning_rate': 1.698717948717949e-05, 'epoch': 0.03}
{'loss': 0.9086, 'learning_rate': 1.7147435897435897e-05, 'epoch': 0.03}
{'loss': 0.8547, 'learning_rate': 1.730769230769231e-05, 'epoch': 0.03}
{'loss': 0.9822, 'learning_rate': 1.7467948717948718e-05, 'epoch': 0.03}
{'loss': 0.9345, 'learning_rate': 1.762820512820513e-05, 'epoch': 0.03}
{'loss': 0.97, 'learning_rate': 1.778846153846154e-05, 'epoch': 0.03}
{'loss': 0.9157, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.03}
{'loss': 0.8337, 'learning_rate': 1.810897435897436e-05, 'epoch': 0.03}
{'loss': 0.8903, 'learning_rate': 1.826923076923077e-05, 'epoch': 0.03}
{'loss': 0.9583, 'learning_rate': 1.842948717948718e-05, 'epoch': 0.03}
{'loss': 1.0091, 'learning_rate': 1.8589743589743593e-05, 'epoch': 0.03}
{'loss': 0.9686, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.03}
{'loss': 0.8702, 'learning_rate': 1.891025641025641e-05, 'epoch': 0.03}
{'loss': 1.0053, 'learning_rate': 1.9070512820512823e-05, 'epoch': 0.03}
{'loss': 0.8663, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.03}
{'loss': 0.9475, 'learning_rate': 1.9391025641025644e-05, 'epoch': 0.03}
{'loss': 0.8501, 'learning_rate': 1.9551282051282052e-05, 'epoch': 0.03}
{'loss': 0.9154, 'learning_rate': 1.9711538461538465e-05, 'epoch': 0.03}
{'loss': 0.9027, 'learning_rate': 1.9871794871794873e-05, 'epoch': 0.03}
{'loss': 0.9365, 'learning_rate': 1.9999999878664707e-05, 'epoch': 0.03}
{'loss': 0.9773, 'learning_rate': 1.999999563192967e-05, 'epoch': 0.03}
{'loss': 0.7739, 'learning_rate': 1.9999985318432804e-05, 'epoch': 0.03}
{'loss': 0.9157, 'learning_rate': 1.9999968938180364e-05, 'epoch': 0.03}
{'loss': 1.0211, 'learning_rate': 1.9999946491182284e-05, 'epoch': 0.03}
{'loss': 0.9404, 'learning_rate': 1.9999917977452187e-05, 'epoch': 0.03}
{'loss': 0.8401, 'learning_rate': 1.9999883397007366e-05, 'epoch': 0.03}
{'loss': 0.932, 'learning_rate': 1.9999842749868808e-05, 'epoch': 0.03}
{'loss': 0.9715, 'learning_rate': 1.9999796036061164e-05, 'epoch': 0.03}
{'loss': 1.0042, 'learning_rate': 1.999974325561278e-05, 'epoch': 0.03}
{'loss': 0.9751, 'learning_rate': 1.9999684408555673e-05, 'epoch': 0.03}
{'loss': 0.9971, 'learning_rate': 1.999961949492555e-05, 'epoch': 0.03}
{'loss': 0.9112, 'learning_rate': 1.9999548514761785e-05, 'epoch': 0.03}
{'loss': 0.9624, 'learning_rate': 1.9999471468107444e-05, 'epoch': 0.03}
{'loss': 0.8303, 'learning_rate': 1.9999388355009266e-05, 'epoch': 0.03}
{'loss': 0.9103, 'learning_rate': 1.999929917551768e-05, 'epoch': 0.03}
{'loss': 1.0372, 'learning_rate': 1.9999203929686786e-05, 'epoch': 0.03}
{'loss': 0.99, 'learning_rate': 1.9999102617574366e-05, 'epoch': 0.03}
{'loss': 0.807, 'learning_rate': 1.9998995239241883e-05, 'epoch': 0.03}
{'loss': 0.9432, 'learning_rate': 1.9998881794754484e-05, 'epoch': 0.03}
{'loss': 0.8137, 'learning_rate': 1.9998762284180996e-05, 'epoch': 0.03}
{'loss': 0.9231, 'learning_rate': 1.9998636707593913e-05, 'epoch': 0.04}
{'loss': 0.9839, 'learning_rate': 1.999850506506943e-05, 'epoch': 0.04}
{'loss': 0.9981, 'learning_rate': 1.9998367356687405e-05, 'epoch': 0.04}
{'loss': 0.9191, 'learning_rate': 1.9998223582531386e-05, 'epoch': 0.04}
{'loss': 0.9258, 'learning_rate': 1.9998073742688592e-05, 'epoch': 0.04}
{'loss': 0.9656, 'learning_rate': 1.999791783724993e-05, 'epoch': 0.04}
{'loss': 0.9684, 'learning_rate': 1.9997755866309988e-05, 'epoch': 0.04}
{'loss': 0.8515, 'learning_rate': 1.9997587829967027e-05, 'epoch': 0.04}
{'loss': 0.9653, 'learning_rate': 1.9997413728322992e-05, 'epoch': 0.04}
{'loss': 0.8124, 'learning_rate': 1.9997233561483503e-05, 'epoch': 0.04}
{'loss': 0.9186, 'learning_rate': 1.9997047329557867e-05, 'epoch': 0.04}
{'loss': 0.9158, 'learning_rate': 1.9996855032659065e-05, 'epoch': 0.04}
{'loss': 0.9466, 'learning_rate': 1.9996656670903753e-05, 'epoch': 0.04}
{'loss': 0.9638, 'learning_rate': 1.9996452244412285e-05, 'epoch': 0.04}
{'loss': 0.8838, 'learning_rate': 1.9996241753308673e-05, 'epoch': 0.04}
{'loss': 0.8389, 'learning_rate': 1.9996025197720615e-05, 'epoch': 0.04}
{'loss': 0.8368, 'learning_rate': 1.9995802577779498e-05, 'epoch': 0.04}
{'loss': 0.9682, 'learning_rate': 1.999557389362037e-05, 'epoch': 0.04}
{'loss': 0.8037, 'learning_rate': 1.9995339145381982e-05, 'epoch': 0.04}
{'loss': 0.994, 'learning_rate': 1.999509833320674e-05, 'epoch': 0.04}
{'loss': 0.9167, 'learning_rate': 1.999485145724074e-05, 'epoch': 0.04}
{'loss': 0.9714, 'learning_rate': 1.999459851763376e-05, 'epoch': 0.04}
{'loss': 0.8872, 'learning_rate': 1.999433951453925e-05, 'epoch': 0.04}
{'loss': 0.9652, 'learning_rate': 1.9994074448114342e-05, 'epoch': 0.04}
{'loss': 0.9365, 'learning_rate': 1.9993803318519845e-05, 'epoch': 0.04}
{'loss': 0.9929, 'learning_rate': 1.9993526125920245e-05, 'epoch': 0.04}
{'loss': 0.939, 'learning_rate': 1.999324287048371e-05, 'epoch': 0.04}
{'loss': 1.0108, 'learning_rate': 1.9992953552382085e-05, 'epoch': 0.04}
{'loss': 0.9431, 'learning_rate': 1.9992658171790893e-05, 'epoch': 0.04}
{'loss': 0.9475, 'learning_rate': 1.9992356728889332e-05, 'epoch': 0.04}
{'loss': 0.8158, 'learning_rate': 1.999204922386028e-05, 'epoch': 0.04}
{'loss': 0.9194, 'learning_rate': 1.9991735656890293e-05, 'epoch': 0.04}
{'loss': 0.9813, 'learning_rate': 1.9991416028169612e-05, 'epoch': 0.04}
{'loss': 0.8773, 'learning_rate': 1.999109033789214e-05, 'epoch': 0.04}
{'loss': 0.9449, 'learning_rate': 1.9990758586255467e-05, 'epoch': 0.04}
{'loss': 0.9255, 'learning_rate': 1.9990420773460864e-05, 'epoch': 0.04}
{'loss': 0.9448, 'learning_rate': 1.9990076899713268e-05, 'epoch': 0.04}
{'loss': 1.0027, 'learning_rate': 1.9989726965221298e-05, 'epoch': 0.04}
{'loss': 0.9729, 'learning_rate': 1.9989370970197257e-05, 'epoch': 0.04}
{'loss': 0.9233, 'learning_rate': 1.9989008914857115e-05, 'epoch': 0.04}
{'loss': 0.8945, 'learning_rate': 1.9988640799420524e-05, 'epoch': 0.04}
{'loss': 0.8683, 'learning_rate': 1.9988266624110813e-05, 'epoch': 0.04}
{'loss': 0.8693, 'learning_rate': 1.998788638915498e-05, 'epoch': 0.05}
{'loss': 0.9686, 'learning_rate': 1.998750009478371e-05, 'epoch': 0.05}
{'loss': 0.841, 'learning_rate': 1.9987107741231352e-05, 'epoch': 0.05}
{'loss': 0.8561, 'learning_rate': 1.9986709328735944e-05, 'epoch': 0.05}
{'loss': 1.003, 'learning_rate': 1.998630485753919e-05, 'epoch': 0.05}
{'loss': 0.9922, 'learning_rate': 1.9985894327886476e-05, 'epoch': 0.05}
{'loss': 0.9849, 'learning_rate': 1.998547774002686e-05, 'epoch': 0.05}
{'loss': 0.9226, 'learning_rate': 1.9985055094213072e-05, 'epoch': 0.05}
{'loss': 0.8729, 'learning_rate': 1.998462639070153e-05, 'epoch': 0.05}
{'loss': 0.9742, 'learning_rate': 1.9984191629752306e-05, 'epoch': 0.05}
{'loss': 0.8762, 'learning_rate': 1.998375081162917e-05, 'epoch': 0.05}
{'loss': 0.9573, 'learning_rate': 1.9983303936599553e-05, 'epoch': 0.05}
{'loss': 0.9562, 'learning_rate': 1.9982851004934557e-05, 'epoch': 0.05}
[2025-12-09 10:46:47,423] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1000 is about to be saved!
[2025-12-09 10:46:47,455] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 10:46:47,455] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 10:46:47,613] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 10:46:47,820] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 10:47:26,314] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 10:47:26,317] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 10:47:32,635] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
{'loss': 0.9707, 'learning_rate': 1.9982392016908975e-05, 'epoch': 0.05}
{'loss': 0.9069, 'learning_rate': 1.9981926972801257e-05, 'epoch': 0.05}
{'loss': 0.9508, 'learning_rate': 1.998145587289354e-05, 'epoch': 0.05}
{'loss': 0.8783, 'learning_rate': 1.998097871747162e-05, 'epoch': 0.05}
{'loss': 0.9502, 'learning_rate': 1.998049550682499e-05, 'epoch': 0.05}
{'loss': 0.8553, 'learning_rate': 1.998000624124679e-05, 'epoch': 0.05}
{'loss': 0.9162, 'learning_rate': 1.997951092103385e-05, 'epoch': 0.05}
{'loss': 0.9867, 'learning_rate': 1.9979009546486675e-05, 'epoch': 0.05}
{'loss': 0.9892, 'learning_rate': 1.997850211790943e-05, 'epoch': 0.05}
{'loss': 0.9845, 'learning_rate': 1.9977988635609957e-05, 'epoch': 0.05}
{'loss': 0.9287, 'learning_rate': 1.997746909989978e-05, 'epoch': 0.05}
{'loss': 1.0829, 'learning_rate': 1.997694351109409e-05, 'epoch': 0.05}
{'loss': 0.8272, 'learning_rate': 1.9976411869511746e-05, 'epoch': 0.05}
{'loss': 0.8121, 'learning_rate': 1.9975874175475284e-05, 'epoch': 0.05}
{'loss': 0.921, 'learning_rate': 1.9975330429310908e-05, 'epoch': 0.05}
{'loss': 0.7297, 'learning_rate': 1.9974780631348495e-05, 'epoch': 0.05}
{'loss': 0.9443, 'learning_rate': 1.99742247819216e-05, 'epoch': 0.05}
{'loss': 1.0005, 'learning_rate': 1.9973662881367442e-05, 'epoch': 0.05}
{'loss': 0.8008, 'learning_rate': 1.997309493002691e-05, 'epoch': 0.05}
{'loss': 0.9542, 'learning_rate': 1.997252092824457e-05, 'epoch': 0.05}
{'loss': 0.8888, 'learning_rate': 1.9971940876368653e-05, 'epoch': 0.05}
{'loss': 0.8493, 'learning_rate': 1.9971354774751063e-05, 'epoch': 0.05}
{'loss': 0.8955, 'learning_rate': 1.9970762623747373e-05, 'epoch': 0.05}
{'loss': 0.9492, 'learning_rate': 1.997016442371683e-05, 'epoch': 0.05}
{'loss': 0.8345, 'learning_rate': 1.9969560175022343e-05, 'epoch': 0.05}
{'loss': 0.7506, 'learning_rate': 1.9968949878030503e-05, 'epoch': 0.05}
{'loss': 1.0079, 'learning_rate': 1.996833353311156e-05, 'epoch': 0.05}
{'loss': 0.9428, 'learning_rate': 1.996771114063943e-05, 'epoch': 0.05}
{'loss': 0.9557, 'learning_rate': 1.9967082700991712e-05, 'epoch': 0.06}
{'loss': 0.9446, 'learning_rate': 1.996644821454966e-05, 'epoch': 0.06}
{'loss': 0.9406, 'learning_rate': 1.9965807681698208e-05, 'epoch': 0.06}
{'loss': 0.9666, 'learning_rate': 1.9965161102825944e-05, 'epoch': 0.06}
{'loss': 0.935, 'learning_rate': 1.996450847832514e-05, 'epoch': 0.06}
{'loss': 0.9229, 'learning_rate': 1.9963849808591723e-05, 'epoch': 0.06}
{'loss': 0.9569, 'learning_rate': 1.9963185094025293e-05, 'epoch': 0.06}
{'loss': 0.8271, 'learning_rate': 1.9962514335029116e-05, 'epoch': 0.06}
{'loss': 0.8591, 'learning_rate': 1.996183753201013e-05, 'epoch': 0.06}
{'loss': 0.942, 'learning_rate': 1.996115468537893e-05, 'epoch': 0.06}
{'loss': 0.9006, 'learning_rate': 1.9960465795549787e-05, 'epoch': 0.06}
{'loss': 0.9467, 'learning_rate': 1.9959770862940632e-05, 'epoch': 0.06}
{'loss': 0.7879, 'learning_rate': 1.9959069887973067e-05, 'epoch': 0.06}
{'loss': 0.8709, 'learning_rate': 1.9958362871072353e-05, 'epoch': 0.06}
{'loss': 0.7989, 'learning_rate': 1.9957649812667422e-05, 'epoch': 0.06}
{'loss': 0.9208, 'learning_rate': 1.995693071319087e-05, 'epoch': 0.06}
{'loss': 0.8988, 'learning_rate': 1.995620557307896e-05, 'epoch': 0.06}
{'loss': 0.8663, 'learning_rate': 1.995547439277161e-05, 'epoch': 0.06}
{'loss': 0.9376, 'learning_rate': 1.9954737172712422e-05, 'epoch': 0.06}
{'loss': 0.9227, 'learning_rate': 1.995399391334864e-05, 'epoch': 0.06}
{'loss': 0.9234, 'learning_rate': 1.9953244615131187e-05, 'epoch': 0.06}
{'loss': 1.0002, 'learning_rate': 1.9952489278514644e-05, 'epoch': 0.06}
{'loss': 0.7775, 'learning_rate': 1.9951727903957252e-05, 'epoch': 0.06}
{'loss': 0.9475, 'learning_rate': 1.9950960491920923e-05, 'epoch': 0.06}
{'loss': 0.6812, 'learning_rate': 1.9950187042871226e-05, 'epoch': 0.06}
{'loss': 0.6584, 'learning_rate': 1.9949407557277394e-05, 'epoch': 0.06}
{'loss': 0.9457, 'learning_rate': 1.9948622035612326e-05, 'epoch': 0.06}
{'loss': 0.7842, 'learning_rate': 1.9947830478352578e-05, 'epoch': 0.06}
{'loss': 0.8627, 'learning_rate': 1.9947032885978365e-05, 'epoch': 0.06}
{'loss': 0.9054, 'learning_rate': 1.994622925897357e-05, 'epoch': 0.06}
{'loss': 0.8565, 'learning_rate': 1.9945419597825736e-05, 'epoch': 0.06}
{'loss': 0.8991, 'learning_rate': 1.9944603903026064e-05, 'epoch': 0.06}
{'loss': 0.9805, 'learning_rate': 1.994378217506942e-05, 'epoch': 0.06}
{'loss': 0.963, 'learning_rate': 1.9942954414454322e-05, 'epoch': 0.06}
{'loss': 0.9392, 'learning_rate': 1.9942120621682957e-05, 'epoch': 0.06}
{'loss': 0.9003, 'learning_rate': 1.9941280797261163e-05, 'epoch': 0.06}
{'loss': 0.9721, 'learning_rate': 1.9940434941698447e-05, 'epoch': 0.06}
{'loss': 0.9579, 'learning_rate': 1.9939583055507964e-05, 'epoch': 0.06}
{'loss': 0.9148, 'learning_rate': 1.993872513920654e-05, 'epoch': 0.06}
{'loss': 0.9932, 'learning_rate': 1.9937861193314648e-05, 'epoch': 0.06}
{'loss': 0.9227, 'learning_rate': 1.993699121835642e-05, 'epoch': 0.06}
{'loss': 0.9783, 'learning_rate': 1.9936115214859663e-05, 'epoch': 0.06}
{'loss': 0.7436, 'learning_rate': 1.993523318335581e-05, 'epoch': 0.07}
{'loss': 0.9686, 'learning_rate': 1.993434512437998e-05, 'epoch': 0.07}
{'loss': 0.9712, 'learning_rate': 1.9933451038470936e-05, 'epoch': 0.07}
{'loss': 0.7316, 'learning_rate': 1.9932550926171096e-05, 'epoch': 0.07}
{'loss': 0.8019, 'learning_rate': 1.993164478802654e-05, 'epoch': 0.07}
{'loss': 0.9595, 'learning_rate': 1.9930732624587e-05, 'epoch': 0.07}
{'loss': 0.9985, 'learning_rate': 1.992981443640586e-05, 'epoch': 0.07}
{'loss': 0.8337, 'learning_rate': 1.9928890224040168e-05, 'epoch': 0.07}
{'loss': 0.9769, 'learning_rate': 1.9927959988050622e-05, 'epoch': 0.07}
{'loss': 0.7635, 'learning_rate': 1.992702372900157e-05, 'epoch': 0.07}
{'loss': 0.9077, 'learning_rate': 1.9926081447461025e-05, 'epoch': 0.07}
{'loss': 0.9568, 'learning_rate': 1.9925133144000643e-05, 'epoch': 0.07}
{'loss': 0.9169, 'learning_rate': 1.9924178819195732e-05, 'epoch': 0.07}
{'loss': 0.8531, 'learning_rate': 1.9923218473625264e-05, 'epoch': 0.07}
{'loss': 0.9412, 'learning_rate': 1.992225210787186e-05, 'epoch': 0.07}
{'loss': 0.8261, 'learning_rate': 1.992127972252179e-05, 'epoch': 0.07}
{'loss': 0.9155, 'learning_rate': 1.9920301318164978e-05, 'epoch': 0.07}
{'loss': 0.9222, 'learning_rate': 1.9919316895394993e-05, 'epoch': 0.07}
{'loss': 0.9173, 'learning_rate': 1.9918326454809066e-05, 'epoch': 0.07}
{'loss': 0.9692, 'learning_rate': 1.9917329997008075e-05, 'epoch': 0.07}
{'loss': 0.8445, 'learning_rate': 1.9916327522596545e-05, 'epoch': 0.07}
{'loss': 1.0185, 'learning_rate': 1.9915319032182655e-05, 'epoch': 0.07}
{'loss': 0.9762, 'learning_rate': 1.991430452637823e-05, 'epoch': 0.07}
{'loss': 0.8776, 'learning_rate': 1.991328400579875e-05, 'epoch': 0.07}
{'loss': 0.8514, 'learning_rate': 1.9912257471063338e-05, 'epoch': 0.07}
{'loss': 0.9522, 'learning_rate': 1.991122492279477e-05, 'epoch': 0.07}
{'loss': 0.9614, 'learning_rate': 1.9910186361619473e-05, 'epoch': 0.07}
{'loss': 0.9373, 'learning_rate': 1.9909141788167506e-05, 'epoch': 0.07}
{'loss': 0.9372, 'learning_rate': 1.99080912030726e-05, 'epoch': 0.07}
{'loss': 0.8458, 'learning_rate': 1.990703460697211e-05, 'epoch': 0.07}
[2025-12-09 11:12:47,029] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1500 is about to be saved!
[2025-12-09 11:12:47,120] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 11:12:47,121] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 11:12:47,738] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 11:12:47,764] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1500/global_step1500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 11:13:24,065] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1500/global_step1500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 11:13:24,068] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-1500/global_step1500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 11:13:28,133] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
{'loss': 1.0114, 'learning_rate': 1.9905972000507057e-05, 'epoch': 0.07}
{'loss': 0.8871, 'learning_rate': 1.9904903384322095e-05, 'epoch': 0.07}
{'loss': 0.887, 'learning_rate': 1.9903828759065524e-05, 'epoch': 0.07}
{'loss': 0.9293, 'learning_rate': 1.99027481253893e-05, 'epoch': 0.07}
{'loss': 0.9011, 'learning_rate': 1.9901661483949015e-05, 'epoch': 0.07}
{'loss': 0.9879, 'learning_rate': 1.990056883540391e-05, 'epoch': 0.07}
{'loss': 0.7397, 'learning_rate': 1.989947018041687e-05, 'epoch': 0.07}
{'loss': 0.8584, 'learning_rate': 1.989836551965442e-05, 'epoch': 0.07}
{'loss': 0.9442, 'learning_rate': 1.9897254853786735e-05, 'epoch': 0.07}
{'loss': 0.9027, 'learning_rate': 1.9896138183487626e-05, 'epoch': 0.07}
{'loss': 0.9269, 'learning_rate': 1.9895015509434555e-05, 'epoch': 0.07}
{'loss': 0.9373, 'learning_rate': 1.989388683230862e-05, 'epoch': 0.08}
{'loss': 0.9394, 'learning_rate': 1.9892752152794565e-05, 'epoch': 0.08}
{'loss': 0.8373, 'learning_rate': 1.9891611471580767e-05, 'epoch': 0.08}
{'loss': 0.962, 'learning_rate': 1.9890464789359253e-05, 'epoch': 0.08}
{'loss': 0.8129, 'learning_rate': 1.9889312106825694e-05, 'epoch': 0.08}
{'loss': 0.987, 'learning_rate': 1.9888153424679387e-05, 'epoch': 0.08}
{'loss': 0.8116, 'learning_rate': 1.9886988743623284e-05, 'epoch': 0.08}
{'loss': 0.9339, 'learning_rate': 1.9885818064363968e-05, 'epoch': 0.08}
{'loss': 0.8515, 'learning_rate': 1.988464138761166e-05, 'epoch': 0.08}
{'loss': 0.8367, 'learning_rate': 1.9883458714080222e-05, 'epoch': 0.08}
{'loss': 0.7868, 'learning_rate': 1.9882270044487155e-05, 'epoch': 0.08}
{'loss': 0.9136, 'learning_rate': 1.9881075379553597e-05, 'epoch': 0.08}
{'loss': 0.9633, 'learning_rate': 1.9879874720004326e-05, 'epoch': 0.08}
{'loss': 0.8738, 'learning_rate': 1.987866806656775e-05, 'epoch': 0.08}
{'loss': 0.9924, 'learning_rate': 1.9877455419975917e-05, 'epoch': 0.08}
{'loss': 0.792, 'learning_rate': 1.9876236780964513e-05, 'epoch': 0.08}
{'loss': 0.9721, 'learning_rate': 1.987501215027286e-05, 'epoch': 0.08}
{'loss': 0.9005, 'learning_rate': 1.9873781528643905e-05, 'epoch': 0.08}
{'loss': 0.9068, 'learning_rate': 1.9872544916824244e-05, 'epoch': 0.08}
{'loss': 0.9559, 'learning_rate': 1.98713023155641e-05, 'epoch': 0.08}
{'loss': 0.9395, 'learning_rate': 1.9870053725617326e-05, 'epoch': 0.08}
{'loss': 0.8358, 'learning_rate': 1.9868799147741417e-05, 'epoch': 0.08}
{'loss': 0.8414, 'learning_rate': 1.986753858269749e-05, 'epoch': 0.08}
{'loss': 1.024, 'learning_rate': 1.98662720312503e-05, 'epoch': 0.08}
{'loss': 0.7581, 'learning_rate': 1.9864999494168245e-05, 'epoch': 0.08}
{'loss': 0.8904, 'learning_rate': 1.986372097222333e-05, 'epoch': 0.08}
{'loss': 0.9566, 'learning_rate': 1.986243646619121e-05, 'epoch': 0.08}
{'loss': 0.9627, 'learning_rate': 1.9861145976851167e-05, 'epoch': 0.08}
{'loss': 0.9809, 'learning_rate': 1.9859849504986105e-05, 'epoch': 0.08}
{'loss': 0.974, 'learning_rate': 1.9858547051382565e-05, 'epoch': 0.08}
{'loss': 0.9098, 'learning_rate': 1.9857238616830718e-05, 'epoch': 0.08}
{'loss': 0.945, 'learning_rate': 1.9855924202124358e-05, 'epoch': 0.08}
{'loss': 0.8029, 'learning_rate': 1.9854603808060907e-05, 'epoch': 0.08}
{'loss': 0.8357, 'learning_rate': 1.9853277435441422e-05, 'epoch': 0.08}
{'loss': 0.9033, 'learning_rate': 1.985194508507058e-05, 'epoch': 0.08}
{'loss': 0.9275, 'learning_rate': 1.9850606757756683e-05, 'epoch': 0.08}
{'loss': 0.8359, 'learning_rate': 1.9849262454311663e-05, 'epoch': 0.08}
{'loss': 0.8985, 'learning_rate': 1.9847912175551085e-05, 'epoch': 0.08}
{'loss': 0.9888, 'learning_rate': 1.9846555922294123e-05, 'epoch': 0.08}
{'loss': 0.9277, 'learning_rate': 1.9845193695363592e-05, 'epoch': 0.08}
{'loss': 0.8713, 'learning_rate': 1.9843825495585912e-05, 'epoch': 0.08}
{'loss': 0.9545, 'learning_rate': 1.9842451323791146e-05, 'epoch': 0.08}
{'loss': 0.7822, 'learning_rate': 1.9841071180812972e-05, 'epoch': 0.09}
{'loss': 0.868, 'learning_rate': 1.9839685067488683e-05, 'epoch': 0.09}
{'loss': 0.8654, 'learning_rate': 1.9838292984659207e-05, 'epoch': 0.09}
{'loss': 0.8244, 'learning_rate': 1.983689493316909e-05, 'epoch': 0.09}
{'loss': 0.7061, 'learning_rate': 1.9835490913866492e-05, 'epoch': 0.09}
{'loss': 0.8875, 'learning_rate': 1.9834080927603198e-05, 'epoch': 0.09}
{'loss': 0.8078, 'learning_rate': 1.983266497523462e-05, 'epoch': 0.09}
{'loss': 0.7897, 'learning_rate': 1.9831243057619774e-05, 'epoch': 0.09}
{'loss': 0.8406, 'learning_rate': 1.9829815175621306e-05, 'epoch': 0.09}
{'loss': 0.9902, 'learning_rate': 1.9828381330105487e-05, 'epoch': 0.09}
{'loss': 0.9097, 'learning_rate': 1.9826941521942187e-05, 'epoch': 0.09}
{'loss': 0.8182, 'learning_rate': 1.9825495752004912e-05, 'epoch': 0.09}
{'loss': 0.9197, 'learning_rate': 1.982404402117077e-05, 'epoch': 0.09}
{'loss': 0.8506, 'learning_rate': 1.9822586330320492e-05, 'epoch': 0.09}
{'loss': 0.9394, 'learning_rate': 1.9821122680338428e-05, 'epoch': 0.09}
{'loss': 0.9362, 'learning_rate': 1.981965307211254e-05, 'epoch': 0.09}
{'loss': 0.9597, 'learning_rate': 1.9818177506534406e-05, 'epoch': 0.09}
{'loss': 0.9679, 'learning_rate': 1.981669598449921e-05, 'epoch': 0.09}
{'loss': 0.9117, 'learning_rate': 1.9815208506905764e-05, 'epoch': 0.09}
{'loss': 0.9514, 'learning_rate': 1.9813715074656482e-05, 'epoch': 0.09}
{'loss': 0.9309, 'learning_rate': 1.9812215688657397e-05, 'epoch': 0.09}
{'loss': 0.807, 'learning_rate': 1.9810710349818147e-05, 'epoch': 0.09}
{'loss': 0.7943, 'learning_rate': 1.9809199059051987e-05, 'epoch': 0.09}
{'loss': 0.9907, 'learning_rate': 1.9807681817275783e-05, 'epoch': 0.09}
{'loss': 0.8937, 'learning_rate': 1.9806158625410008e-05, 'epoch': 0.09}
{'loss': 0.9912, 'learning_rate': 1.980462948437875e-05, 'epoch': 0.09}
{'loss': 0.9497, 'learning_rate': 1.98030943951097e-05, 'epoch': 0.09}
{'loss': 0.8485, 'learning_rate': 1.9801553358534157e-05, 'epoch': 0.09}
{'loss': 0.8967, 'learning_rate': 1.9800006375587043e-05, 'epoch': 0.09}
{'loss': 0.8633, 'learning_rate': 1.9798453447206862e-05, 'epoch': 0.09}
{'loss': 0.9849, 'learning_rate': 1.979689457433575e-05, 'epoch': 0.09}
{'loss': 0.7672, 'learning_rate': 1.9795329757919433e-05, 'epoch': 0.09}
{'loss': 0.9396, 'learning_rate': 1.9793758998907248e-05, 'epoch': 0.09}
{'loss': 0.925, 'learning_rate': 1.979218229825214e-05, 'epoch': 0.09}
{'loss': 0.9449, 'learning_rate': 1.9790599656910653e-05, 'epoch': 0.09}
{'loss': 0.8693, 'learning_rate': 1.9789011075842947e-05, 'epoch': 0.09}
{'loss': 0.9185, 'learning_rate': 1.9787416556012766e-05, 'epoch': 0.09}
{'loss': 0.6696, 'learning_rate': 1.9785816098387468e-05, 'epoch': 0.09}
{'loss': 0.908, 'learning_rate': 1.978420970393802e-05, 'epoch': 0.09}
{'loss': 0.9596, 'learning_rate': 1.978259737363898e-05, 'epoch': 0.09}
{'loss': 0.9303, 'learning_rate': 1.9780979108468513e-05, 'epoch': 0.09}
{'loss': 0.9314, 'learning_rate': 1.977935490940838e-05, 'epoch': 0.09}
{'loss': 0.8379, 'learning_rate': 1.9777724777443943e-05, 'epoch': 0.1}
{'loss': 0.8484, 'learning_rate': 1.977608871356417e-05, 'epoch': 0.1}
{'loss': 0.8041, 'learning_rate': 1.9774446718761616e-05, 'epoch': 0.1}
{'loss': 0.9389, 'learning_rate': 1.9772798794032445e-05, 'epoch': 0.1}
{'loss': 1.0019, 'learning_rate': 1.9771144940376413e-05, 'epoch': 0.1}
[2025-12-09 11:38:36,309] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step2000 is about to be saved!
[2025-12-09 11:38:36,339] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2000/global_step2000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 11:38:36,340] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2000/global_step2000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 11:38:36,742] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2000/global_step2000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 11:38:36,744] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2000/global_step2000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 11:39:09,768] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2000/global_step2000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 11:39:09,771] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2000/global_step2000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 11:39:14,379] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
{'loss': 0.8352, 'learning_rate': 1.976948515879687e-05, 'epoch': 0.1}
{'loss': 0.8394, 'learning_rate': 1.9767819450300773e-05, 'epoch': 0.1}
{'loss': 0.8347, 'learning_rate': 1.9766147815898668e-05, 'epoch': 0.1}
{'loss': 0.822, 'learning_rate': 1.976447025660469e-05, 'epoch': 0.1}
{'loss': 0.9276, 'learning_rate': 1.976278677343658e-05, 'epoch': 0.1}
{'loss': 0.9248, 'learning_rate': 1.9761097367415663e-05, 'epoch': 0.1}
{'loss': 0.9498, 'learning_rate': 1.9759402039566865e-05, 'epoch': 0.1}
{'loss': 0.903, 'learning_rate': 1.9757700790918704e-05, 'epoch': 0.1}
{'loss': 0.8879, 'learning_rate': 1.9755993622503283e-05, 'epoch': 0.1}
{'loss': 0.9049, 'learning_rate': 1.9754280535356302e-05, 'epoch': 0.1}
{'loss': 0.8979, 'learning_rate': 1.975256153051705e-05, 'epoch': 0.1}
{'loss': 0.8422, 'learning_rate': 1.975083660902841e-05, 'epoch': 0.1}
{'loss': 0.7536, 'learning_rate': 1.974910577193685e-05, 'epoch': 0.1}
{'loss': 0.9466, 'learning_rate': 1.9747369020292424e-05, 'epoch': 0.1}
{'loss': 0.8274, 'learning_rate': 1.9745626355148782e-05, 'epoch': 0.1}
{'loss': 1.0061, 'learning_rate': 1.974387777756316e-05, 'epoch': 0.1}
{'loss': 0.9821, 'learning_rate': 1.9742123288596375e-05, 'epoch': 0.1}
{'loss': 0.9474, 'learning_rate': 1.9740362889312835e-05, 'epoch': 0.1}
{'loss': 0.8264, 'learning_rate': 1.973859658078053e-05, 'epoch': 0.1}
{'loss': 0.9608, 'learning_rate': 1.9736824364071047e-05, 'epoch': 0.1}
{'loss': 0.9616, 'learning_rate': 1.973504624025954e-05, 'epoch': 0.1}
{'loss': 0.927, 'learning_rate': 1.9733262210424752e-05, 'epoch': 0.1}
{'loss': 0.9328, 'learning_rate': 1.9731472275649023e-05, 'epoch': 0.1}
{'loss': 0.7384, 'learning_rate': 1.9729676437018256e-05, 'epoch': 0.1}
{'loss': 0.938, 'learning_rate': 1.9727874695621946e-05, 'epoch': 0.1}
{'loss': 0.9789, 'learning_rate': 1.9726067052553167e-05, 'epoch': 0.1}
{'loss': 0.8794, 'learning_rate': 1.9724253508908574e-05, 'epoch': 0.1}
{'loss': 0.8316, 'learning_rate': 1.9722434065788398e-05, 'epoch': 0.1}
{'loss': 0.9573, 'learning_rate': 1.972060872429646e-05, 'epoch': 0.1}
{'loss': 0.9073, 'learning_rate': 1.9718777485540145e-05, 'epoch': 0.1}
{'loss': 0.9179, 'learning_rate': 1.9716940350630424e-05, 'epoch': 0.1}
{'loss': 0.9126, 'learning_rate': 1.971509732068184e-05, 'epoch': 0.1}
{'loss': 0.8817, 'learning_rate': 1.9713248396812524e-05, 'epoch': 0.1}
{'loss': 0.9758, 'learning_rate': 1.9711393580144168e-05, 'epoch': 0.1}
{'loss': 0.9134, 'learning_rate': 1.970953287180205e-05, 'epoch': 0.1}
{'loss': 0.9597, 'learning_rate': 1.9707666272915016e-05, 'epoch': 0.1}
{'loss': 0.899, 'learning_rate': 1.9705793784615487e-05, 'epoch': 0.11}
{'loss': 0.8143, 'learning_rate': 1.9703915408039454e-05, 'epoch': 0.11}
{'loss': 0.9096, 'learning_rate': 1.970203114432649e-05, 'epoch': 0.11}
{'loss': 0.8997, 'learning_rate': 1.970014099461973e-05, 'epoch': 0.11}
{'loss': 0.8363, 'learning_rate': 1.969824496006589e-05, 'epoch': 0.11}
{'loss': 0.9728, 'learning_rate': 1.969634304181524e-05, 'epoch': 0.11}
{'loss': 0.9463, 'learning_rate': 1.969443524102163e-05, 'epoch': 0.11}
{'loss': 0.913, 'learning_rate': 1.9692521558842485e-05, 'epoch': 0.11}
{'loss': 0.9319, 'learning_rate': 1.9690601996438782e-05, 'epoch': 0.11}
{'loss': 0.9482, 'learning_rate': 1.968867655497508e-05, 'epoch': 0.11}
{'loss': 0.8422, 'learning_rate': 1.96867452356195e-05, 'epoch': 0.11}
{'loss': 0.9497, 'learning_rate': 1.9684808039543727e-05, 'epoch': 0.11}
{'loss': 0.9137, 'learning_rate': 1.9682864967923006e-05, 'epoch': 0.11}
{'loss': 0.9498, 'learning_rate': 1.968091602193616e-05, 'epoch': 0.11}
{'loss': 0.9524, 'learning_rate': 1.9678961202765572e-05, 'epoch': 0.11}
{'loss': 1.0057, 'learning_rate': 1.9677000511597175e-05, 'epoch': 0.11}
{'loss': 0.8, 'learning_rate': 1.967503394962048e-05, 'epoch': 0.11}
{'loss': 0.9498, 'learning_rate': 1.967306151802855e-05, 'epoch': 0.11}
{'loss': 0.887, 'learning_rate': 1.9671083218018016e-05, 'epoch': 0.11}
{'loss': 0.7851, 'learning_rate': 1.9669099050789063e-05, 'epoch': 0.11}
{'loss': 0.9534, 'learning_rate': 1.9667109017545442e-05, 'epoch': 0.11}
{'loss': 0.9497, 'learning_rate': 1.966511311949446e-05, 'epoch': 0.11}
{'loss': 0.9271, 'learning_rate': 1.9663111357846976e-05, 'epoch': 0.11}
{'loss': 0.9829, 'learning_rate': 1.9661103733817418e-05, 'epoch': 0.11}
{'loss': 0.8565, 'learning_rate': 1.965909024862376e-05, 'epoch': 0.11}
{'loss': 0.8499, 'learning_rate': 1.9657070903487534e-05, 'epoch': 0.11}
{'loss': 0.8643, 'learning_rate': 1.9655045699633836e-05, 'epoch': 0.11}
{'loss': 0.8562, 'learning_rate': 1.9653014638291304e-05, 'epoch': 0.11}
{'loss': 0.9774, 'learning_rate': 1.9650977720692138e-05, 'epoch': 0.11}
{'loss': 0.9704, 'learning_rate': 1.9648934948072086e-05, 'epoch': 0.11}
{'loss': 0.938, 'learning_rate': 1.964688632167045e-05, 'epoch': 0.11}
{'loss': 0.9158, 'learning_rate': 1.9644831842730084e-05, 'epoch': 0.11}
{'loss': 0.9465, 'learning_rate': 1.9642771512497395e-05, 'epoch': 0.11}
{'loss': 0.9594, 'learning_rate': 1.964070533222233e-05, 'epoch': 0.11}
{'loss': 0.8039, 'learning_rate': 1.96386333031584e-05, 'epoch': 0.11}
{'loss': 0.9469, 'learning_rate': 1.9636555426562653e-05, 'epoch': 0.11}
{'loss': 0.9689, 'learning_rate': 1.963447170369568e-05, 'epoch': 0.11}
{'loss': 0.9327, 'learning_rate': 1.9632382135821638e-05, 'epoch': 0.11}
{'loss': 0.7715, 'learning_rate': 1.9630286724208216e-05, 'epoch': 0.11}
{'loss': 0.852, 'learning_rate': 1.9628185470126645e-05, 'epoch': 0.11}
{'loss': 0.8178, 'learning_rate': 1.9626078374851715e-05, 'epoch': 0.11}
{'loss': 0.9035, 'learning_rate': 1.962396543966174e-05, 'epoch': 0.11}
{'loss': 1.0042, 'learning_rate': 1.9621846665838598e-05, 'epoch': 0.12}
{'loss': 0.8084, 'learning_rate': 1.9619722054667698e-05, 'epoch': 0.12}
{'loss': 0.9356, 'learning_rate': 1.9617591607437988e-05, 'epoch': 0.12}
{'loss': 0.8482, 'learning_rate': 1.961545532544196e-05, 'epoch': 0.12}
{'loss': 0.8331, 'learning_rate': 1.9613313209975645e-05, 'epoch': 0.12}
{'loss': 0.925, 'learning_rate': 1.961116526233862e-05, 'epoch': 0.12}
{'loss': 0.9064, 'learning_rate': 1.9609011483833993e-05, 'epoch': 0.12}
{'loss': 0.9746, 'learning_rate': 1.9606851875768404e-05, 'epoch': 0.12}
WARNING: tokenization mismatch: 1 vs. 1440. (ignored)
{'loss': 0.8664, 'learning_rate': 1.960468643945204e-05, 'epoch': 0.12}
{'loss': 0.7744, 'learning_rate': 1.9602515176198623e-05, 'epoch': 0.12}
{'loss': 0.9378, 'learning_rate': 1.9600338087325407e-05, 'epoch': 0.12}
{'loss': 0.9759, 'learning_rate': 1.9598155174153174e-05, 'epoch': 0.12}
{'loss': 0.9, 'learning_rate': 1.9595966438006253e-05, 'epoch': 0.12}
{'loss': 0.9642, 'learning_rate': 1.9593771880212498e-05, 'epoch': 0.12}
{'loss': 0.9642, 'learning_rate': 1.9591571502103294e-05, 'epoch': 0.12}
{'loss': 0.9698, 'learning_rate': 1.9589365305013556e-05, 'epoch': 0.12}
{'loss': 0.8426, 'learning_rate': 1.9587153290281734e-05, 'epoch': 0.12}
{'loss': 0.9764, 'learning_rate': 1.9584935459249807e-05, 'epoch': 0.12}
{'loss': 0.739, 'learning_rate': 1.9582711813263277e-05, 'epoch': 0.12}
{'loss': 0.9228, 'learning_rate': 1.9580482353671184e-05, 'epoch': 0.12}
{'loss': 0.932, 'learning_rate': 1.9578247081826083e-05, 'epoch': 0.12}
{'loss': 0.9475, 'learning_rate': 1.957600599908406e-05, 'epoch': 0.12}
[2025-12-09 12:14:04,192] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step2500 is about to be saved!
[2025-12-09 12:14:04,720] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2500/global_step2500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 12:14:04,720] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2500/global_step2500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 12:14:04,872] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2500/global_step2500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 12:14:04,874] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2500/global_step2500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 12:14:41,378] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2500/global_step2500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 12:14:41,383] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-2500/global_step2500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 12:14:41,883] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
{'loss': 0.9206, 'learning_rate': 1.9573759106804732e-05, 'epoch': 0.12}
{'loss': 0.9219, 'learning_rate': 1.9571506406351233e-05, 'epoch': 0.12}
{'loss': 0.9461, 'learning_rate': 1.956924789909022e-05, 'epoch': 0.12}
{'loss': 0.9069, 'learning_rate': 1.9566983586391884e-05, 'epoch': 0.12}
{'loss': 0.9641, 'learning_rate': 1.9564713469629928e-05, 'epoch': 0.12}
{'loss': 0.957, 'learning_rate': 1.9562437550181573e-05, 'epoch': 0.12}
{'loss': 0.8987, 'learning_rate': 1.9560155829427567e-05, 'epoch': 0.12}
{'loss': 0.9009, 'learning_rate': 1.955786830875218e-05, 'epoch': 0.12}
{'loss': 0.9277, 'learning_rate': 1.9555574989543197e-05, 'epoch': 0.12}
{'loss': 0.9135, 'learning_rate': 1.9553275873191916e-05, 'epoch': 0.12}
{'loss': 0.9564, 'learning_rate': 1.955097096109316e-05, 'epoch': 0.12}
{'loss': 0.8483, 'learning_rate': 1.9548660254645265e-05, 'epoch': 0.12}
{'loss': 0.8183, 'learning_rate': 1.954634375525008e-05, 'epoch': 0.12}
{'loss': 0.9308, 'learning_rate': 1.9544021464312977e-05, 'epoch': 0.12}
{'loss': 0.8235, 'learning_rate': 1.954169338324283e-05, 'epoch': 0.12}
{'loss': 0.8408, 'learning_rate': 1.9539359513452026e-05, 'epoch': 0.12}
{'loss': 0.9342, 'learning_rate': 1.9537019856356478e-05, 'epoch': 0.12}
{'loss': 0.9142, 'learning_rate': 1.9534674413375595e-05, 'epoch': 0.12}
{'loss': 0.927, 'learning_rate': 1.9532323185932306e-05, 'epoch': 0.12}
{'loss': 0.9192, 'learning_rate': 1.952996617545304e-05, 'epoch': 0.13}
{'loss': 0.8927, 'learning_rate': 1.952760338336775e-05, 'epoch': 0.13}
{'loss': 0.8796, 'learning_rate': 1.9525234811109874e-05, 'epoch': 0.13}
{'loss': 0.7635, 'learning_rate': 1.9522860460116377e-05, 'epoch': 0.13}
{'loss': 0.6877, 'learning_rate': 1.9520480331827718e-05, 'epoch': 0.13}
{'loss': 0.8197, 'learning_rate': 1.9518094427687866e-05, 'epoch': 0.13}
{'loss': 0.9229, 'learning_rate': 1.9515702749144293e-05, 'epoch': 0.13}
{'loss': 0.9163, 'learning_rate': 1.9513305297647976e-05, 'epoch': 0.13}
{'loss': 0.7311, 'learning_rate': 1.951090207465339e-05, 'epoch': 0.13}
{'loss': 0.6502, 'learning_rate': 1.9508493081618515e-05, 'epoch': 0.13}
{'loss': 0.9097, 'learning_rate': 1.9506078320004825e-05, 'epoch': 0.13}
{'loss': 1.0046, 'learning_rate': 1.950365779127731e-05, 'epoch': 0.13}
{'loss': 0.9021, 'learning_rate': 1.9501231496904435e-05, 'epoch': 0.13}
{'loss': 0.9509, 'learning_rate': 1.9498799438358186e-05, 'epoch': 0.13}
{'loss': 0.791, 'learning_rate': 1.949636161711403e-05, 'epoch': 0.13}
{'loss': 0.906, 'learning_rate': 1.9493918034650934e-05, 'epoch': 0.13}
{'loss': 0.9165, 'learning_rate': 1.9491468692451373e-05, 'epoch': 0.13}
{'loss': 0.9183, 'learning_rate': 1.9489013592001293e-05, 'epoch': 0.13}
{'loss': 0.7869, 'learning_rate': 1.948655273479015e-05, 'epoch': 0.13}
{'loss': 0.92, 'learning_rate': 1.9484086122310887e-05, 'epoch': 0.13}
{'loss': 0.8826, 'learning_rate': 1.9481613756059944e-05, 'epoch': 0.13}
{'loss': 0.9285, 'learning_rate': 1.947913563753724e-05, 'epoch': 0.13}
{'loss': 0.9192, 'learning_rate': 1.9476651768246203e-05, 'epoch': 0.13}
{'loss': 0.9495, 'learning_rate': 1.9474162149693724e-05, 'epoch': 0.13}
{'loss': 0.8909, 'learning_rate': 1.9471666783390204e-05, 'epoch': 0.13}
{'loss': 0.8896, 'learning_rate': 1.946916567084952e-05, 'epoch': 0.13}
{'loss': 0.8802, 'learning_rate': 1.946665881358904e-05, 'epoch': 0.13}
{'loss': 0.8957, 'learning_rate': 1.9464146213129615e-05, 'epoch': 0.13}
{'loss': 0.9233, 'learning_rate': 1.9461627870995585e-05, 'epoch': 0.13}
{'loss': 0.7681, 'learning_rate': 1.9459103788714756e-05, 'epoch': 0.13}
{'loss': 0.7899, 'learning_rate': 1.945657396781844e-05, 'epoch': 0.13}
{'loss': 0.9151, 'learning_rate': 1.945403840984142e-05, 'epoch': 0.13}
{'loss': 0.9366, 'learning_rate': 1.9451497116321954e-05, 'epoch': 0.13}
{'loss': 0.949, 'learning_rate': 1.944895008880179e-05, 'epoch': 0.13}
{'loss': 0.8592, 'learning_rate': 1.9446397328826145e-05, 'epoch': 0.13}
{'loss': 0.9894, 'learning_rate': 1.9443838837943717e-05, 'epoch': 0.13}
{'loss': 0.9108, 'learning_rate': 1.944127461770669e-05, 'epoch': 0.13}
{'loss': 0.73, 'learning_rate': 1.943870466967071e-05, 'epoch': 0.13}
{'loss': 0.9534, 'learning_rate': 1.9436128995394903e-05, 'epoch': 0.13}
{'loss': 0.8426, 'learning_rate': 1.9433547596441877e-05, 'epoch': 0.13}
{'loss': 0.9323, 'learning_rate': 1.9430960474377697e-05, 'epoch': 0.13}
{'loss': 0.9257, 'learning_rate': 1.9428367630771915e-05, 'epoch': 0.13}
{'loss': 0.8377, 'learning_rate': 1.9425769067197548e-05, 'epoch': 0.14}
{'loss': 0.9103, 'learning_rate': 1.9423164785231078e-05, 'epoch': 0.14}
{'loss': 0.9395, 'learning_rate': 1.942055478645247e-05, 'epoch': 0.14}
{'loss': 0.8627, 'learning_rate': 1.941793907244514e-05, 'epoch': 0.14}
{'loss': 0.9263, 'learning_rate': 1.9415317644795984e-05, 'epoch': 0.14}
{'loss': 0.9374, 'learning_rate': 1.9412690505095363e-05, 'epoch': 0.14}
{'loss': 0.9433, 'learning_rate': 1.94100576549371e-05, 'epoch': 0.14}
{'loss': 0.9244, 'learning_rate': 1.9407419095918477e-05, 'epoch': 0.14}
{'loss': 0.9034, 'learning_rate': 1.9404774829640254e-05, 'epoch': 0.14}
{'loss': 0.8738, 'learning_rate': 1.940212485770664e-05, 'epoch': 0.14}
{'loss': 0.7929, 'learning_rate': 1.939946918172531e-05, 'epoch': 0.14}
{'loss': 0.8883, 'learning_rate': 1.9396807803307405e-05, 'epoch': 0.14}
{'loss': 0.9487, 'learning_rate': 1.9394140724067515e-05, 'epoch': 0.14}
{'loss': 0.7844, 'learning_rate': 1.9391467945623698e-05, 'epoch': 0.14}
{'loss': 0.9022, 'learning_rate': 1.9388789469597464e-05, 'epoch': 0.14}
{'loss': 1.008, 'learning_rate': 1.9386105297613782e-05, 'epoch': 0.14}
{'loss': 0.8783, 'learning_rate': 1.9383415431301075e-05, 'epoch': 0.14}
{'loss': 0.8188, 'learning_rate': 1.9380719872291223e-05, 'epoch': 0.14}
{'loss': 0.943, 'learning_rate': 1.9378018622219557e-05, 'epoch': 0.14}
{'loss': 0.8097, 'learning_rate': 1.9375311682724863e-05, 'epoch': 0.14}
{'loss': 0.9344, 'learning_rate': 1.9372599055449374e-05, 'epoch': 0.14}
{'loss': 0.9421, 'learning_rate': 1.9369880742038783e-05, 'epoch': 0.14}
{'loss': 0.8065, 'learning_rate': 1.9367156744142218e-05, 'epoch': 0.14}
{'loss': 0.9576, 'learning_rate': 1.9364427063412276e-05, 'epoch': 0.14}
{'loss': 0.9487, 'learning_rate': 1.936169170150498e-05, 'epoch': 0.14}
{'loss': 0.8675, 'learning_rate': 1.9358950660079815e-05, 'epoch': 0.14}
{'loss': 0.9522, 'learning_rate': 1.9356203940799702e-05, 'epoch': 0.14}
{'loss': 0.9048, 'learning_rate': 1.935345154533102e-05, 'epoch': 0.14}
{'loss': 0.9721, 'learning_rate': 1.935069347534357e-05, 'epoch': 0.14}
{'loss': 0.9564, 'learning_rate': 1.9347929732510614e-05, 'epoch': 0.14}
{'loss': 0.8708, 'learning_rate': 1.9345160318508853e-05, 'epoch': 0.14}
{'loss': 0.9532, 'learning_rate': 1.934238523501842e-05, 'epoch': 0.14}
{'loss': 0.8991, 'learning_rate': 1.9339604483722896e-05, 'epoch': 0.14}
{'loss': 0.9549, 'learning_rate': 1.9336818066309297e-05, 'epoch': 0.14}
WARNING: tokenization mismatch: 1 vs. 1473. (ignored)
{'loss': 0.9417, 'learning_rate': 1.9334025984468075e-05, 'epoch': 0.14}
{'loss': 0.7913, 'learning_rate': 1.933122823989312e-05, 'epoch': 0.14}
{'loss': 0.8996, 'learning_rate': 1.9328424834281763e-05, 'epoch': 0.14}
{'loss': 0.9061, 'learning_rate': 1.9325615769334755e-05, 'epoch': 0.14}
{'loss': 0.8955, 'learning_rate': 1.93228010467563e-05, 'epoch': 0.14}
[2025-12-09 12:39:20,216] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step3000 is about to be saved!
[2025-12-09 12:39:20,248] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3000/global_step3000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 12:39:20,249] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3000/global_step3000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 12:39:20,405] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3000/global_step3000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 12:39:20,792] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3000/global_step3000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 12:40:14,895] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3000/global_step3000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 12:40:15,162] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3000/global_step3000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 12:40:37,225] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
{'loss': 0.8127, 'learning_rate': 1.9319980668254016e-05, 'epoch': 0.14}
{'loss': 0.8203, 'learning_rate': 1.9317154635538964e-05, 'epoch': 0.14}
{'loss': 0.9119, 'learning_rate': 1.931432295032563e-05, 'epoch': 0.15}
{'loss': 0.9086, 'learning_rate': 1.9311485614331928e-05, 'epoch': 0.15}
{'loss': 0.8778, 'learning_rate': 1.930864262927921e-05, 'epoch': 0.15}
{'loss': 0.7926, 'learning_rate': 1.9305793996892244e-05, 'epoch': 0.15}
{'loss': 0.9303, 'learning_rate': 1.930293971889923e-05, 'epoch': 0.15}
{'loss': 0.9503, 'learning_rate': 1.930007979703178e-05, 'epoch': 0.15}
{'loss': 0.9014, 'learning_rate': 1.929721423302496e-05, 'epoch': 0.15}
{'loss': 0.808, 'learning_rate': 1.929434302861723e-05, 'epoch': 0.15}
{'loss': 0.8858, 'learning_rate': 1.9291466185550482e-05, 'epoch': 0.15}
{'loss': 0.7355, 'learning_rate': 1.9288583705570026e-05, 'epoch': 0.15}
{'loss': 0.7969, 'learning_rate': 1.9285695590424604e-05, 'epoch': 0.15}
{'loss': 0.9521, 'learning_rate': 1.928280184186636e-05, 'epoch': 0.15}
{'loss': 0.8591, 'learning_rate': 1.9279902461650866e-05, 'epoch': 0.15}
{'loss': 0.9631, 'learning_rate': 1.9276997451537107e-05, 'epoch': 0.15}
{'loss': 0.922, 'learning_rate': 1.9274086813287484e-05, 'epoch': 0.15}
{'loss': 0.8001, 'learning_rate': 1.927117054866781e-05, 'epoch': 0.15}
{'loss': 0.9418, 'learning_rate': 1.926824865944732e-05, 'epoch': 0.15}
{'loss': 0.8845, 'learning_rate': 1.926532114739865e-05, 'epoch': 0.15}
{'loss': 0.9125, 'learning_rate': 1.926238801429786e-05, 'epoch': 0.15}
{'loss': 0.8746, 'learning_rate': 1.9259449261924405e-05, 'epoch': 0.15}
{'loss': 0.7344, 'learning_rate': 1.9256504892061156e-05, 'epoch': 0.15}
{'loss': 0.7812, 'learning_rate': 1.92535549064944e-05, 'epoch': 0.15}
{'loss': 0.8674, 'learning_rate': 1.925059930701382e-05, 'epoch': 0.15}
{'loss': 0.8314, 'learning_rate': 1.9247638095412508e-05, 'epoch': 0.15}
{'loss': 0.9128, 'learning_rate': 1.9244671273486962e-05, 'epoch': 0.15}
{'loss': 0.8753, 'learning_rate': 1.9241698843037083e-05, 'epoch': 0.15}
{'loss': 0.8614, 'learning_rate': 1.9238720805866174e-05, 'epoch': 0.15}
{'loss': 0.9068, 'learning_rate': 1.923573716378094e-05, 'epoch': 0.15}
{'loss': 0.9135, 'learning_rate': 1.9232747918591488e-05, 'epoch': 0.15}
{'loss': 0.9814, 'learning_rate': 1.9229753072111325e-05, 'epoch': 0.15}
{'loss': 0.9808, 'learning_rate': 1.9226752626157345e-05, 'epoch': 0.15}
{'loss': 0.9253, 'learning_rate': 1.9223746582549853e-05, 'epoch': 0.15}
{'loss': 0.8224, 'learning_rate': 1.922073494311255e-05, 'epoch': 0.15}
{'loss': 0.881, 'learning_rate': 1.921771770967252e-05, 'epoch': 0.15}
{'loss': 0.8724, 'learning_rate': 1.9214694884060248e-05, 'epoch': 0.15}
{'loss': 0.9004, 'learning_rate': 1.9211666468109612e-05, 'epoch': 0.15}
{'loss': 1.0041, 'learning_rate': 1.9208632463657885e-05, 'epoch': 0.15}
{'loss': 0.9513, 'learning_rate': 1.920559287254572e-05, 'epoch': 0.15}
{'loss': 0.9276, 'learning_rate': 1.9202547696617165e-05, 'epoch': 0.15}
{'loss': 0.8972, 'learning_rate': 1.9199496937719663e-05, 'epoch': 0.15}
{'loss': 0.8963, 'learning_rate': 1.9196440597704033e-05, 'epoch': 0.15}
{'loss': 0.8016, 'learning_rate': 1.9193378678424484e-05, 'epoch': 0.15}
{'loss': 0.806, 'learning_rate': 1.919031118173861e-05, 'epoch': 0.16}
{'loss': 0.8225, 'learning_rate': 1.9187238109507393e-05, 'epoch': 0.16}
{'loss': 0.8188, 'learning_rate': 1.918415946359519e-05, 'epoch': 0.16}
{'loss': 0.8897, 'learning_rate': 1.9181075245869744e-05, 'epoch': 0.16}
{'loss': 0.934, 'learning_rate': 1.917798545820218e-05, 'epoch': 0.16}
{'loss': 1.0133, 'learning_rate': 1.917489010246699e-05, 'epoch': 0.16}
{'loss': 0.9083, 'learning_rate': 1.9171789180542066e-05, 'epoch': 0.16}
{'loss': 0.9936, 'learning_rate': 1.9168682694308654e-05, 'epoch': 0.16}
{'loss': 0.8534, 'learning_rate': 1.9165570645651392e-05, 'epoch': 0.16}
{'loss': 0.9846, 'learning_rate': 1.9162453036458287e-05, 'epoch': 0.16}
{'loss': 0.9027, 'learning_rate': 1.9159329868620714e-05, 'epoch': 0.16}
{'loss': 0.8745, 'learning_rate': 1.915620114403343e-05, 'epoch': 0.16}
{'loss': 0.9065, 'learning_rate': 1.9153066864594558e-05, 'epoch': 0.16}
{'loss': 0.7893, 'learning_rate': 1.914992703220559e-05, 'epoch': 0.16}
{'loss': 0.8554, 'learning_rate': 1.9146781648771387e-05, 'epoch': 0.16}
{'loss': 0.9478, 'learning_rate': 1.9143630716200184e-05, 'epoch': 0.16}
{'loss': 0.8946, 'learning_rate': 1.914047423640357e-05, 'epoch': 0.16}
{'loss': 0.7558, 'learning_rate': 1.9137312211296516e-05, 'epoch': 0.16}
{'loss': 0.8081, 'learning_rate': 1.913414464279734e-05, 'epoch': 0.16}
{'loss': 0.8739, 'learning_rate': 1.9130971532827737e-05, 'epoch': 0.16}
{'loss': 0.9488, 'learning_rate': 1.9127792883312756e-05, 'epoch': 0.16}
{'loss': 0.901, 'learning_rate': 1.9124608696180806e-05, 'epoch': 0.16}
{'loss': 0.9351, 'learning_rate': 1.912141897336366e-05, 'epoch': 0.16}
{'loss': 0.8867, 'learning_rate': 1.9118223716796453e-05, 'epoch': 0.16}
{'loss': 0.9482, 'learning_rate': 1.9115022928417664e-05, 'epoch': 0.16}
{'loss': 0.8592, 'learning_rate': 1.911181661016914e-05, 'epoch': 0.16}
{'loss': 0.8146, 'learning_rate': 1.9108604763996084e-05, 'epoch': 0.16}
{'loss': 0.89, 'learning_rate': 1.9105387391847036e-05, 'epoch': 0.16}
{'loss': 0.9297, 'learning_rate': 1.9102164495673906e-05, 'epoch': 0.16}
{'loss': 0.7313, 'learning_rate': 1.9098936077431953e-05, 'epoch': 0.16}
{'loss': 0.9359, 'learning_rate': 1.9095702139079774e-05, 'epoch': 0.16}
{'loss': 0.8359, 'learning_rate': 1.909246268257933e-05, 'epoch': 0.16}
{'loss': 0.9526, 'learning_rate': 1.9089217709895918e-05, 'epoch': 0.16}
{'loss': 0.8904, 'learning_rate': 1.908596722299819e-05, 'epoch': 0.16}
{'loss': 0.9715, 'learning_rate': 1.9082711223858136e-05, 'epoch': 0.16}
{'loss': 0.8763, 'learning_rate': 1.90794497144511e-05, 'epoch': 0.16}
{'loss': 0.8104, 'learning_rate': 1.907618269675576e-05, 'epoch': 0.16}
{'loss': 0.9228, 'learning_rate': 1.9072910172754137e-05, 'epoch': 0.16}
{'loss': 0.9248, 'learning_rate': 1.9069632144431595e-05, 'epoch': 0.16}
{'loss': 0.8079, 'learning_rate': 1.906634861377684e-05, 'epoch': 0.16}
{'loss': 0.8971, 'learning_rate': 1.9063059582781905e-05, 'epoch': 0.16}
{'loss': 0.9106, 'learning_rate': 1.9059765053442176e-05, 'epoch': 0.16}
{'loss': 0.9511, 'learning_rate': 1.9056465027756362e-05, 'epoch': 0.17}
{'loss': 0.9582, 'learning_rate': 1.9053159507726514e-05, 'epoch': 0.17}
{'loss': 0.9539, 'learning_rate': 1.9049848495358006e-05, 'epoch': 0.17}
{'loss': 0.9336, 'learning_rate': 1.904653199265956e-05, 'epoch': 0.17}
{'loss': 0.9511, 'learning_rate': 1.9043210001643215e-05, 'epoch': 0.17}
{'loss': 0.9162, 'learning_rate': 1.9039882524324346e-05, 'epoch': 0.17}
{'loss': 0.8887, 'learning_rate': 1.9036549562721657e-05, 'epoch': 0.17}
{'loss': 0.814, 'learning_rate': 1.903321111885717e-05, 'epoch': 0.17}
{'loss': 0.8188, 'learning_rate': 1.9029867194756248e-05, 'epoch': 0.17}
{'loss': 0.8953, 'learning_rate': 1.902651779244757e-05, 'epoch': 0.17}
{'loss': 0.9112, 'learning_rate': 1.9023162913963136e-05, 'epoch': 0.17}
{'loss': 0.8944, 'learning_rate': 1.9019802561338278e-05, 'epoch': 0.17}
{'loss': 0.9316, 'learning_rate': 1.9016436736611637e-05, 'epoch': 0.17}
{'loss': 0.9298, 'learning_rate': 1.901306544182518e-05, 'epoch': 0.17}
[2025-12-09 13:05:52,156] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step3500 is about to be saved!
[2025-12-09 13:05:52,679] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3500/global_step3500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 13:05:52,679] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3500/global_step3500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 13:05:52,829] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3500/global_step3500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 13:05:52,832] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3500/global_step3500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 13:06:29,932] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3500/global_step3500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 13:06:29,935] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-3500/global_step3500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 13:06:33,242] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
{'loss': 0.9964, 'learning_rate': 1.900968867902419e-05, 'epoch': 0.17}
{'loss': 0.9156, 'learning_rate': 1.9006306450257278e-05, 'epoch': 0.17}
{'loss': 0.8591, 'learning_rate': 1.9002918757576358e-05, 'epoch': 0.17}
{'loss': 0.9574, 'learning_rate': 1.899952560303666e-05, 'epoch': 0.17}
{'loss': 0.8926, 'learning_rate': 1.899612698869673e-05, 'epoch': 0.17}
{'loss': 0.9741, 'learning_rate': 1.899272291661844e-05, 'epoch': 0.17}
{'loss': 0.8515, 'learning_rate': 1.8989313388866944e-05, 'epoch': 0.17}
{'loss': 0.9669, 'learning_rate': 1.898589840751073e-05, 'epoch': 0.17}
{'loss': 0.9123, 'learning_rate': 1.898247797462159e-05, 'epoch': 0.17}
{'loss': 0.7245, 'learning_rate': 1.8979052092274615e-05, 'epoch': 0.17}
{'loss': 0.922, 'learning_rate': 1.8975620762548207e-05, 'epoch': 0.17}
{'loss': 0.9106, 'learning_rate': 1.8972183987524076e-05, 'epoch': 0.17}
{'loss': 0.7989, 'learning_rate': 1.896874176928723e-05, 'epoch': 0.17}
{'loss': 0.9339, 'learning_rate': 1.8965294109925984e-05, 'epoch': 0.17}
{'loss': 0.9324, 'learning_rate': 1.8961841011531948e-05, 'epoch': 0.17}
{'loss': 0.8555, 'learning_rate': 1.8958382476200038e-05, 'epoch': 0.17}
{'loss': 0.9276, 'learning_rate': 1.8954918506028467e-05, 'epoch': 0.17}
{'loss': 0.8012, 'learning_rate': 1.8951449103118743e-05, 'epoch': 0.17}
{'loss': 0.9172, 'learning_rate': 1.894797426957567e-05, 'epoch': 0.17}
{'loss': 0.8801, 'learning_rate': 1.894449400750735e-05, 'epoch': 0.17}
{'loss': 0.9634, 'learning_rate': 1.8941008319025174e-05, 'epoch': 0.17}
{'loss': 0.9989, 'learning_rate': 1.8937517206243828e-05, 'epoch': 0.17}
{'loss': 0.9208, 'learning_rate': 1.8934020671281285e-05, 'epoch': 0.17}
{'loss': 0.9523, 'learning_rate': 1.8930518716258816e-05, 'epoch': 0.17}
{'loss': 0.7115, 'learning_rate': 1.892701134330097e-05, 'epoch': 0.17}
{'loss': 0.8435, 'learning_rate': 1.892349855453559e-05, 'epoch': 0.17}
{'loss': 0.8899, 'learning_rate': 1.8919980352093802e-05, 'epoch': 0.17}
{'loss': 0.7883, 'learning_rate': 1.8916456738110013e-05, 'epoch': 0.18}
{'loss': 0.7926, 'learning_rate': 1.8912927714721922e-05, 'epoch': 0.18}
{'loss': 0.8846, 'learning_rate': 1.89093932840705e-05, 'epoch': 0.18}
{'loss': 0.7572, 'learning_rate': 1.890585344830001e-05, 'epoch': 0.18}
{'loss': 0.8647, 'learning_rate': 1.8902308209557976e-05, 'epoch': 0.18}
{'loss': 0.9777, 'learning_rate': 1.8898757569995218e-05, 'epoch': 0.18}
{'loss': 0.9309, 'learning_rate': 1.889520153176583e-05, 'epoch': 0.18}
{'loss': 0.9141, 'learning_rate': 1.8891640097027163e-05, 'epoch': 0.18}
{'loss': 0.7562, 'learning_rate': 1.8888073267939865e-05, 'epoch': 0.18}
{'loss': 0.8934, 'learning_rate': 1.8884501046667847e-05, 'epoch': 0.18}
{'loss': 0.858, 'learning_rate': 1.888092343537829e-05, 'epoch': 0.18}
{'loss': 0.816, 'learning_rate': 1.8877340436241645e-05, 'epoch': 0.18}
{'loss': 0.7993, 'learning_rate': 1.8873752051431635e-05, 'epoch': 0.18}
{'loss': 0.8119, 'learning_rate': 1.887015828312525e-05, 'epoch': 0.18}
{'loss': 0.9294, 'learning_rate': 1.886655913350274e-05, 'epoch': 0.18}
{'loss': 0.8645, 'learning_rate': 1.886295460474763e-05, 'epoch': 0.18}
{'loss': 0.9226, 'learning_rate': 1.88593446990467e-05, 'epoch': 0.18}
{'loss': 0.9043, 'learning_rate': 1.8855729418589994e-05, 'epoch': 0.18}
{'loss': 0.8734, 'learning_rate': 1.8852108765570814e-05, 'epoch': 0.18}
{'loss': 0.9646, 'learning_rate': 1.8848482742185737e-05, 'epoch': 0.18}
{'loss': 0.8838, 'learning_rate': 1.8844851350634573e-05, 'epoch': 0.18}
{'loss': 0.7465, 'learning_rate': 1.8841214593120405e-05, 'epoch': 0.18}
{'loss': 0.894, 'learning_rate': 1.8837572471849574e-05, 'epoch': 0.18}
{'loss': 0.8347, 'learning_rate': 1.8833924989031663e-05, 'epoch': 0.18}
{'loss': 0.9225, 'learning_rate': 1.8830272146879513e-05, 'epoch': 0.18}
{'loss': 0.9507, 'learning_rate': 1.8826613947609225e-05, 'epoch': 0.18}
{'loss': 0.8376, 'learning_rate': 1.8822950393440135e-05, 'epoch': 0.18}
{'loss': 0.8093, 'learning_rate': 1.881928148659484e-05, 'epoch': 0.18}
{'loss': 0.918, 'learning_rate': 1.8815607229299177e-05, 'epoch': 0.18}
{'loss': 0.9644, 'learning_rate': 1.8811927623782227e-05, 'epoch': 0.18}
{'loss': 0.7179, 'learning_rate': 1.880824267227633e-05, 'epoch': 0.18}
{'loss': 0.8919, 'learning_rate': 1.880455237701705e-05, 'epoch': 0.18}
{'loss': 0.9904, 'learning_rate': 1.880085674024321e-05, 'epoch': 0.18}
{'loss': 0.921, 'learning_rate': 1.879715576419686e-05, 'epoch': 0.18}
{'loss': 0.8911, 'learning_rate': 1.8793449451123296e-05, 'epoch': 0.18}
{'loss': 0.8317, 'learning_rate': 1.878973780327105e-05, 'epoch': 0.18}
{'loss': 0.786, 'learning_rate': 1.8786020822891892e-05, 'epoch': 0.18}
{'loss': 0.9291, 'learning_rate': 1.878229851224083e-05, 'epoch': 0.18}
{'loss': 0.9057, 'learning_rate': 1.87785708735761e-05, 'epoch': 0.18}
{'loss': 0.943, 'learning_rate': 1.877483790915917e-05, 'epoch': 0.18}
{'loss': 0.9607, 'learning_rate': 1.8771099621254748e-05, 'epoch': 0.18}
{'loss': 0.899, 'learning_rate': 1.8767356012130758e-05, 'epoch': 0.18}
{'loss': 0.9545, 'learning_rate': 1.876360708405836e-05, 'epoch': 0.19}
{'loss': 0.9358, 'learning_rate': 1.8759852839311946e-05, 'epoch': 0.19}
{'loss': 0.9161, 'learning_rate': 1.8756093280169126e-05, 'epoch': 0.19}
{'loss': 0.9084, 'learning_rate': 1.8752328408910732e-05, 'epoch': 0.19}
{'loss': 0.8956, 'learning_rate': 1.8748558227820828e-05, 'epoch': 0.19}
{'loss': 0.9178, 'learning_rate': 1.8744782739186688e-05, 'epoch': 0.19}
{'loss': 0.8003, 'learning_rate': 1.8741001945298817e-05, 'epoch': 0.19}
{'loss': 0.9406, 'learning_rate': 1.8737215848450933e-05, 'epoch': 0.19}
{'loss': 0.843, 'learning_rate': 1.873342445093997e-05, 'epoch': 0.19}
{'loss': 0.7198, 'learning_rate': 1.8729627755066082e-05, 'epoch': 0.19}
{'loss': 0.8879, 'learning_rate': 1.872582576313263e-05, 'epoch': 0.19}
{'loss': 0.8211, 'learning_rate': 1.87220184774462e-05, 'epoch': 0.19}
{'loss': 0.9114, 'learning_rate': 1.8718205900316578e-05, 'epoch': 0.19}
{'loss': 0.8105, 'learning_rate': 1.8714388034056764e-05, 'epoch': 0.19}
{'loss': 0.9195, 'learning_rate': 1.8710564880982975e-05, 'epoch': 0.19}
{'loss': 0.9263, 'learning_rate': 1.8706736443414616e-05, 'epoch': 0.19}
{'loss': 0.9272, 'learning_rate': 1.8702902723674317e-05, 'epoch': 0.19}
{'loss': 0.9275, 'learning_rate': 1.8699063724087905e-05, 'epoch': 0.19}
{'loss': 0.9014, 'learning_rate': 1.869521944698441e-05, 'epoch': 0.19}
{'loss': 0.8654, 'learning_rate': 1.8691369894696064e-05, 'epoch': 0.19}
{'loss': 0.7332, 'learning_rate': 1.8687515069558303e-05, 'epoch': 0.19}
{'loss': 0.9322, 'learning_rate': 1.8683654973909754e-05, 'epoch': 0.19}
{'loss': 0.7524, 'learning_rate': 1.867978961009225e-05, 'epoch': 0.19}
{'loss': 0.8665, 'learning_rate': 1.8675918980450812e-05, 'epoch': 0.19}
{'loss': 0.8188, 'learning_rate': 1.8672043087333662e-05, 'epoch': 0.19}
{'loss': 0.914, 'learning_rate': 1.8668161933092218e-05, 'epoch': 0.19}
{'loss': 1.0024, 'learning_rate': 1.866427552008107e-05, 'epoch': 0.19}
{'loss': 0.962, 'learning_rate': 1.8660383850658033e-05, 'epoch': 0.19}
{'loss': 0.9224, 'learning_rate': 1.865648692718408e-05, 'epoch': 0.19}
{'loss': 0.8791, 'learning_rate': 1.865258475202338e-05, 'epoch': 0.19}
{'loss': 0.8085, 'learning_rate': 1.8648677327543297e-05, 'epoch': 0.19}
[2025-12-09 13:31:43,782] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step4000 is about to be saved!
[2025-12-09 13:31:44,319] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4000/global_step4000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 13:31:44,320] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4000/global_step4000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 13:31:44,473] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4000/global_step4000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 13:31:44,476] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4000/global_step4000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 13:32:23,767] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4000/global_step4000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 13:32:23,770] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4000/global_step4000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 13:32:30,559] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
{'loss': 0.937, 'learning_rate': 1.864476465611437e-05, 'epoch': 0.19}
{'loss': 0.9028, 'learning_rate': 1.8640846740110327e-05, 'epoch': 0.19}
{'loss': 0.8982, 'learning_rate': 1.8636923581908074e-05, 'epoch': 0.19}
{'loss': 0.9472, 'learning_rate': 1.8632995183887697e-05, 'epoch': 0.19}
{'loss': 0.9379, 'learning_rate': 1.862906154843247e-05, 'epoch': 0.19}
{'loss': 0.9859, 'learning_rate': 1.862512267792883e-05, 'epoch': 0.19}
{'loss': 0.8645, 'learning_rate': 1.8621178574766397e-05, 'epoch': 0.19}
{'loss': 0.7806, 'learning_rate': 1.8617229241337967e-05, 'epoch': 0.19}
{'loss': 0.8616, 'learning_rate': 1.8613274680039506e-05, 'epoch': 0.19}
{'loss': 0.9137, 'learning_rate': 1.8609314893270155e-05, 'epoch': 0.19}
{'loss': 0.8053, 'learning_rate': 1.8605349883432223e-05, 'epoch': 0.2}
{'loss': 0.7568, 'learning_rate': 1.860137965293119e-05, 'epoch': 0.2}
{'loss': 0.8554, 'learning_rate': 1.85974042041757e-05, 'epoch': 0.2}
{'loss': 0.9384, 'learning_rate': 1.8593423539577565e-05, 'epoch': 0.2}
{'loss': 0.8359, 'learning_rate': 1.8589437661551756e-05, 'epoch': 0.2}
{'loss': 0.8173, 'learning_rate': 1.8585446572516416e-05, 'epoch': 0.2}
{'loss': 0.9636, 'learning_rate': 1.8581450274892842e-05, 'epoch': 0.2}
{'loss': 0.9069, 'learning_rate': 1.8577448771105494e-05, 'epoch': 0.2}
{'loss': 0.9358, 'learning_rate': 1.857344206358199e-05, 'epoch': 0.2}
{'loss': 0.9536, 'learning_rate': 1.856943015475311e-05, 'epoch': 0.2}
{'loss': 0.8504, 'learning_rate': 1.8565413047052778e-05, 'epoch': 0.2}
{'loss': 0.8476, 'learning_rate': 1.856139074291808e-05, 'epoch': 0.2}
{'loss': 0.8886, 'learning_rate': 1.855736324478926e-05, 'epoch': 0.2}
{'loss': 0.9477, 'learning_rate': 1.8553330555109696e-05, 'epoch': 0.2}
{'loss': 0.9222, 'learning_rate': 1.8549292676325935e-05, 'epoch': 0.2}
{'loss': 0.8836, 'learning_rate': 1.8545249610887653e-05, 'epoch': 0.2}
{'loss': 0.8839, 'learning_rate': 1.854120136124769e-05, 'epoch': 0.2}
{'loss': 0.8796, 'learning_rate': 1.8537147929862023e-05, 'epoch': 0.2}
{'loss': 0.9334, 'learning_rate': 1.853308931918977e-05, 'epoch': 0.2}
{'loss': 0.9098, 'learning_rate': 1.85290255316932e-05, 'epoch': 0.2}
{'loss': 0.9382, 'learning_rate': 1.852495656983771e-05, 'epoch': 0.2}
{'loss': 0.9582, 'learning_rate': 1.852088243609185e-05, 'epoch': 0.2}
{'loss': 0.9238, 'learning_rate': 1.8516803132927296e-05, 'epoch': 0.2}
{'loss': 0.9697, 'learning_rate': 1.851271866281887e-05, 'epoch': 0.2}
{'loss': 0.9234, 'learning_rate': 1.850862902824452e-05, 'epoch': 0.2}
{'loss': 0.8874, 'learning_rate': 1.8504534231685332e-05, 'epoch': 0.2}
{'loss': 0.8129, 'learning_rate': 1.850043427562552e-05, 'epoch': 0.2}
{'loss': 0.9076, 'learning_rate': 1.8496329162552437e-05, 'epoch': 0.2}
{'loss': 0.9461, 'learning_rate': 1.8492218894956555e-05, 'epoch': 0.2}
{'loss': 0.8829, 'learning_rate': 1.8488103475331476e-05, 'epoch': 0.2}
{'loss': 0.9318, 'learning_rate': 1.8483982906173928e-05, 'epoch': 0.2}
{'loss': 0.8969, 'learning_rate': 1.8479857189983762e-05, 'epoch': 0.2}
{'loss': 0.8051, 'learning_rate': 1.8475726329263958e-05, 'epoch': 0.2}
{'loss': 0.8767, 'learning_rate': 1.8471590326520607e-05, 'epoch': 0.2}
{'loss': 0.9351, 'learning_rate': 1.8467449184262927e-05, 'epoch': 0.2}
{'loss': 0.9469, 'learning_rate': 1.8463302905003247e-05, 'epoch': 0.2}
{'loss': 0.8637, 'learning_rate': 1.845915149125703e-05, 'epoch': 0.2}
{'loss': 0.9002, 'learning_rate': 1.845499494554282e-05, 'epoch': 0.2}
{'loss': 0.9672, 'learning_rate': 1.8450833270382312e-05, 'epoch': 0.2}
{'loss': 0.8466, 'learning_rate': 1.8446666468300292e-05, 'epoch': 0.2}
{'loss': 0.8953, 'learning_rate': 1.844249454182466e-05, 'epoch': 0.2}
{'loss': 0.9414, 'learning_rate': 1.8438317493486426e-05, 'epoch': 0.2}
{'loss': 0.9007, 'learning_rate': 1.8434135325819703e-05, 'epoch': 0.21}
{'loss': 0.8545, 'learning_rate': 1.842994804136172e-05, 'epoch': 0.21}
{'loss': 0.8806, 'learning_rate': 1.8425755642652797e-05, 'epoch': 0.21}
{'loss': 0.7787, 'learning_rate': 1.842155813223637e-05, 'epoch': 0.21}
{'loss': 0.8755, 'learning_rate': 1.841735551265897e-05, 'epoch': 0.21}
{'loss': 0.8681, 'learning_rate': 1.8413147786470217e-05, 'epoch': 0.21}
{'loss': 0.8886, 'learning_rate': 1.8408934956222855e-05, 'epoch': 0.21}
{'loss': 0.8309, 'learning_rate': 1.8404717024472696e-05, 'epoch': 0.21}
{'loss': 0.8932, 'learning_rate': 1.8400493993778666e-05, 'epoch': 0.21}
{'loss': 0.898, 'learning_rate': 1.8396265866702773e-05, 'epoch': 0.21}
{'loss': 0.8142, 'learning_rate': 1.839203264581013e-05, 'epoch': 0.21}
{'loss': 0.819, 'learning_rate': 1.8387794333668928e-05, 'epoch': 0.21}
{'loss': 0.8145, 'learning_rate': 1.838355093285045e-05, 'epoch': 0.21}
{'loss': 0.8585, 'learning_rate': 1.8379302445929068e-05, 'epoch': 0.21}
{'loss': 0.8947, 'learning_rate': 1.837504887548224e-05, 'epoch': 0.21}
{'loss': 0.9035, 'learning_rate': 1.8370790224090508e-05, 'epoch': 0.21}
{'loss': 0.9001, 'learning_rate': 1.8366526494337497e-05, 'epoch': 0.21}
{'loss': 0.8176, 'learning_rate': 1.8362257688809904e-05, 'epoch': 0.21}
{'loss': 0.8801, 'learning_rate': 1.835798381009752e-05, 'epoch': 0.21}
{'loss': 0.8294, 'learning_rate': 1.8353704860793202e-05, 'epoch': 0.21}
{'loss': 0.9553, 'learning_rate': 1.834942084349289e-05, 'epoch': 0.21}
{'loss': 0.779, 'learning_rate': 1.8345131760795598e-05, 'epoch': 0.21}
{'loss': 0.8803, 'learning_rate': 1.8340837615303405e-05, 'epoch': 0.21}
{'loss': 0.9381, 'learning_rate': 1.8336538409621474e-05, 'epoch': 0.21}
{'loss': 0.8975, 'learning_rate': 1.8332234146358034e-05, 'epoch': 0.21}
{'loss': 0.9307, 'learning_rate': 1.8327924828124377e-05, 'epoch': 0.21}
{'loss': 0.7707, 'learning_rate': 1.832361045753486e-05, 'epoch': 0.21}
{'loss': 0.9191, 'learning_rate': 1.831929103720692e-05, 'epoch': 0.21}
{'loss': 0.9111, 'learning_rate': 1.831496656976104e-05, 'epoch': 0.21}
{'loss': 0.893, 'learning_rate': 1.831063705782077e-05, 'epoch': 0.21}
{'loss': 0.8352, 'learning_rate': 1.8306302504012732e-05, 'epoch': 0.21}
{'loss': 0.9487, 'learning_rate': 1.8301962910966592e-05, 'epoch': 0.21}
{'loss': 0.8992, 'learning_rate': 1.829761828131508e-05, 'epoch': 0.21}
{'loss': 0.8624, 'learning_rate': 1.829326861769398e-05, 'epoch': 0.21}
{'loss': 0.8949, 'learning_rate': 1.8288913922742134e-05, 'epoch': 0.21}
{'loss': 0.9572, 'learning_rate': 1.828455419910143e-05, 'epoch': 0.21}
{'loss': 0.6462, 'learning_rate': 1.8280189449416805e-05, 'epoch': 0.21}
{'loss': 0.7528, 'learning_rate': 1.8275819676336256e-05, 'epoch': 0.21}
{'loss': 0.8134, 'learning_rate': 1.827144488251082e-05, 'epoch': 0.21}
{'loss': 0.9516, 'learning_rate': 1.826706507059458e-05, 'epoch': 0.21}
{'loss': 0.7174, 'learning_rate': 1.826268024324467e-05, 'epoch': 0.21}
{'loss': 0.803, 'learning_rate': 1.8258290403121252e-05, 'epoch': 0.21}
{'loss': 0.8599, 'learning_rate': 1.8253895552887547e-05, 'epoch': 0.22}
{'loss': 0.8584, 'learning_rate': 1.8249495695209805e-05, 'epoch': 0.22}
{'loss': 0.9442, 'learning_rate': 1.8245090832757317e-05, 'epoch': 0.22}
{'loss': 0.9154, 'learning_rate': 1.82406809682024e-05, 'epoch': 0.22}
{'loss': 0.8594, 'learning_rate': 1.8236266104220432e-05, 'epoch': 0.22}
{'loss': 0.8613, 'learning_rate': 1.823184624348979e-05, 'epoch': 0.22}
[2025-12-09 13:57:07,879] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step4500 is about to be saved!
[2025-12-09 13:57:07,971] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4500/global_step4500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 13:57:07,972] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4500/global_step4500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 13:57:08,647] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4500/global_step4500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 13:57:08,655] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4500/global_step4500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 13:57:48,172] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4500/global_step4500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 13:57:48,178] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-4500/global_step4500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 13:57:49,855] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4500 is ready now!
{'loss': 0.8695, 'learning_rate': 1.8227421388691912e-05, 'epoch': 0.22}
{'loss': 0.8931, 'learning_rate': 1.8222991542511247e-05, 'epoch': 0.22}
{'loss': 0.8692, 'learning_rate': 1.8218556707635277e-05, 'epoch': 0.22}
{'loss': 0.8904, 'learning_rate': 1.8214116886754513e-05, 'epoch': 0.22}
{'loss': 0.9373, 'learning_rate': 1.8209672082562496e-05, 'epoch': 0.22}
{'loss': 0.9253, 'learning_rate': 1.8205222297755774e-05, 'epoch': 0.22}
{'loss': 0.9434, 'learning_rate': 1.8200767535033938e-05, 'epoch': 0.22}
{'loss': 0.9802, 'learning_rate': 1.819630779709958e-05, 'epoch': 0.22}
{'loss': 0.9016, 'learning_rate': 1.8191843086658313e-05, 'epoch': 0.22}
{'loss': 0.8454, 'learning_rate': 1.8187373406418782e-05, 'epoch': 0.22}
{'loss': 0.9029, 'learning_rate': 1.818289875909263e-05, 'epoch': 0.22}
{'loss': 0.8942, 'learning_rate': 1.8178419147394528e-05, 'epoch': 0.22}
{'loss': 0.9078, 'learning_rate': 1.817393457404214e-05, 'epoch': 0.22}
{'loss': 0.9113, 'learning_rate': 1.8169445041756165e-05, 'epoch': 0.22}
{'loss': 0.9735, 'learning_rate': 1.816495055326028e-05, 'epoch': 0.22}
{'loss': 0.852, 'learning_rate': 1.8160451111281202e-05, 'epoch': 0.22}
{'loss': 0.8817, 'learning_rate': 1.815594671854862e-05, 'epoch': 0.22}
{'loss': 0.8812, 'learning_rate': 1.8151437377795256e-05, 'epoch': 0.22}
{'loss': 0.9656, 'learning_rate': 1.8146923091756813e-05, 'epoch': 0.22}
{'loss': 0.9012, 'learning_rate': 1.8142403863172007e-05, 'epoch': 0.22}
{'loss': 0.7524, 'learning_rate': 1.8137879694782543e-05, 'epoch': 0.22}
{'loss': 0.8404, 'learning_rate': 1.8133350589333136e-05, 'epoch': 0.22}
{'loss': 0.9157, 'learning_rate': 1.8128816549571472e-05, 'epoch': 0.22}
{'loss': 0.8678, 'learning_rate': 1.812427757824826e-05, 'epoch': 0.22}
{'loss': 0.946, 'learning_rate': 1.8119733678117185e-05, 'epoch': 0.22}
{'loss': 0.8744, 'learning_rate': 1.8115184851934922e-05, 'epoch': 0.22}
{'loss': 0.844, 'learning_rate': 1.8110631102461134e-05, 'epoch': 0.22}
{'loss': 0.8439, 'learning_rate': 1.8106072432458478e-05, 'epoch': 0.22}
{'loss': 0.9095, 'learning_rate': 1.8101508844692586e-05, 'epoch': 0.22}
{'loss': 0.9211, 'learning_rate': 1.809694034193209e-05, 'epoch': 0.22}
{'loss': 0.8889, 'learning_rate': 1.8092366926948578e-05, 'epoch': 0.22}
{'loss': 0.7981, 'learning_rate': 1.8087788602516643e-05, 'epoch': 0.22}
{'loss': 0.8852, 'learning_rate': 1.808320537141385e-05, 'epoch': 0.22}
{'loss': 0.9501, 'learning_rate': 1.807861723642073e-05, 'epoch': 0.22}
{'loss': 0.8843, 'learning_rate': 1.8074024200320797e-05, 'epoch': 0.22}
{'loss': 0.8649, 'learning_rate': 1.806942626590054e-05, 'epoch': 0.23}
{'loss': 0.8426, 'learning_rate': 1.806482343594942e-05, 'epoch': 0.23}
{'loss': 0.8534, 'learning_rate': 1.8060215713259856e-05, 'epoch': 0.23}
{'loss': 0.7888, 'learning_rate': 1.805560310062726e-05, 'epoch': 0.23}
{'loss': 0.872, 'learning_rate': 1.805098560084998e-05, 'epoch': 0.23}
{'loss': 0.8752, 'learning_rate': 1.8046363216729354e-05, 'epoch': 0.23}
{'loss': 0.9426, 'learning_rate': 1.804173595106967e-05, 'epoch': 0.23}
{'loss': 0.7985, 'learning_rate': 1.803710380667818e-05, 'epoch': 0.23}
{'loss': 0.9587, 'learning_rate': 1.8032466786365098e-05, 'epoch': 0.23}
{'loss': 0.955, 'learning_rate': 1.80278248929436e-05, 'epoch': 0.23}
{'loss': 0.7834, 'learning_rate': 1.8023178129229808e-05, 'epoch': 0.23}
{'loss': 0.8231, 'learning_rate': 1.8018526498042805e-05, 'epoch': 0.23}
{'loss': 0.9765, 'learning_rate': 1.8013870002204625e-05, 'epoch': 0.23}
{'loss': 0.8516, 'learning_rate': 1.800920864454026e-05, 'epoch': 0.23}
{'loss': 0.9638, 'learning_rate': 1.8004542427877635e-05, 'epoch': 0.23}
{'loss': 0.8255, 'learning_rate': 1.7999871355047647e-05, 'epoch': 0.23}
{'loss': 0.8445, 'learning_rate': 1.7995195428884114e-05, 'epoch': 0.23}
{'loss': 0.8281, 'learning_rate': 1.7990514652223818e-05, 'epoch': 0.23}
{'loss': 0.9174, 'learning_rate': 1.7985829027906475e-05, 'epoch': 0.23}
{'loss': 0.8246, 'learning_rate': 1.7981138558774737e-05, 'epoch': 0.23}
{'loss': 0.8801, 'learning_rate': 1.797644324767421e-05, 'epoch': 0.23}
{'loss': 0.8275, 'learning_rate': 1.797174309745342e-05, 'epoch': 0.23}
{'loss': 0.9553, 'learning_rate': 1.7967038110963847e-05, 'epoch': 0.23}
{'loss': 0.7547, 'learning_rate': 1.7962328291059886e-05, 'epoch': 0.23}
{'loss': 0.8791, 'learning_rate': 1.795761364059888e-05, 'epoch': 0.23}
{'loss': 0.9329, 'learning_rate': 1.7952894162441094e-05, 'epoch': 0.23}
{'loss': 0.8655, 'learning_rate': 1.7948169859449726e-05, 'epoch': 0.23}
{'loss': 0.807, 'learning_rate': 1.7943440734490893e-05, 'epoch': 0.23}
{'loss': 0.9254, 'learning_rate': 1.7938706790433655e-05, 'epoch': 0.23}
{'loss': 0.9064, 'learning_rate': 1.7933968030149972e-05, 'epoch': 0.23}
{'loss': 0.767, 'learning_rate': 1.792922445651475e-05, 'epoch': 0.23}
{'loss': 0.9018, 'learning_rate': 1.7924476072405795e-05, 'epoch': 0.23}
{'loss': 0.8433, 'learning_rate': 1.7919722880703843e-05, 'epoch': 0.23}
{'loss': 0.9072, 'learning_rate': 1.7914964884292543e-05, 'epoch': 0.23}
{'loss': 0.852, 'learning_rate': 1.7910202086058458e-05, 'epoch': 0.23}
{'loss': 0.7463, 'learning_rate': 1.790543448889107e-05, 'epoch': 0.23}
{'loss': 0.8756, 'learning_rate': 1.7900662095682762e-05, 'epoch': 0.23}
{'loss': 0.8995, 'learning_rate': 1.7895884909328835e-05, 'epoch': 0.23}
{'loss': 0.914, 'learning_rate': 1.78911029327275e-05, 'epoch': 0.23}
{'loss': 0.9165, 'learning_rate': 1.7886316168779862e-05, 'epoch': 0.23}
{'loss': 0.8735, 'learning_rate': 1.788152462038994e-05, 'epoch': 0.23}
{'loss': 0.9391, 'learning_rate': 1.7876728290464658e-05, 'epoch': 0.23}
{'loss': 0.9027, 'learning_rate': 1.7871927181913832e-05, 'epoch': 0.24}
{'loss': 0.8641, 'learning_rate': 1.7867121297650184e-05, 'epoch': 0.24}
{'loss': 0.9477, 'learning_rate': 1.7862310640589328e-05, 'epoch': 0.24}
{'loss': 0.9278, 'learning_rate': 1.785749521364978e-05, 'epoch': 0.24}
{'loss': 0.8365, 'learning_rate': 1.785267501975294e-05, 'epoch': 0.24}
{'loss': 0.8812, 'learning_rate': 1.784785006182311e-05, 'epoch': 0.24}
{'loss': 0.9234, 'learning_rate': 1.784302034278748e-05, 'epoch': 0.24}
{'loss': 0.8905, 'learning_rate': 1.783818586557613e-05, 'epoch': 0.24}
{'loss': 0.8859, 'learning_rate': 1.7833346633122013e-05, 'epoch': 0.24}
{'loss': 0.933, 'learning_rate': 1.782850264836099e-05, 'epoch': 0.24}
{'loss': 0.8239, 'learning_rate': 1.782365391423178e-05, 'epoch': 0.24}
{'loss': 0.89, 'learning_rate': 1.7818800433676e-05, 'epoch': 0.24}
{'loss': 0.81, 'learning_rate': 1.7813942209638148e-05, 'epoch': 0.24}
{'loss': 0.8649, 'learning_rate': 1.7809079245065586e-05, 'epoch': 0.24}
{'loss': 0.7464, 'learning_rate': 1.7804211542908568e-05, 'epoch': 0.24}
{'loss': 0.8865, 'learning_rate': 1.7799339106120205e-05, 'epoch': 0.24}
{'loss': 0.9408, 'learning_rate': 1.77944619376565e-05, 'epoch': 0.24}
{'loss': 0.8616, 'learning_rate': 1.7789580040476305e-05, 'epoch': 0.24}
{'loss': 0.8849, 'learning_rate': 1.7784693417541364e-05, 'epoch': 0.24}
{'loss': 0.9082, 'learning_rate': 1.777980207181627e-05, 'epoch': 0.24}
{'loss': 0.7893, 'learning_rate': 1.7774906006268482e-05, 'epoch': 0.24}
{'loss': 0.7944, 'learning_rate': 1.7770005223868336e-05, 'epoch': 0.24}
{'loss': 0.951, 'learning_rate': 1.776509972758902e-05, 'epoch': 0.24}
[2025-12-09 14:22:13,773] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step5000 is about to be saved!
[2025-12-09 14:22:13,864] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5000/global_step5000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 14:22:13,865] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5000/global_step5000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 14:22:14,468] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5000/global_step5000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 14:22:14,476] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5000/global_step5000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 14:23:00,074] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5000/global_step5000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 14:23:00,077] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5000/global_step5000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 14:23:05,279] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5000 is ready now!
{'loss': 0.8541, 'learning_rate': 1.776018952040658e-05, 'epoch': 0.24}
{'loss': 0.7343, 'learning_rate': 1.7755274605299924e-05, 'epoch': 0.24}
{'loss': 0.8462, 'learning_rate': 1.7750354985250817e-05, 'epoch': 0.24}
{'loss': 0.8859, 'learning_rate': 1.7745430663243874e-05, 'epoch': 0.24}
{'loss': 0.9334, 'learning_rate': 1.7740501642266568e-05, 'epoch': 0.24}
{'loss': 0.8241, 'learning_rate': 1.7735567925309217e-05, 'epoch': 0.24}
{'loss': 0.7462, 'learning_rate': 1.773062951536499e-05, 'epoch': 0.24}
{'loss': 0.8468, 'learning_rate': 1.772568641542991e-05, 'epoch': 0.24}
{'loss': 0.912, 'learning_rate': 1.7720738628502836e-05, 'epoch': 0.24}
{'loss': 0.802, 'learning_rate': 1.771578615758547e-05, 'epoch': 0.24}
{'loss': 0.8309, 'learning_rate': 1.7710829005682364e-05, 'epoch': 0.24}
{'loss': 0.8396, 'learning_rate': 1.7705867175800905e-05, 'epoch': 0.24}
{'loss': 0.7652, 'learning_rate': 1.7700900670951317e-05, 'epoch': 0.24}
{'loss': 0.9028, 'learning_rate': 1.7695929494146662e-05, 'epoch': 0.24}
{'loss': 0.9237, 'learning_rate': 1.7690953648402835e-05, 'epoch': 0.24}
{'loss': 0.8827, 'learning_rate': 1.7685973136738568e-05, 'epoch': 0.24}
{'loss': 0.8604, 'learning_rate': 1.7680987962175415e-05, 'epoch': 0.24}
{'loss': 0.8695, 'learning_rate': 1.767599812773777e-05, 'epoch': 0.24}
{'loss': 0.8851, 'learning_rate': 1.767100363645284e-05, 'epoch': 0.25}
{'loss': 0.7571, 'learning_rate': 1.766600449135067e-05, 'epoch': 0.25}
{'loss': 0.8916, 'learning_rate': 1.7661000695464125e-05, 'epoch': 0.25}
{'loss': 0.9169, 'learning_rate': 1.765599225182889e-05, 'epoch': 0.25}
{'loss': 0.8974, 'learning_rate': 1.7650979163483464e-05, 'epoch': 0.25}
{'loss': 0.8666, 'learning_rate': 1.764596143346918e-05, 'epoch': 0.25}
{'loss': 0.8885, 'learning_rate': 1.7640939064830166e-05, 'epoch': 0.25}
{'loss': 0.8443, 'learning_rate': 1.7635912060613377e-05, 'epoch': 0.25}
{'loss': 0.9335, 'learning_rate': 1.7630880423868585e-05, 'epoch': 0.25}
{'loss': 0.7261, 'learning_rate': 1.762584415764836e-05, 'epoch': 0.25}
{'loss': 0.9056, 'learning_rate': 1.7620803265008085e-05, 'epoch': 0.25}
{'loss': 0.9335, 'learning_rate': 1.7615757749005954e-05, 'epoch': 0.25}
{'loss': 0.9377, 'learning_rate': 1.7610707612702963e-05, 'epoch': 0.25}
{'loss': 0.7058, 'learning_rate': 1.7605652859162908e-05, 'epoch': 0.25}
{'loss': 0.9089, 'learning_rate': 1.760059349145239e-05, 'epoch': 0.25}
{'loss': 0.9494, 'learning_rate': 1.7595529512640807e-05, 'epoch': 0.25}
{'loss': 0.8911, 'learning_rate': 1.7590460925800358e-05, 'epoch': 0.25}
{'loss': 0.7812, 'learning_rate': 1.7585387734006033e-05, 'epoch': 0.25}
{'loss': 0.7179, 'learning_rate': 1.758030994033562e-05, 'epoch': 0.25}
{'loss': 0.8768, 'learning_rate': 1.75752275478697e-05, 'epoch': 0.25}
{'loss': 0.8836, 'learning_rate': 1.7570140559691635e-05, 'epoch': 0.25}
{'loss': 0.8772, 'learning_rate': 1.756504897888758e-05, 'epoch': 0.25}
{'loss': 0.7755, 'learning_rate': 1.755995280854648e-05, 'epoch': 0.25}
{'loss': 0.8227, 'learning_rate': 1.7554852051760068e-05, 'epoch': 0.25}
{'loss': 0.8103, 'learning_rate': 1.754974671162284e-05, 'epoch': 0.25}
{'loss': 0.8954, 'learning_rate': 1.7544636791232094e-05, 'epoch': 0.25}
{'loss': 0.8937, 'learning_rate': 1.75395222936879e-05, 'epoch': 0.25}
{'loss': 0.8766, 'learning_rate': 1.7534403222093093e-05, 'epoch': 0.25}
{'loss': 0.7691, 'learning_rate': 1.7529279579553303e-05, 'epoch': 0.25}
{'loss': 0.8101, 'learning_rate': 1.752415136917692e-05, 'epoch': 0.25}
{'loss': 0.8733, 'learning_rate': 1.751901859407511e-05, 'epoch': 0.25}
{'loss': 0.8914, 'learning_rate': 1.7513881257361806e-05, 'epoch': 0.25}
{'loss': 0.9426, 'learning_rate': 1.7508739362153708e-05, 'epoch': 0.25}
{'loss': 0.8017, 'learning_rate': 1.7503592911570283e-05, 'epoch': 0.25}
{'loss': 0.8967, 'learning_rate': 1.749844190873376e-05, 'epoch': 0.25}
{'loss': 0.8375, 'learning_rate': 1.7493286356769135e-05, 'epoch': 0.25}
{'loss': 0.7861, 'learning_rate': 1.748812625880416e-05, 'epoch': 0.25}
{'loss': 0.9258, 'learning_rate': 1.7482961617969338e-05, 'epoch': 0.25}
{'loss': 0.9509, 'learning_rate': 1.747779243739794e-05, 'epoch': 0.25}
{'loss': 0.897, 'learning_rate': 1.7472618720225988e-05, 'epoch': 0.25}
{'loss': 0.9467, 'learning_rate': 1.7467440469592248e-05, 'epoch': 0.25}
{'loss': 0.8719, 'learning_rate': 1.746225768863825e-05, 'epoch': 0.25}
{'loss': 0.8263, 'learning_rate': 1.745707038050826e-05, 'epoch': 0.26}
{'loss': 0.904, 'learning_rate': 1.74518785483493e-05, 'epoch': 0.26}
{'loss': 0.9427, 'learning_rate': 1.7446682195311128e-05, 'epoch': 0.26}
{'loss': 0.6737, 'learning_rate': 1.7441481324546254e-05, 'epoch': 0.26}
{'loss': 0.8495, 'learning_rate': 1.7436275939209918e-05, 'epoch': 0.26}
{'loss': 0.9447, 'learning_rate': 1.743106604246011e-05, 'epoch': 0.26}
{'loss': 0.9492, 'learning_rate': 1.7425851637457546e-05, 'epoch': 0.26}
{'loss': 0.873, 'learning_rate': 1.7420632727365686e-05, 'epoch': 0.26}
{'loss': 0.8187, 'learning_rate': 1.741540931535072e-05, 'epoch': 0.26}
{'loss': 0.9057, 'learning_rate': 1.7410181404581567e-05, 'epoch': 0.26}
{'loss': 0.8018, 'learning_rate': 1.740494899822988e-05, 'epoch': 0.26}
{'loss': 0.877, 'learning_rate': 1.7399712099470042e-05, 'epoch': 0.26}
{'loss': 0.854, 'learning_rate': 1.739447071147914e-05, 'epoch': 0.26}
{'loss': 0.935, 'learning_rate': 1.7389224837437018e-05, 'epoch': 0.26}
{'loss': 0.8883, 'learning_rate': 1.7383974480526213e-05, 'epoch': 0.26}
{'loss': 0.9713, 'learning_rate': 1.7378719643932e-05, 'epoch': 0.26}
{'loss': 0.9332, 'learning_rate': 1.7373460330842354e-05, 'epoch': 0.26}
{'loss': 0.8887, 'learning_rate': 1.7368196544447987e-05, 'epoch': 0.26}
{'loss': 0.6248, 'learning_rate': 1.7362928287942314e-05, 'epoch': 0.26}
{'loss': 0.8931, 'learning_rate': 1.7357655564521457e-05, 'epoch': 0.26}
{'loss': 0.9374, 'learning_rate': 1.7352378377384254e-05, 'epoch': 0.26}
{'loss': 0.9067, 'learning_rate': 1.734709672973225e-05, 'epoch': 0.26}
{'loss': 0.8868, 'learning_rate': 1.73418106247697e-05, 'epoch': 0.26}
{'loss': 0.9019, 'learning_rate': 1.7336520065703557e-05, 'epoch': 0.26}
{'loss': 0.9011, 'learning_rate': 1.7331225055743478e-05, 'epoch': 0.26}
{'loss': 0.8545, 'learning_rate': 1.7325925598101817e-05, 'epoch': 0.26}
{'loss': 0.8607, 'learning_rate': 1.732062169599364e-05, 'epoch': 0.26}
{'loss': 0.8837, 'learning_rate': 1.731531335263669e-05, 'epoch': 0.26}
{'loss': 0.9187, 'learning_rate': 1.731000057125142e-05, 'epoch': 0.26}
{'loss': 0.8786, 'learning_rate': 1.7304683355060966e-05, 'epoch': 0.26}
{'loss': 0.6543, 'learning_rate': 1.729936170729116e-05, 'epoch': 0.26}
{'loss': 0.8446, 'learning_rate': 1.729403563117052e-05, 'epoch': 0.26}
{'loss': 0.8185, 'learning_rate': 1.728870512993025e-05, 'epoch': 0.26}
{'loss': 0.7856, 'learning_rate': 1.728337020680424e-05, 'epoch': 0.26}
{'loss': 0.8726, 'learning_rate': 1.7278030865029062e-05, 'epoch': 0.26}
{'loss': 0.9418, 'learning_rate': 1.7272687107843966e-05, 'epoch': 0.26}
{'loss': 0.9271, 'learning_rate': 1.726733893849089e-05, 'epoch': 0.26}
{'loss': 0.8624, 'learning_rate': 1.7261986360214435e-05, 'epoch': 0.26}
{'loss': 0.8753, 'learning_rate': 1.725662937626189e-05, 'epoch': 0.26}
{'loss': 0.8952, 'learning_rate': 1.7251267989883212e-05, 'epoch': 0.26}
[2025-12-09 14:56:09,558] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step5500 is about to be saved!
[2025-12-09 14:56:09,649] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5500/global_step5500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 14:56:09,650] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5500/global_step5500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 14:56:10,313] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5500/global_step5500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 14:56:10,320] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5500/global_step5500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 14:56:56,282] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5500/global_step5500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 14:56:56,286] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-5500/global_step5500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 14:56:57,389] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step5500 is ready now!
{'loss': 0.9014, 'learning_rate': 1.724590220433102e-05, 'epoch': 0.26}
{'loss': 0.8769, 'learning_rate': 1.724053202286062e-05, 'epoch': 0.27}
{'loss': 0.7753, 'learning_rate': 1.7235157448729967e-05, 'epoch': 0.27}
{'loss': 0.8613, 'learning_rate': 1.722977848519969e-05, 'epoch': 0.27}
{'loss': 0.7848, 'learning_rate': 1.722439513553308e-05, 'epoch': 0.27}
{'loss': 0.8645, 'learning_rate': 1.7219007402996092e-05, 'epoch': 0.27}
{'loss': 0.7896, 'learning_rate': 1.7213615290857326e-05, 'epoch': 0.27}
{'loss': 0.7902, 'learning_rate': 1.7208218802388065e-05, 'epoch': 0.27}
{'loss': 0.8668, 'learning_rate': 1.7202817940862216e-05, 'epoch': 0.27}
{'loss': 0.8408, 'learning_rate': 1.7197412709556368e-05, 'epoch': 0.27}
{'loss': 0.8771, 'learning_rate': 1.7192003111749737e-05, 'epoch': 0.27}
{'loss': 0.9139, 'learning_rate': 1.7186589150724203e-05, 'epoch': 0.27}
{'loss': 0.8949, 'learning_rate': 1.7181170829764292e-05, 'epoch': 0.27}
{'loss': 0.8221, 'learning_rate': 1.7175748152157163e-05, 'epoch': 0.27}
{'loss': 0.8184, 'learning_rate': 1.7170321121192635e-05, 'epoch': 0.27}
{'loss': 0.898, 'learning_rate': 1.7164889740163158e-05, 'epoch': 0.27}
{'loss': 0.8983, 'learning_rate': 1.715945401236382e-05, 'epoch': 0.27}
{'loss': 0.8627, 'learning_rate': 1.7154013941092352e-05, 'epoch': 0.27}
{'loss': 0.7348, 'learning_rate': 1.714856952964911e-05, 'epoch': 0.27}
{'loss': 0.7595, 'learning_rate': 1.7143120781337102e-05, 'epoch': 0.27}
{'loss': 0.9075, 'learning_rate': 1.713766769946195e-05, 'epoch': 0.27}
{'loss': 0.8801, 'learning_rate': 1.7132210287331905e-05, 'epoch': 0.27}
{'loss': 0.865, 'learning_rate': 1.7126748548257858e-05, 'epoch': 0.27}
{'loss': 0.8901, 'learning_rate': 1.7121282485553315e-05, 'epoch': 0.27}
{'loss': 0.8567, 'learning_rate': 1.7115812102534405e-05, 'epoch': 0.27}
{'loss': 0.8418, 'learning_rate': 1.7110337402519885e-05, 'epoch': 0.27}
{'loss': 0.8936, 'learning_rate': 1.7104858388831123e-05, 'epoch': 0.27}
{'loss': 0.7803, 'learning_rate': 1.7099375064792107e-05, 'epoch': 0.27}
{'loss': 0.8203, 'learning_rate': 1.7093887433729445e-05, 'epoch': 0.27}
{'loss': 0.8631, 'learning_rate': 1.708839549897235e-05, 'epoch': 0.27}
{'loss': 0.9335, 'learning_rate': 1.708289926385265e-05, 'epoch': 0.27}
{'loss': 0.7744, 'learning_rate': 1.7077398731704778e-05, 'epoch': 0.27}
{'loss': 0.8547, 'learning_rate': 1.7071893905865788e-05, 'epoch': 0.27}
{'loss': 0.8659, 'learning_rate': 1.7066384789675318e-05, 'epoch': 0.27}
{'loss': 0.7901, 'learning_rate': 1.7060871386475623e-05, 'epoch': 0.27}
{'loss': 0.8852, 'learning_rate': 1.705535369961155e-05, 'epoch': 0.27}
{'loss': 0.7449, 'learning_rate': 1.704983173243056e-05, 'epoch': 0.27}
{'loss': 0.9189, 'learning_rate': 1.704430548828269e-05, 'epoch': 0.27}
{'loss': 0.8673, 'learning_rate': 1.7038774970520585e-05, 'epoch': 0.27}
{'loss': 0.8368, 'learning_rate': 1.7033240182499484e-05, 'epoch': 0.27}
{'loss': 0.8729, 'learning_rate': 1.7027701127577208e-05, 'epoch': 0.27}
{'loss': 0.8844, 'learning_rate': 1.7022157809114176e-05, 'epoch': 0.27}
{'loss': 0.8375, 'learning_rate': 1.7016610230473385e-05, 'epoch': 0.27}
{'loss': 0.7668, 'learning_rate': 1.7011058395020417e-05, 'epoch': 0.28}
{'loss': 0.8915, 'learning_rate': 1.7005502306123447e-05, 'epoch': 0.28}
{'loss': 0.8597, 'learning_rate': 1.699994196715322e-05, 'epoch': 0.28}
{'loss': 0.7698, 'learning_rate': 1.699437738148306e-05, 'epoch': 0.28}
{'loss': 0.8142, 'learning_rate': 1.698880855248888e-05, 'epoch': 0.28}
{'loss': 0.8454, 'learning_rate': 1.6983235483549144e-05, 'epoch': 0.28}
{'loss': 0.8884, 'learning_rate': 1.697765817804491e-05, 'epoch': 0.28}
{'loss': 0.7125, 'learning_rate': 1.6972076639359795e-05, 'epoch': 0.28}
{'loss': 0.8796, 'learning_rate': 1.6966490870879984e-05, 'epoch': 0.28}
{'loss': 0.8277, 'learning_rate': 1.6960900875994243e-05, 'epoch': 0.28}
{'loss': 0.8698, 'learning_rate': 1.6955306658093876e-05, 'epoch': 0.28}
{'loss': 0.9036, 'learning_rate': 1.694970822057277e-05, 'epoch': 0.28}
{'loss': 0.8838, 'learning_rate': 1.694410556682737e-05, 'epoch': 0.28}
{'loss': 0.7438, 'learning_rate': 1.6938498700256664e-05, 'epoch': 0.28}
{'loss': 0.8571, 'learning_rate': 1.6932887624262214e-05, 'epoch': 0.28}
{'loss': 0.8787, 'learning_rate': 1.692727234224812e-05, 'epoch': 0.28}
{'loss': 0.7651, 'learning_rate': 1.692165285762105e-05, 'epoch': 0.28}
{'loss': 0.8946, 'learning_rate': 1.6916029173790207e-05, 'epoch': 0.28}
{'loss': 0.8839, 'learning_rate': 1.691040129416735e-05, 'epoch': 0.28}
{'loss': 0.8978, 'learning_rate': 1.6904769222166777e-05, 'epoch': 0.28}
{'loss': 0.8697, 'learning_rate': 1.6899132961205338e-05, 'epoch': 0.28}
{'loss': 0.7711, 'learning_rate': 1.689349251470242e-05, 'epoch': 0.28}
{'loss': 0.9101, 'learning_rate': 1.6887847886079946e-05, 'epoch': 0.28}
{'loss': 0.8749, 'learning_rate': 1.6882199078762385e-05, 'epoch': 0.28}
{'loss': 0.9195, 'learning_rate': 1.6876546096176728e-05, 'epoch': 0.28}
{'loss': 0.9003, 'learning_rate': 1.6870888941752507e-05, 'epoch': 0.28}
{'loss': 0.8718, 'learning_rate': 1.686522761892179e-05, 'epoch': 0.28}
{'loss': 0.7164, 'learning_rate': 1.6859562131119162e-05, 'epoch': 0.28}
{'loss': 0.8417, 'learning_rate': 1.685389248178175e-05, 'epoch': 0.28}
{'loss': 0.862, 'learning_rate': 1.6848218674349182e-05, 'epoch': 0.28}
{'loss': 0.8957, 'learning_rate': 1.684254071226364e-05, 'epoch': 0.28}
{'loss': 0.7546, 'learning_rate': 1.6836858598969797e-05, 'epoch': 0.28}
{'loss': 0.8901, 'learning_rate': 1.6831172337914866e-05, 'epoch': 0.28}
{'loss': 0.8589, 'learning_rate': 1.6825481932548565e-05, 'epoch': 0.28}
{'loss': 0.8146, 'learning_rate': 1.6819787386323124e-05, 'epoch': 0.28}
{'loss': 0.8041, 'learning_rate': 1.6814088702693294e-05, 'epoch': 0.28}
{'loss': 0.8888, 'learning_rate': 1.6808385885116333e-05, 'epoch': 0.28}
{'loss': 0.8677, 'learning_rate': 1.6802678937052005e-05, 'epoch': 0.28}
{'loss': 0.8406, 'learning_rate': 1.6796967861962582e-05, 'epoch': 0.28}
{'loss': 0.844, 'learning_rate': 1.679125266331284e-05, 'epoch': 0.28}
{'loss': 0.975, 'learning_rate': 1.6785533344570053e-05, 'epoch': 0.28}
{'loss': 0.861, 'learning_rate': 1.6779809909203996e-05, 'epoch': 0.28}
{'loss': 0.7884, 'learning_rate': 1.6774082360686944e-05, 'epoch': 0.29}
{'loss': 0.8705, 'learning_rate': 1.6768350702493663e-05, 'epoch': 0.29}
{'loss': 0.8852, 'learning_rate': 1.676261493810142e-05, 'epoch': 0.29}
{'loss': 0.8611, 'learning_rate': 1.6756875070989967e-05, 'epoch': 0.29}
{'loss': 0.8839, 'learning_rate': 1.6751131104641543e-05, 'epoch': 0.29}
{'loss': 0.8613, 'learning_rate': 1.674538304254088e-05, 'epoch': 0.29}
{'loss': 0.8719, 'learning_rate': 1.6739630888175188e-05, 'epoch': 0.29}
{'loss': 0.9019, 'learning_rate': 1.673387464503417e-05, 'epoch': 0.29}
{'loss': 0.777, 'learning_rate': 1.672811431661e-05, 'epoch': 0.29}
{'loss': 0.8581, 'learning_rate': 1.6722349906397334e-05, 'epoch': 0.29}
{'loss': 0.8391, 'learning_rate': 1.67165814178933e-05, 'epoch': 0.29}
{'loss': 0.8023, 'learning_rate': 1.671080885459751e-05, 'epoch': 0.29}
{'loss': 0.6928, 'learning_rate': 1.670503222001204e-05, 'epoch': 0.29}
{'loss': 0.8237, 'learning_rate': 1.6699251517641435e-05, 'epoch': 0.29}
{'loss': 0.7365, 'learning_rate': 1.669346675099272e-05, 'epoch': 0.29}
[2025-12-09 15:23:13,630] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step6000 is about to be saved!
[2025-12-09 15:23:13,721] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6000/global_step6000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 15:23:13,722] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6000/global_step6000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 15:23:14,361] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6000/global_step6000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 15:23:14,371] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6000/global_step6000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 15:24:02,497] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6000/global_step6000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 15:24:02,721] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6000/global_step6000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 15:24:15,696] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step6000 is ready now!
{'loss': 0.8843, 'learning_rate': 1.668767792357536e-05, 'epoch': 0.29}
{'loss': 0.8334, 'learning_rate': 1.668188503890132e-05, 'epoch': 0.29}
{'loss': 0.8908, 'learning_rate': 1.667608810048499e-05, 'epoch': 0.29}
{'loss': 0.8878, 'learning_rate': 1.6670287111843247e-05, 'epoch': 0.29}
{'loss': 0.8876, 'learning_rate': 1.666448207649541e-05, 'epoch': 0.29}
{'loss': 0.9784, 'learning_rate': 1.6658672997963258e-05, 'epoch': 0.29}
{'loss': 0.7678, 'learning_rate': 1.6652859879771024e-05, 'epoch': 0.29}
{'loss': 0.8959, 'learning_rate': 1.6647042725445386e-05, 'epoch': 0.29}
{'loss': 0.8661, 'learning_rate': 1.6641221538515474e-05, 'epoch': 0.29}
{'loss': 0.8312, 'learning_rate': 1.663539632251287e-05, 'epoch': 0.29}
{'loss': 0.8895, 'learning_rate': 1.662956708097159e-05, 'epoch': 0.29}
{'loss': 0.866, 'learning_rate': 1.6623733817428104e-05, 'epoch': 0.29}
{'loss': 0.8334, 'learning_rate': 1.661789653542131e-05, 'epoch': 0.29}
{'loss': 0.7139, 'learning_rate': 1.661205523849255e-05, 'epoch': 0.29}
{'loss': 0.8592, 'learning_rate': 1.6606209930185604e-05, 'epoch': 0.29}
{'loss': 0.916, 'learning_rate': 1.660036061404668e-05, 'epoch': 0.29}
{'loss': 0.8555, 'learning_rate': 1.6594507293624426e-05, 'epoch': 0.29}
{'loss': 0.9281, 'learning_rate': 1.6588649972469907e-05, 'epoch': 0.29}
{'loss': 0.7954, 'learning_rate': 1.6582788654136623e-05, 'epoch': 0.29}
{'loss': 0.9099, 'learning_rate': 1.65769233421805e-05, 'epoch': 0.29}
{'loss': 0.7654, 'learning_rate': 1.6571054040159884e-05, 'epoch': 0.29}
{'loss': 0.914, 'learning_rate': 1.656518075163554e-05, 'epoch': 0.29}
{'loss': 0.8925, 'learning_rate': 1.655930348017066e-05, 'epoch': 0.29}
{'loss': 0.889, 'learning_rate': 1.6553422229330837e-05, 'epoch': 0.29}
{'loss': 0.7772, 'learning_rate': 1.6547537002684097e-05, 'epoch': 0.29}
{'loss': 0.8472, 'learning_rate': 1.6541647803800863e-05, 'epoch': 0.29}
{'loss': 0.772, 'learning_rate': 1.653575463625397e-05, 'epoch': 0.3}
{'loss': 0.8653, 'learning_rate': 1.652985750361867e-05, 'epoch': 0.3}
{'loss': 0.7796, 'learning_rate': 1.6523956409472616e-05, 'epoch': 0.3}
{'loss': 0.8341, 'learning_rate': 1.6518051357395855e-05, 'epoch': 0.3}
{'loss': 0.9146, 'learning_rate': 1.6512142350970852e-05, 'epoch': 0.3}
{'loss': 0.8848, 'learning_rate': 1.650622939378245e-05, 'epoch': 0.3}
{'loss': 0.7698, 'learning_rate': 1.6500312489417912e-05, 'epoch': 0.3}
{'loss': 0.792, 'learning_rate': 1.649439164146688e-05, 'epoch': 0.3}
{'loss': 0.8925, 'learning_rate': 1.64884668535214e-05, 'epoch': 0.3}
{'loss': 0.9025, 'learning_rate': 1.648253812917589e-05, 'epoch': 0.3}
{'loss': 0.8792, 'learning_rate': 1.6476605472027173e-05, 'epoch': 0.3}
{'loss': 0.846, 'learning_rate': 1.647066888567445e-05, 'epoch': 0.3}
{'loss': 0.8963, 'learning_rate': 1.6464728373719307e-05, 'epoch': 0.3}
{'loss': 0.8751, 'learning_rate': 1.645878393976572e-05, 'epoch': 0.3}
{'loss': 0.825, 'learning_rate': 1.6452835587420034e-05, 'epoch': 0.3}
{'loss': 0.867, 'learning_rate': 1.644688332029097e-05, 'epoch': 0.3}
{'loss': 0.9042, 'learning_rate': 1.6440927141989635e-05, 'epoch': 0.3}
{'loss': 0.7892, 'learning_rate': 1.6434967056129496e-05, 'epoch': 0.3}
{'loss': 0.8888, 'learning_rate': 1.64290030663264e-05, 'epoch': 0.3}
{'loss': 0.8773, 'learning_rate': 1.6423035176198558e-05, 'epoch': 0.3}
{'loss': 0.8651, 'learning_rate': 1.6417063389366546e-05, 'epoch': 0.3}
{'loss': 0.9858, 'learning_rate': 1.6411087709453313e-05, 'epoch': 0.3}
{'loss': 0.8336, 'learning_rate': 1.6405108140084157e-05, 'epoch': 0.3}
{'loss': 0.6946, 'learning_rate': 1.6399124684886744e-05, 'epoch': 0.3}
{'loss': 0.8715, 'learning_rate': 1.6393137347491098e-05, 'epoch': 0.3}
{'loss': 0.8248, 'learning_rate': 1.6387146131529594e-05, 'epoch': 0.3}
{'loss': 0.8403, 'learning_rate': 1.6381151040636955e-05, 'epoch': 0.3}
{'loss': 0.8866, 'learning_rate': 1.637515207845027e-05, 'epoch': 0.3}
{'loss': 0.899, 'learning_rate': 1.6369149248608967e-05, 'epoch': 0.3}
{'loss': 0.8986, 'learning_rate': 1.6363142554754817e-05, 'epoch': 0.3}
{'loss': 0.8339, 'learning_rate': 1.6357132000531944e-05, 'epoch': 0.3}
{'loss': 0.8863, 'learning_rate': 1.635111758958681e-05, 'epoch': 0.3}
{'loss': 0.8422, 'learning_rate': 1.6345099325568217e-05, 'epoch': 0.3}
{'loss': 0.9063, 'learning_rate': 1.6339077212127294e-05, 'epoch': 0.3}
{'loss': 0.8599, 'learning_rate': 1.633305125291753e-05, 'epoch': 0.3}
{'loss': 0.8858, 'learning_rate': 1.6327021451594724e-05, 'epoch': 0.3}
{'loss': 0.8125, 'learning_rate': 1.6320987811817013e-05, 'epoch': 0.3}
{'loss': 0.9076, 'learning_rate': 1.6314950337244866e-05, 'epoch': 0.3}
{'loss': 0.7972, 'learning_rate': 1.630890903154108e-05, 'epoch': 0.3}
{'loss': 0.8744, 'learning_rate': 1.6302863898370772e-05, 'epoch': 0.3}
{'loss': 0.833, 'learning_rate': 1.6296814941401384e-05, 'epoch': 0.3}
{'loss': 0.7493, 'learning_rate': 1.6290762164302666e-05, 'epoch': 0.3}
{'loss': 0.8522, 'learning_rate': 1.6284705570746708e-05, 'epoch': 0.31}
{'loss': 0.9253, 'learning_rate': 1.6278645164407892e-05, 'epoch': 0.31}
{'loss': 0.7558, 'learning_rate': 1.6272580948962926e-05, 'epoch': 0.31}
{'loss': 0.8505, 'learning_rate': 1.6266512928090833e-05, 'epoch': 0.31}
{'loss': 0.8168, 'learning_rate': 1.6260441105472932e-05, 'epoch': 0.31}
{'loss': 0.9091, 'learning_rate': 1.625436548479286e-05, 'epoch': 0.31}
{'loss': 0.892, 'learning_rate': 1.6248286069736544e-05, 'epoch': 0.31}
{'loss': 0.9457, 'learning_rate': 1.6242202863992235e-05, 'epoch': 0.31}
WARNING: tokenization mismatch: 1 vs. 1419. (ignored)
{'loss': 0.8958, 'learning_rate': 1.623611587125046e-05, 'epoch': 0.31}
{'loss': 0.7613, 'learning_rate': 1.6230025095204058e-05, 'epoch': 0.31}
{'loss': 0.9268, 'learning_rate': 1.6223930539548157e-05, 'epoch': 0.31}
{'loss': 0.8586, 'learning_rate': 1.6217832207980185e-05, 'epoch': 0.31}
{'loss': 0.8694, 'learning_rate': 1.6211730104199853e-05, 'epoch': 0.31}
{'loss': 0.9211, 'learning_rate': 1.6205624231909163e-05, 'epoch': 0.31}
{'loss': 0.8985, 'learning_rate': 1.6199514594812405e-05, 'epoch': 0.31}
{'loss': 0.8732, 'learning_rate': 1.6193401196616153e-05, 'epoch': 0.31}
{'loss': 0.8593, 'learning_rate': 1.6187284041029262e-05, 'epoch': 0.31}
{'loss': 0.8299, 'learning_rate': 1.6181163131762865e-05, 'epoch': 0.31}
{'loss': 0.916, 'learning_rate': 1.6175038472530375e-05, 'epoch': 0.31}
{'loss': 0.9247, 'learning_rate': 1.616891006704747e-05, 'epoch': 0.31}
{'loss': 0.8544, 'learning_rate': 1.616277791903212e-05, 'epoch': 0.31}
{'loss': 0.8955, 'learning_rate': 1.6156642032204554e-05, 'epoch': 0.31}
{'loss': 0.8153, 'learning_rate': 1.6150502410287265e-05, 'epoch': 0.31}
{'loss': 0.8655, 'learning_rate': 1.6144359057005018e-05, 'epoch': 0.31}
{'loss': 0.8727, 'learning_rate': 1.6138211976084845e-05, 'epoch': 0.31}
{'loss': 0.7363, 'learning_rate': 1.613206117125603e-05, 'epoch': 0.31}
{'loss': 0.9199, 'learning_rate': 1.6125906646250124e-05, 'epoch': 0.31}
{'loss': 0.7591, 'learning_rate': 1.6119748404800927e-05, 'epoch': 0.31}
{'loss': 0.7946, 'learning_rate': 1.611358645064451e-05, 'epoch': 0.31}
{'loss': 0.8938, 'learning_rate': 1.6107420787519178e-05, 'epoch': 0.31}
{'loss': 0.8892, 'learning_rate': 1.6101251419165493e-05, 'epoch': 0.31}
{'loss': 0.9202, 'learning_rate': 1.6095078349326268e-05, 'epoch': 0.31}
[2025-12-09 15:48:50,352] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step6500 is about to be saved!
[2025-12-09 15:48:50,383] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6500/global_step6500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 15:48:50,384] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6500/global_step6500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 15:48:50,545] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6500/global_step6500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 15:48:50,548] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6500/global_step6500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 15:49:30,278] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6500/global_step6500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 15:49:30,281] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-6500/global_step6500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 15:49:31,381] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step6500 is ready now!
{'loss': 0.8171, 'learning_rate': 1.6088901581746562e-05, 'epoch': 0.31}
{'loss': 0.8745, 'learning_rate': 1.608272112017367e-05, 'epoch': 0.31}
{'loss': 0.7739, 'learning_rate': 1.607653696835713e-05, 'epoch': 0.31}
{'loss': 0.8714, 'learning_rate': 1.6070349130048724e-05, 'epoch': 0.31}
{'loss': 0.8588, 'learning_rate': 1.6064157609002473e-05, 'epoch': 0.31}
{'loss': 0.8362, 'learning_rate': 1.605796240897462e-05, 'epoch': 0.31}
{'loss': 0.9766, 'learning_rate': 1.605176353372365e-05, 'epoch': 0.31}
{'loss': 0.9062, 'learning_rate': 1.6045560987010276e-05, 'epoch': 0.31}
{'loss': 0.8805, 'learning_rate': 1.6039354772597432e-05, 'epoch': 0.31}
{'loss': 0.737, 'learning_rate': 1.603314489425029e-05, 'epoch': 0.32}
{'loss': 0.8551, 'learning_rate': 1.6026931355736225e-05, 'epoch': 0.32}
{'loss': 0.7561, 'learning_rate': 1.6020714160824854e-05, 'epoch': 0.32}
{'loss': 0.8817, 'learning_rate': 1.6014493313288e-05, 'epoch': 0.32}
{'loss': 0.772, 'learning_rate': 1.6008268816899706e-05, 'epoch': 0.32}
{'loss': 0.9015, 'learning_rate': 1.6002040675436225e-05, 'epoch': 0.32}
{'loss': 0.8139, 'learning_rate': 1.5995808892676028e-05, 'epoch': 0.32}
{'loss': 0.8638, 'learning_rate': 1.5989573472399785e-05, 'epoch': 0.32}
{'loss': 0.9052, 'learning_rate': 1.5983334418390382e-05, 'epoch': 0.32}
{'loss': 0.8081, 'learning_rate': 1.597709173443291e-05, 'epoch': 0.32}
{'loss': 0.8545, 'learning_rate': 1.597084542431465e-05, 'epoch': 0.32}
{'loss': 0.906, 'learning_rate': 1.5964595491825093e-05, 'epoch': 0.32}
{'loss': 0.85, 'learning_rate': 1.595834194075593e-05, 'epoch': 0.32}
{'loss': 0.9046, 'learning_rate': 1.5952084774901043e-05, 'epoch': 0.32}
{'loss': 0.6837, 'learning_rate': 1.5945823998056505e-05, 'epoch': 0.32}
{'loss': 0.8994, 'learning_rate': 1.5939559614020584e-05, 'epoch': 0.32}
{'loss': 0.9012, 'learning_rate': 1.593329162659373e-05, 'epoch': 0.32}
{'loss': 0.8226, 'learning_rate': 1.5927020039578587e-05, 'epoch': 0.32}
{'loss': 0.9143, 'learning_rate': 1.5920744856779974e-05, 'epoch': 0.32}
{'loss': 0.8606, 'learning_rate': 1.5914466082004904e-05, 'epoch': 0.32}
{'loss': 0.8573, 'learning_rate': 1.5908183719062557e-05, 'epoch': 0.32}
{'loss': 0.9162, 'learning_rate': 1.5901897771764298e-05, 'epoch': 0.32}
{'loss': 0.8787, 'learning_rate': 1.5895608243923662e-05, 'epoch': 0.32}
{'loss': 0.8879, 'learning_rate': 1.5889315139356352e-05, 'epoch': 0.32}
{'loss': 0.903, 'learning_rate': 1.5883018461880255e-05, 'epoch': 0.32}
{'loss': 0.8474, 'learning_rate': 1.587671821531541e-05, 'epoch': 0.32}
{'loss': 0.8274, 'learning_rate': 1.5870414403484034e-05, 'epoch': 0.32}
{'loss': 0.9173, 'learning_rate': 1.58641070302105e-05, 'epoch': 0.32}
{'loss': 0.8851, 'learning_rate': 1.5857796099321333e-05, 'epoch': 0.32}
{'loss': 0.8691, 'learning_rate': 1.585148161464524e-05, 'epoch': 0.32}
WARNING: tokenization mismatch: 1 vs. 70. (ignored)
{'loss': 0.747, 'learning_rate': 1.5845163580013062e-05, 'epoch': 0.32}
{'loss': 0.8746, 'learning_rate': 1.583884199925781e-05, 'epoch': 0.32}
{'loss': 0.8259, 'learning_rate': 1.5832516876214627e-05, 'epoch': 0.32}
{'loss': 0.7883, 'learning_rate': 1.582618821472082e-05, 'epoch': 0.32}
{'loss': 0.7748, 'learning_rate': 1.5819856018615843e-05, 'epoch': 0.32}
{'loss': 0.9188, 'learning_rate': 1.581352029174129e-05, 'epoch': 0.32}
{'loss': 0.9447, 'learning_rate': 1.580718103794089e-05, 'epoch': 0.32}
{'loss': 0.8146, 'learning_rate': 1.5800838261060528e-05, 'epoch': 0.32}
{'loss': 0.8389, 'learning_rate': 1.579449196494821e-05, 'epoch': 0.32}
{'loss': 0.7935, 'learning_rate': 1.5788142153454086e-05, 'epoch': 0.32}
{'loss': 0.6798, 'learning_rate': 1.5781788830430443e-05, 'epoch': 0.32}
{'loss': 0.8343, 'learning_rate': 1.5775431999731686e-05, 'epoch': 0.32}
{'loss': 0.9031, 'learning_rate': 1.5769071665214356e-05, 'epoch': 0.33}
{'loss': 0.9292, 'learning_rate': 1.5762707830737124e-05, 'epoch': 0.33}
{'loss': 0.7795, 'learning_rate': 1.5756340500160768e-05, 'epoch': 0.33}
{'loss': 0.7632, 'learning_rate': 1.57499696773482e-05, 'epoch': 0.33}
{'loss': 0.8405, 'learning_rate': 1.5743595366164458e-05, 'epoch': 0.33}
{'loss': 0.8455, 'learning_rate': 1.573721757047668e-05, 'epoch': 0.33}
{'loss': 0.8148, 'learning_rate': 1.5730836294154116e-05, 'epoch': 0.33}
{'loss': 0.8548, 'learning_rate': 1.5724451541068147e-05, 'epoch': 0.33}
{'loss': 0.8833, 'learning_rate': 1.571806331509225e-05, 'epoch': 0.33}
{'loss': 0.8548, 'learning_rate': 1.5711671620102014e-05, 'epoch': 0.33}
{'loss': 0.7837, 'learning_rate': 1.5705276459975124e-05, 'epoch': 0.33}
{'loss': 0.861, 'learning_rate': 1.569887783859137e-05, 'epoch': 0.33}
{'loss': 0.7932, 'learning_rate': 1.5692475759832655e-05, 'epoch': 0.33}
{'loss': 0.9315, 'learning_rate': 1.5686070227582964e-05, 'epoch': 0.33}
{'loss': 0.9078, 'learning_rate': 1.5679661245728383e-05, 'epoch': 0.33}
{'loss': 0.904, 'learning_rate': 1.5673248818157088e-05, 'epoch': 0.33}
{'loss': 0.7106, 'learning_rate': 1.5666832948759352e-05, 'epoch': 0.33}
{'loss': 0.8872, 'learning_rate': 1.5660413641427533e-05, 'epoch': 0.33}
{'loss': 0.8303, 'learning_rate': 1.565399090005607e-05, 'epoch': 0.33}
{'loss': 0.8937, 'learning_rate': 1.5647564728541485e-05, 'epoch': 0.33}
{'loss': 0.8676, 'learning_rate': 1.5641135130782393e-05, 'epoch': 0.33}
{'loss': 0.837, 'learning_rate': 1.5634702110679474e-05, 'epoch': 0.33}
{'loss': 0.7862, 'learning_rate': 1.5628265672135496e-05, 'epoch': 0.33}
{'loss': 0.8375, 'learning_rate': 1.5621825819055288e-05, 'epoch': 0.33}
{'loss': 0.8887, 'learning_rate': 1.5615382555345758e-05, 'epoch': 0.33}
{'loss': 0.8638, 'learning_rate': 1.5608935884915887e-05, 'epoch': 0.33}
{'loss': 0.8063, 'learning_rate': 1.5602485811676712e-05, 'epoch': 0.33}
{'loss': 0.8265, 'learning_rate': 1.5596032339541345e-05, 'epoch': 0.33}
{'loss': 0.9441, 'learning_rate': 1.5589575472424954e-05, 'epoch': 0.33}
{'loss': 0.7638, 'learning_rate': 1.558311521424477e-05, 'epoch': 0.33}
{'loss': 0.9227, 'learning_rate': 1.557665156892008e-05, 'epoch': 0.33}
{'loss': 0.6954, 'learning_rate': 1.557018454037222e-05, 'epoch': 0.33}
{'loss': 0.8825, 'learning_rate': 1.5563714132524586e-05, 'epoch': 0.33}
{'loss': 0.9026, 'learning_rate': 1.5557240349302625e-05, 'epoch': 0.33}
{'loss': 0.6796, 'learning_rate': 1.555076319463383e-05, 'epoch': 0.33}
{'loss': 0.9193, 'learning_rate': 1.554428267244773e-05, 'epoch': 0.33}
{'loss': 0.8662, 'learning_rate': 1.553779878667591e-05, 'epoch': 0.33}
{'loss': 0.8331, 'learning_rate': 1.5531311541251995e-05, 'epoch': 0.33}
{'loss': 0.8986, 'learning_rate': 1.552482094011164e-05, 'epoch': 0.33}
{'loss': 0.9182, 'learning_rate': 1.5518326987192537e-05, 'epoch': 0.33}
{'loss': 0.799, 'learning_rate': 1.5511829686434422e-05, 'epoch': 0.33}
{'loss': 0.7595, 'learning_rate': 1.5505329041779048e-05, 'epoch': 0.34}
{'loss': 0.8707, 'learning_rate': 1.5498825057170207e-05, 'epoch': 0.34}
{'loss': 0.8165, 'learning_rate': 1.549231773655371e-05, 'epoch': 0.34}
{'loss': 0.8158, 'learning_rate': 1.5485807083877393e-05, 'epoch': 0.34}
{'loss': 0.8076, 'learning_rate': 1.5479293103091116e-05, 'epoch': 0.34}
{'loss': 0.8982, 'learning_rate': 1.5472775798146766e-05, 'epoch': 0.34}
{'loss': 0.892, 'learning_rate': 1.546625517299823e-05, 'epoch': 0.34}
{'loss': 0.9302, 'learning_rate': 1.5459731231601425e-05, 'epoch': 0.34}
[2025-12-09 16:20:18,456] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step7000 is about to be saved!
[2025-12-09 16:20:18,487] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7000/global_step7000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 16:20:18,488] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7000/global_step7000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 16:20:18,648] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7000/global_step7000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 16:20:18,651] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7000/global_step7000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 16:21:15,238] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7000/global_step7000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 16:21:15,477] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7000/global_step7000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 16:27:34,946] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step7000 is ready now!
{'loss': 0.8508, 'learning_rate': 1.5453203977914267e-05, 'epoch': 0.34}
{'loss': 0.9638, 'learning_rate': 1.5446673415896686e-05, 'epoch': 0.34}
{'loss': 0.8385, 'learning_rate': 1.5440139549510624e-05, 'epoch': 0.34}
{'loss': 0.7886, 'learning_rate': 1.5433602382720022e-05, 'epoch': 0.34}
{'loss': 0.8232, 'learning_rate': 1.5427061919490826e-05, 'epoch': 0.34}
{'loss': 0.7451, 'learning_rate': 1.542051816379098e-05, 'epoch': 0.34}
{'loss': 0.8718, 'learning_rate': 1.541397111959043e-05, 'epoch': 0.34}
{'loss': 0.8624, 'learning_rate': 1.5407420790861106e-05, 'epoch': 0.34}
{'loss': 0.8924, 'learning_rate': 1.5400867181576945e-05, 'epoch': 0.34}
{'loss': 0.8767, 'learning_rate': 1.5394310295713862e-05, 'epoch': 0.34}
{'loss': 0.9253, 'learning_rate': 1.5387750137249775e-05, 'epoch': 0.34}
{'loss': 0.8231, 'learning_rate': 1.5381186710164565e-05, 'epoch': 0.34}
{'loss': 0.7777, 'learning_rate': 1.537462001844012e-05, 'epoch': 0.34}
{'loss': 0.8539, 'learning_rate': 1.5368050066060285e-05, 'epoch': 0.34}
{'loss': 0.7689, 'learning_rate': 1.5361476857010907e-05, 'epoch': 0.34}
{'loss': 0.8503, 'learning_rate': 1.535490039527979e-05, 'epoch': 0.34}
{'loss': 0.8677, 'learning_rate': 1.534832068485672e-05, 'epoch': 0.34}
{'loss': 0.7744, 'learning_rate': 1.5341737729733453e-05, 'epoch': 0.34}
{'loss': 0.8638, 'learning_rate': 1.533515153390372e-05, 'epoch': 0.34}
{'loss': 0.9039, 'learning_rate': 1.5328562101363196e-05, 'epoch': 0.34}
{'loss': 0.8993, 'learning_rate': 1.5321969436109545e-05, 'epoch': 0.34}
{'loss': 0.8373, 'learning_rate': 1.531537354214238e-05, 'epoch': 0.34}
{'loss': 0.7953, 'learning_rate': 1.530877442346327e-05, 'epoch': 0.34}
{'loss': 0.8504, 'learning_rate': 1.5302172084075752e-05, 'epoch': 0.34}
{'loss': 0.7915, 'learning_rate': 1.5295566527985306e-05, 'epoch': 0.34}
{'loss': 0.7768, 'learning_rate': 1.5288957759199366e-05, 'epoch': 0.34}
{'loss': 0.8873, 'learning_rate': 1.5282345781727318e-05, 'epoch': 0.34}
{'loss': 0.8393, 'learning_rate': 1.5275730599580497e-05, 'epoch': 0.34}
{'loss': 0.9489, 'learning_rate': 1.526911221677217e-05, 'epoch': 0.34}
{'loss': 0.7796, 'learning_rate': 1.5262490637317555e-05, 'epoch': 0.34}
{'loss': 0.8465, 'learning_rate': 1.5255865865233817e-05, 'epoch': 0.34}
{'loss': 0.9599, 'learning_rate': 1.5249237904540041e-05, 'epoch': 0.34}
{'loss': 0.8392, 'learning_rate': 1.524260675925726e-05, 'epoch': 0.34}
{'loss': 0.822, 'learning_rate': 1.523597243340843e-05, 'epoch': 0.34}
{'loss': 0.8926, 'learning_rate': 1.522933493101844e-05, 'epoch': 0.35}
{'loss': 0.8508, 'learning_rate': 1.522269425611411e-05, 'epoch': 0.35}
{'loss': 0.8417, 'learning_rate': 1.5216050412724178e-05, 'epoch': 0.35}
{'loss': 0.8488, 'learning_rate': 1.5209403404879305e-05, 'epoch': 0.35}
{'loss': 0.7919, 'learning_rate': 1.5202753236612078e-05, 'epoch': 0.35}
{'loss': 0.7955, 'learning_rate': 1.5196099911956998e-05, 'epoch': 0.35}
{'loss': 0.7232, 'learning_rate': 1.518944343495048e-05, 'epoch': 0.35}
{'loss': 0.8533, 'learning_rate': 1.5182783809630847e-05, 'epoch': 0.35}
{'loss': 0.8624, 'learning_rate': 1.5176121040038342e-05, 'epoch': 0.35}
{'loss': 0.8255, 'learning_rate': 1.5169455130215111e-05, 'epoch': 0.35}
{'loss': 0.8648, 'learning_rate': 1.5162786084205204e-05, 'epoch': 0.35}
{'loss': 0.8741, 'learning_rate': 1.5156113906054568e-05, 'epoch': 0.35}
{'loss': 0.893, 'learning_rate': 1.5149438599811062e-05, 'epoch': 0.35}
{'loss': 0.8277, 'learning_rate': 1.5142760169524438e-05, 'epoch': 0.35}
{'loss': 0.913, 'learning_rate': 1.5136078619246339e-05, 'epoch': 0.35}
{'loss': 0.8777, 'learning_rate': 1.5129393953030307e-05, 'epoch': 0.35}
{'loss': 0.8929, 'learning_rate': 1.512270617493177e-05, 'epoch': 0.35}
{'loss': 0.9419, 'learning_rate': 1.5116015289008043e-05, 'epoch': 0.35}
{'loss': 0.738, 'learning_rate': 1.5109321299318333e-05, 'epoch': 0.35}
{'loss': 0.7833, 'learning_rate': 1.5102624209923723e-05, 'epoch': 0.35}
{'loss': 0.8921, 'learning_rate': 1.5095924024887185e-05, 'epoch': 0.35}
{'loss': 0.834, 'learning_rate': 1.5089220748273557e-05, 'epoch': 0.35}
{'loss': 0.7962, 'learning_rate': 1.508251438414956e-05, 'epoch': 0.35}
{'loss': 0.8135, 'learning_rate': 1.5075804936583791e-05, 'epoch': 0.35}
{'loss': 0.8644, 'learning_rate': 1.5069092409646713e-05, 'epoch': 0.35}
{'loss': 0.9091, 'learning_rate': 1.506237680741065e-05, 'epoch': 0.35}
{'loss': 0.9099, 'learning_rate': 1.5055658133949811e-05, 'epoch': 0.35}
{'loss': 0.8627, 'learning_rate': 1.504893639334025e-05, 'epoch': 0.35}
{'loss': 0.8708, 'learning_rate': 1.5042211589659892e-05, 'epoch': 0.35}
{'loss': 0.8707, 'learning_rate': 1.5035483726988513e-05, 'epoch': 0.35}
{'loss': 0.856, 'learning_rate': 1.5028752809407752e-05, 'epoch': 0.35}
{'loss': 0.9223, 'learning_rate': 1.50220188410011e-05, 'epoch': 0.35}
{'loss': 0.8285, 'learning_rate': 1.5015281825853896e-05, 'epoch': 0.35}
{'loss': 0.7811, 'learning_rate': 1.5008541768053324e-05, 'epoch': 0.35}
{'loss': 0.9124, 'learning_rate': 1.5001798671688424e-05, 'epoch': 0.35}
{'loss': 0.8914, 'learning_rate': 1.499505254085007e-05, 'epoch': 0.35}
{'loss': 0.8784, 'learning_rate': 1.498830337963098e-05, 'epoch': 0.35}
{'loss': 0.8755, 'learning_rate': 1.4981551192125714e-05, 'epoch': 0.35}
{'loss': 0.7601, 'learning_rate': 1.4974795982430665e-05, 'epoch': 0.35}
{'loss': 0.8704, 'learning_rate': 1.4968037754644061e-05, 'epoch': 0.35}
{'loss': 0.8052, 'learning_rate': 1.4961276512865954e-05, 'epoch': 0.35}
{'loss': 0.9232, 'learning_rate': 1.4954512261198235e-05, 'epoch': 0.35}
{'loss': 0.8662, 'learning_rate': 1.4947745003744616e-05, 'epoch': 0.36}
{'loss': 0.8414, 'learning_rate': 1.494097474461063e-05, 'epoch': 0.36}
{'loss': 0.7128, 'learning_rate': 1.4934201487903635e-05, 'epoch': 0.36}
{'loss': 0.8283, 'learning_rate': 1.492742523773281e-05, 'epoch': 0.36}
{'loss': 0.8149, 'learning_rate': 1.4920645998209138e-05, 'epoch': 0.36}
{'loss': 0.8317, 'learning_rate': 1.4913863773445432e-05, 'epoch': 0.36}
{'loss': 0.731, 'learning_rate': 1.4907078567556303e-05, 'epoch': 0.36}
{'loss': 0.8934, 'learning_rate': 1.4900290384658181e-05, 'epoch': 0.36}
{'loss': 0.7781, 'learning_rate': 1.489349922886929e-05, 'epoch': 0.36}
{'loss': 0.8576, 'learning_rate': 1.488670510430967e-05, 'epoch': 0.36}
{'loss': 0.9152, 'learning_rate': 1.4879908015101152e-05, 'epoch': 0.36}
{'loss': 0.9517, 'learning_rate': 1.487310796536737e-05, 'epoch': 0.36}
{'loss': 0.8993, 'learning_rate': 1.4866304959233762e-05, 'epoch': 0.36}
{'loss': 0.7963, 'learning_rate': 1.4859499000827539e-05, 'epoch': 0.36}
{'loss': 0.838, 'learning_rate': 1.4852690094277727e-05, 'epoch': 0.36}
{'loss': 0.8851, 'learning_rate': 1.4845878243715122e-05, 'epoch': 0.36}
{'loss': 0.8601, 'learning_rate': 1.4839063453272318e-05, 'epoch': 0.36}
{'loss': 0.748, 'learning_rate': 1.4832245727083683e-05, 'epoch': 0.36}
{'loss': 0.8798, 'learning_rate': 1.4825425069285374e-05, 'epoch': 0.36}
{'loss': 0.8906, 'learning_rate': 1.4818601484015323e-05, 'epoch': 0.36}
{'loss': 0.8997, 'learning_rate': 1.4811774975413238e-05, 'epoch': 0.36}
{'loss': 0.8492, 'learning_rate': 1.4804945547620601e-05, 'epoch': 0.36}
{'loss': 0.8989, 'learning_rate': 1.4798113204780668e-05, 'epoch': 0.36}
{'loss': 0.8939, 'learning_rate': 1.4791277951038456e-05, 'epoch': 0.36}
[2025-12-09 16:52:41,042] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step7500 is about to be saved!
[2025-12-09 16:52:41,133] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7500/global_step7500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 16:52:41,134] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7500/global_step7500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 16:52:41,768] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7500/global_step7500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 16:52:41,776] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7500/global_step7500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 16:53:35,429] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7500/global_step7500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 16:53:35,432] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-7500/global_step7500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 16:53:35,444] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step7500 is ready now!
{'loss': 0.8265, 'learning_rate': 1.4784439790540753e-05, 'epoch': 0.36}
{'loss': 0.8523, 'learning_rate': 1.4777598727436115e-05, 'epoch': 0.36}
{'loss': 0.8673, 'learning_rate': 1.4770754765874846e-05, 'epoch': 0.36}
{'loss': 0.8419, 'learning_rate': 1.476390791000902e-05, 'epoch': 0.36}
{'loss': 0.7828, 'learning_rate': 1.4757058163992466e-05, 'epoch': 0.36}
{'loss': 0.8254, 'learning_rate': 1.4750205531980764e-05, 'epoch': 0.36}
{'loss': 0.8427, 'learning_rate': 1.4743350018131237e-05, 'epoch': 0.36}
{'loss': 0.9352, 'learning_rate': 1.473649162660297e-05, 'epoch': 0.36}
{'loss': 0.9319, 'learning_rate': 1.4729630361556789e-05, 'epoch': 0.36}
{'loss': 0.8491, 'learning_rate': 1.4722766227155256e-05, 'epoch': 0.36}
{'loss': 0.9117, 'learning_rate': 1.4715899227562682e-05, 'epoch': 0.36}
{'loss': 0.899, 'learning_rate': 1.4709029366945115e-05, 'epoch': 0.36}
{'loss': 0.8829, 'learning_rate': 1.4702156649470336e-05, 'epoch': 0.36}
{'loss': 0.8109, 'learning_rate': 1.4695281079307865e-05, 'epoch': 0.36}
{'loss': 0.7481, 'learning_rate': 1.4688402660628945e-05, 'epoch': 0.36}
{'loss': 0.8861, 'learning_rate': 1.4681521397606551e-05, 'epoch': 0.36}
{'loss': 0.8543, 'learning_rate': 1.467463729441538e-05, 'epoch': 0.36}
{'loss': 0.8323, 'learning_rate': 1.4667750355231863e-05, 'epoch': 0.37}
{'loss': 0.9008, 'learning_rate': 1.4660860584234138e-05, 'epoch': 0.37}
{'loss': 0.8738, 'learning_rate': 1.4653967985602066e-05, 'epoch': 0.37}
{'loss': 0.8216, 'learning_rate': 1.4647072563517228e-05, 'epoch': 0.37}
{'loss': 0.905, 'learning_rate': 1.4640174322162913e-05, 'epoch': 0.37}
{'loss': 0.7351, 'learning_rate': 1.4633273265724121e-05, 'epoch': 0.37}
{'loss': 0.7623, 'learning_rate': 1.462636939838756e-05, 'epoch': 0.37}
{'loss': 0.8392, 'learning_rate': 1.4619462724341647e-05, 'epoch': 0.37}
{'loss': 0.8946, 'learning_rate': 1.4612553247776493e-05, 'epoch': 0.37}
{'loss': 0.8822, 'learning_rate': 1.4605640972883919e-05, 'epoch': 0.37}
{'loss': 0.8935, 'learning_rate': 1.4598725903857438e-05, 'epoch': 0.37}
{'loss': 0.7779, 'learning_rate': 1.4591808044892257e-05, 'epoch': 0.37}
{'loss': 0.76, 'learning_rate': 1.458488740018528e-05, 'epoch': 0.37}
{'loss': 0.7753, 'learning_rate': 1.4577963973935105e-05, 'epoch': 0.37}
{'loss': 0.8041, 'learning_rate': 1.4571037770342003e-05, 'epoch': 0.37}
{'loss': 0.8797, 'learning_rate': 1.4564108793607944e-05, 'epoch': 0.37}
{'loss': 0.8452, 'learning_rate': 1.4557177047936568e-05, 'epoch': 0.37}
{'loss': 0.8851, 'learning_rate': 1.455024253753321e-05, 'epoch': 0.37}
{'loss': 0.7852, 'learning_rate': 1.4543305266604873e-05, 'epoch': 0.37}
{'loss': 0.8623, 'learning_rate': 1.4536365239360231e-05, 'epoch': 0.37}
{'loss': 0.8855, 'learning_rate': 1.4529422460009635e-05, 'epoch': 0.37}
{'loss': 0.796, 'learning_rate': 1.4522476932765112e-05, 'epoch': 0.37}
{'loss': 0.9114, 'learning_rate': 1.4515528661840347e-05, 'epoch': 0.37}
{'loss': 0.9038, 'learning_rate': 1.450857765145069e-05, 'epoch': 0.37}
{'loss': 0.7692, 'learning_rate': 1.4501623905813161e-05, 'epoch': 0.37}
{'loss': 0.8661, 'learning_rate': 1.4494667429146426e-05, 'epoch': 0.37}
{'loss': 0.899, 'learning_rate': 1.448770822567082e-05, 'epoch': 0.37}
{'loss': 0.9178, 'learning_rate': 1.4480746299608326e-05, 'epoch': 0.37}
{'loss': 0.8486, 'learning_rate': 1.4473781655182582e-05, 'epoch': 0.37}
{'loss': 0.7842, 'learning_rate': 1.4466814296618875e-05, 'epoch': 0.37}
{'loss': 0.8901, 'learning_rate': 1.4459844228144134e-05, 'epoch': 0.37}
{'loss': 0.8213, 'learning_rate': 1.4452871453986936e-05, 'epoch': 0.37}
{'loss': 0.8857, 'learning_rate': 1.4445895978377504e-05, 'epoch': 0.37}
{'loss': 0.8745, 'learning_rate': 1.4438917805547687e-05, 'epoch': 0.37}
{'loss': 0.7415, 'learning_rate': 1.4431936939730984e-05, 'epoch': 0.37}
{'loss': 0.811, 'learning_rate': 1.4424953385162522e-05, 'epoch': 0.37}
{'loss': 0.7879, 'learning_rate': 1.4417967146079053e-05, 'epoch': 0.37}
{'loss': 0.8506, 'learning_rate': 1.4410978226718966e-05, 'epoch': 0.37}
{'loss': 0.8747, 'learning_rate': 1.4403986631322278e-05, 'epoch': 0.37}
{'loss': 0.8569, 'learning_rate': 1.4396992364130624e-05, 'epoch': 0.37}
{'loss': 0.8817, 'learning_rate': 1.4389995429387258e-05, 'epoch': 0.37}
{'loss': 0.8544, 'learning_rate': 1.4382995831337058e-05, 'epoch': 0.37}
{'loss': 0.849, 'learning_rate': 1.4375993574226515e-05, 'epoch': 0.38}
{'loss': 0.9016, 'learning_rate': 1.4368988662303733e-05, 'epoch': 0.38}
{'loss': 0.8685, 'learning_rate': 1.4361981099818425e-05, 'epoch': 0.38}
{'loss': 0.8955, 'learning_rate': 1.4354970891021918e-05, 'epoch': 0.38}
{'loss': 0.7713, 'learning_rate': 1.4347958040167138e-05, 'epoch': 0.38}
{'loss': 0.8635, 'learning_rate': 1.4340942551508619e-05, 'epoch': 0.38}
{'loss': 0.8506, 'learning_rate': 1.4333924429302489e-05, 'epoch': 0.38}
{'loss': 0.8622, 'learning_rate': 1.4326903677806481e-05, 'epoch': 0.38}
{'loss': 0.7846, 'learning_rate': 1.4319880301279918e-05, 'epoch': 0.38}
{'loss': 0.7968, 'learning_rate': 1.4312854303983715e-05, 'epoch': 0.38}
{'loss': 0.8121, 'learning_rate': 1.4305825690180383e-05, 'epoch': 0.38}
{'loss': 0.9544, 'learning_rate': 1.4298794464134015e-05, 'epoch': 0.38}
{'loss': 0.8556, 'learning_rate': 1.429176063011029e-05, 'epoch': 0.38}
{'loss': 0.7487, 'learning_rate': 1.4284724192376467e-05, 'epoch': 0.38}
{'loss': 0.7719, 'learning_rate': 1.4277685155201392e-05, 'epoch': 0.38}
{'loss': 0.8691, 'learning_rate': 1.427064352285548e-05, 'epoch': 0.38}
{'loss': 0.789, 'learning_rate': 1.4263599299610725e-05, 'epoch': 0.38}
{'loss': 0.8573, 'learning_rate': 1.425655248974069e-05, 'epoch': 0.38}
{'loss': 0.832, 'learning_rate': 1.4249503097520507e-05, 'epoch': 0.38}
{'loss': 0.8713, 'learning_rate': 1.4242451127226877e-05, 'epoch': 0.38}
{'loss': 0.8658, 'learning_rate': 1.423539658313807e-05, 'epoch': 0.38}
{'loss': 0.8595, 'learning_rate': 1.4228339469533902e-05, 'epoch': 0.38}
{'loss': 0.8714, 'learning_rate': 1.4221279790695768e-05, 'epoch': 0.38}
{'loss': 0.7904, 'learning_rate': 1.4214217550906602e-05, 'epoch': 0.38}
{'loss': 0.8455, 'learning_rate': 1.4207152754450902e-05, 'epoch': 0.38}
{'loss': 0.7913, 'learning_rate': 1.420008540561471e-05, 'epoch': 0.38}
{'loss': 0.8699, 'learning_rate': 1.4193015508685618e-05, 'epoch': 0.38}
{'loss': 0.8924, 'learning_rate': 1.4185943067952776e-05, 'epoch': 0.38}
{'loss': 0.8371, 'learning_rate': 1.4178868087706858e-05, 'epoch': 0.38}
{'loss': 0.8448, 'learning_rate': 1.4171790572240092e-05, 'epoch': 0.38}
{'loss': 0.8413, 'learning_rate': 1.4164710525846238e-05, 'epoch': 0.38}
{'loss': 0.9354, 'learning_rate': 1.4157627952820598e-05, 'epoch': 0.38}
{'loss': 0.9241, 'learning_rate': 1.4150542857459995e-05, 'epoch': 0.38}
{'loss': 0.8599, 'learning_rate': 1.4143455244062796e-05, 'epoch': 0.38}
{'loss': 0.7515, 'learning_rate': 1.4136365116928883e-05, 'epoch': 0.38}
{'loss': 0.7892, 'learning_rate': 1.4129272480359674e-05, 'epoch': 0.38}
{'loss': 0.8898, 'learning_rate': 1.4122177338658101e-05, 'epoch': 0.38}
{'loss': 0.883, 'learning_rate': 1.4115079696128624e-05, 'epoch': 0.38}
{'loss': 0.8397, 'learning_rate': 1.4107979557077212e-05, 'epoch': 0.38}
{'loss': 0.8106, 'learning_rate': 1.4100876925811355e-05, 'epoch': 0.38}
{'loss': 0.8944, 'learning_rate': 1.4093771806640046e-05, 'epoch': 0.38}
[2025-12-09 17:18:26,009] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step8000 is about to be saved!
[2025-12-09 17:18:26,100] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8000/global_step8000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 17:18:26,101] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8000/global_step8000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 17:18:26,256] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8000/global_step8000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 17:18:26,264] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8000/global_step8000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 17:19:15,634] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8000/global_step8000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 17:19:15,638] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8000/global_step8000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 17:19:15,650] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step8000 is ready now!
{'loss': 0.8531, 'learning_rate': 1.4086664203873803e-05, 'epoch': 0.39}
{'loss': 0.8834, 'learning_rate': 1.4079554121824633e-05, 'epoch': 0.39}
{'loss': 0.8246, 'learning_rate': 1.4072441564806055e-05, 'epoch': 0.39}
{'loss': 0.8709, 'learning_rate': 1.4065326537133094e-05, 'epoch': 0.39}
{'loss': 0.8692, 'learning_rate': 1.4058209043122273e-05, 'epoch': 0.39}
{'loss': 0.8552, 'learning_rate': 1.40510890870916e-05, 'epoch': 0.39}
{'loss': 0.8799, 'learning_rate': 1.404396667336059e-05, 'epoch': 0.39}
{'loss': 0.8732, 'learning_rate': 1.4036841806250242e-05, 'epoch': 0.39}
{'loss': 0.8553, 'learning_rate': 1.4029714490083043e-05, 'epoch': 0.39}
{'loss': 0.7569, 'learning_rate': 1.4022584729182973e-05, 'epoch': 0.39}
{'loss': 0.8607, 'learning_rate': 1.4015452527875487e-05, 'epoch': 0.39}
{'loss': 0.7789, 'learning_rate': 1.4008317890487522e-05, 'epoch': 0.39}
{'loss': 0.7831, 'learning_rate': 1.4001180821347492e-05, 'epoch': 0.39}
{'loss': 0.8358, 'learning_rate': 1.3994041324785298e-05, 'epoch': 0.39}
{'loss': 0.8092, 'learning_rate': 1.3986899405132297e-05, 'epoch': 0.39}
{'loss': 0.8485, 'learning_rate': 1.3979755066721327e-05, 'epoch': 0.39}
{'loss': 0.833, 'learning_rate': 1.397260831388669e-05, 'epoch': 0.39}
{'loss': 0.9001, 'learning_rate': 1.3965459150964146e-05, 'epoch': 0.39}
{'loss': 0.8708, 'learning_rate': 1.3958307582290932e-05, 'epoch': 0.39}
{'loss': 0.805, 'learning_rate': 1.3951153612205732e-05, 'epoch': 0.39}
{'loss': 0.8213, 'learning_rate': 1.394399724504869e-05, 'epoch': 0.39}
{'loss': 0.8473, 'learning_rate': 1.3936838485161413e-05, 'epoch': 0.39}
{'loss': 0.8678, 'learning_rate': 1.3929677336886945e-05, 'epoch': 0.39}
{'loss': 0.8441, 'learning_rate': 1.3922513804569784e-05, 'epoch': 0.39}
{'loss': 0.8083, 'learning_rate': 1.3915347892555887e-05, 'epoch': 0.39}
{'loss': 0.8527, 'learning_rate': 1.3908179605192631e-05, 'epoch': 0.39}
{'loss': 0.8691, 'learning_rate': 1.3901008946828856e-05, 'epoch': 0.39}
{'loss': 0.8625, 'learning_rate': 1.3893835921814826e-05, 'epoch': 0.39}
{'loss': 0.7023, 'learning_rate': 1.388666053450225e-05, 'epoch': 0.39}
{'loss': 0.8672, 'learning_rate': 1.3879482789244267e-05, 'epoch': 0.39}
{'loss': 0.8691, 'learning_rate': 1.3872302690395445e-05, 'epoch': 0.39}
{'loss': 0.8899, 'learning_rate': 1.3865120242311778e-05, 'epoch': 0.39}
{'loss': 0.8394, 'learning_rate': 1.3857935449350695e-05, 'epoch': 0.39}
{'loss': 0.8329, 'learning_rate': 1.3850748315871031e-05, 'epoch': 0.39}
{'loss': 0.8876, 'learning_rate': 1.3843558846233061e-05, 'epoch': 0.39}
{'loss': 0.8621, 'learning_rate': 1.3836367044798458e-05, 'epoch': 0.39}
{'loss': 0.8437, 'learning_rate': 1.3829172915930322e-05, 'epoch': 0.39}
{'loss': 0.8543, 'learning_rate': 1.3821976463993161e-05, 'epoch': 0.39}
{'loss': 0.7659, 'learning_rate': 1.3814777693352899e-05, 'epoch': 0.39}
{'loss': 0.7401, 'learning_rate': 1.3807576608376851e-05, 'epoch': 0.39}
{'loss': 0.8221, 'learning_rate': 1.3800373213433748e-05, 'epoch': 0.39}
{'loss': 0.803, 'learning_rate': 1.3793167512893728e-05, 'epoch': 0.39}
{'loss': 0.7406, 'learning_rate': 1.3785959511128311e-05, 'epoch': 0.4}
{'loss': 0.7991, 'learning_rate': 1.3778749212510426e-05, 'epoch': 0.4}
{'loss': 0.8856, 'learning_rate': 1.3771536621414387e-05, 'epoch': 0.4}
{'loss': 0.8951, 'learning_rate': 1.3764321742215907e-05, 'epoch': 0.4}
{'loss': 0.6754, 'learning_rate': 1.3757104579292082e-05, 'epoch': 0.4}
{'loss': 0.7698, 'learning_rate': 1.3749885137021399e-05, 'epoch': 0.4}
{'loss': 0.8353, 'learning_rate': 1.3742663419783717e-05, 'epoch': 0.4}
{'loss': 0.7805, 'learning_rate': 1.3735439431960287e-05, 'epoch': 0.4}
{'loss': 0.835, 'learning_rate': 1.3728213177933727e-05, 'epoch': 0.4}
{'loss': 0.8853, 'learning_rate': 1.3720984662088042e-05, 'epoch': 0.4}
{'loss': 0.799, 'learning_rate': 1.3713753888808594e-05, 'epoch': 0.4}
{'loss': 0.8675, 'learning_rate': 1.3706520862482128e-05, 'epoch': 0.4}
{'loss': 0.8332, 'learning_rate': 1.3699285587496752e-05, 'epoch': 0.4}
{'loss': 0.8334, 'learning_rate': 1.3692048068241936e-05, 'epoch': 0.4}
{'loss': 0.8074, 'learning_rate': 1.3684808309108508e-05, 'epoch': 0.4}
{'loss': 0.8992, 'learning_rate': 1.3677566314488664e-05, 'epoch': 0.4}
{'loss': 0.8566, 'learning_rate': 1.3670322088775952e-05, 'epoch': 0.4}
{'loss': 0.8671, 'learning_rate': 1.3663075636365268e-05, 'epoch': 0.4}
{'loss': 0.7008, 'learning_rate': 1.3655826961652871e-05, 'epoch': 0.4}
{'loss': 0.9031, 'learning_rate': 1.3648576069036356e-05, 'epoch': 0.4}
{'loss': 0.9224, 'learning_rate': 1.3641322962914669e-05, 'epoch': 0.4}
{'loss': 0.8177, 'learning_rate': 1.36340676476881e-05, 'epoch': 0.4}
{'loss': 0.7809, 'learning_rate': 1.3626810127758283e-05, 'epoch': 0.4}
{'loss': 0.8579, 'learning_rate': 1.3619550407528175e-05, 'epoch': 0.4}
{'loss': 0.874, 'learning_rate': 1.3612288491402084e-05, 'epoch': 0.4}
{'loss': 0.7217, 'learning_rate': 1.360502438378564e-05, 'epoch': 0.4}
{'loss': 0.748, 'learning_rate': 1.3597758089085807e-05, 'epoch': 0.4}
{'loss': 0.8963, 'learning_rate': 1.3590489611710874e-05, 'epoch': 0.4}
{'loss': 0.867, 'learning_rate': 1.3583218956070457e-05, 'epoch': 0.4}
{'loss': 0.8681, 'learning_rate': 1.357594612657549e-05, 'epoch': 0.4}
{'loss': 0.7779, 'learning_rate': 1.3568671127638231e-05, 'epoch': 0.4}
{'loss': 0.8297, 'learning_rate': 1.3561393963672243e-05, 'epoch': 0.4}
{'loss': 0.8678, 'learning_rate': 1.3554114639092414e-05, 'epoch': 0.4}
{'loss': 0.8068, 'learning_rate': 1.3546833158314944e-05, 'epoch': 0.4}
{'loss': 0.8154, 'learning_rate': 1.353954952575733e-05, 'epoch': 0.4}
{'loss': 0.7427, 'learning_rate': 1.3532263745838381e-05, 'epoch': 0.4}
{'loss': 0.8903, 'learning_rate': 1.3524975822978206e-05, 'epoch': 0.4}
{'loss': 0.7037, 'learning_rate': 1.3517685761598223e-05, 'epoch': 0.4}
{'loss': 0.7754, 'learning_rate': 1.3510393566121134e-05, 'epoch': 0.4}
{'loss': 0.7506, 'learning_rate': 1.3503099240970945e-05, 'epoch': 0.4}
{'loss': 0.8528, 'learning_rate': 1.3495802790572949e-05, 'epoch': 0.4}
{'loss': 0.8071, 'learning_rate': 1.3488504219353736e-05, 'epoch': 0.4}
{'loss': 0.7828, 'learning_rate': 1.348120353174117e-05, 'epoch': 0.41}
{'loss': 0.8458, 'learning_rate': 1.3473900732164414e-05, 'epoch': 0.41}
{'loss': 0.8507, 'learning_rate': 1.3466595825053896e-05, 'epoch': 0.41}
{'loss': 0.8812, 'learning_rate': 1.3459288814841339e-05, 'epoch': 0.41}
{'loss': 0.9014, 'learning_rate': 1.3451979705959729e-05, 'epoch': 0.41}
{'loss': 0.8266, 'learning_rate': 1.344466850284333e-05, 'epoch': 0.41}
{'loss': 0.9195, 'learning_rate': 1.343735520992768e-05, 'epoch': 0.41}
{'loss': 0.8329, 'learning_rate': 1.3430039831649579e-05, 'epoch': 0.41}
{'loss': 0.7742, 'learning_rate': 1.3422722372447098e-05, 'epoch': 0.41}
{'loss': 0.8173, 'learning_rate': 1.3415402836759563e-05, 'epoch': 0.41}
{'loss': 0.7932, 'learning_rate': 1.340808122902757e-05, 'epoch': 0.41}
{'loss': 0.8383, 'learning_rate': 1.3400757553692955e-05, 'epoch': 0.41}
{'loss': 0.9134, 'learning_rate': 1.3393431815198831e-05, 'epoch': 0.41}
{'loss': 0.8368, 'learning_rate': 1.3386104017989543e-05, 'epoch': 0.41}
{'loss': 0.791, 'learning_rate': 1.33787741665107e-05, 'epoch': 0.41}
{'loss': 0.7543, 'learning_rate': 1.3371442265209145e-05, 'epoch': 0.41}
[2025-12-09 17:44:22,510] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step8500 is about to be saved!
[2025-12-09 17:44:22,603] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8500/global_step8500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 17:44:22,604] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8500/global_step8500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 17:44:23,310] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8500/global_step8500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 17:44:23,314] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8500/global_step8500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 17:45:11,237] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8500/global_step8500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 17:45:11,240] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-8500/global_step8500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 17:45:18,736] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step8500 is ready now!
{'loss': 0.8186, 'learning_rate': 1.336410831853297e-05, 'epoch': 0.41}
{'loss': 0.7721, 'learning_rate': 1.335677233093151e-05, 'epoch': 0.41}
{'loss': 0.7472, 'learning_rate': 1.3349434306855335e-05, 'epoch': 0.41}
{'loss': 0.9182, 'learning_rate': 1.3342094250756248e-05, 'epoch': 0.41}
{'loss': 0.8219, 'learning_rate': 1.3334752167087295e-05, 'epoch': 0.41}
{'loss': 0.8729, 'learning_rate': 1.332740806030274e-05, 'epoch': 0.41}
{'loss': 0.8519, 'learning_rate': 1.3320061934858083e-05, 'epoch': 0.41}
{'loss': 0.8258, 'learning_rate': 1.3312713795210041e-05, 'epoch': 0.41}
{'loss': 0.8346, 'learning_rate': 1.3305363645816564e-05, 'epoch': 0.41}
{'loss': 0.914, 'learning_rate': 1.3298011491136808e-05, 'epoch': 0.41}
{'loss': 0.8458, 'learning_rate': 1.3290657335631153e-05, 'epoch': 0.41}
{'loss': 0.8302, 'learning_rate': 1.3283301183761194e-05, 'epoch': 0.41}
{'loss': 0.8288, 'learning_rate': 1.3275943039989735e-05, 'epoch': 0.41}
{'loss': 0.8069, 'learning_rate': 1.3268582908780788e-05, 'epoch': 0.41}
{'loss': 0.854, 'learning_rate': 1.3261220794599569e-05, 'epoch': 0.41}
{'loss': 0.8616, 'learning_rate': 1.3253856701912507e-05, 'epoch': 0.41}
{'loss': 0.8416, 'learning_rate': 1.3246490635187214e-05, 'epoch': 0.41}
{'loss': 0.873, 'learning_rate': 1.3239122598892516e-05, 'epoch': 0.41}
{'loss': 0.7823, 'learning_rate': 1.3231752597498421e-05, 'epoch': 0.41}
{'loss': 0.834, 'learning_rate': 1.3224380635476142e-05, 'epoch': 0.41}
{'loss': 0.7965, 'learning_rate': 1.3217006717298066e-05, 'epoch': 0.41}
{'loss': 0.8343, 'learning_rate': 1.3209630847437787e-05, 'epoch': 0.41}
{'loss': 0.8377, 'learning_rate': 1.3202253030370062e-05, 'epoch': 0.41}
{'loss': 0.8211, 'learning_rate': 1.3194873270570845e-05, 'epoch': 0.41}
{'loss': 0.8622, 'learning_rate': 1.3187491572517257e-05, 'epoch': 0.41}
{'loss': 0.8388, 'learning_rate': 1.3180107940687607e-05, 'epoch': 0.42}
{'loss': 0.8518, 'learning_rate': 1.3172722379561363e-05, 'epoch': 0.42}
{'loss': 0.8592, 'learning_rate': 1.3165334893619175e-05, 'epoch': 0.42}
{'loss': 0.79, 'learning_rate': 1.3157945487342855e-05, 'epoch': 0.42}
{'loss': 0.7668, 'learning_rate': 1.3150554165215387e-05, 'epoch': 0.42}
{'loss': 0.7972, 'learning_rate': 1.3143160931720906e-05, 'epoch': 0.42}
{'loss': 0.7632, 'learning_rate': 1.3135765791344715e-05, 'epoch': 0.42}
{'loss': 0.7599, 'learning_rate': 1.3128368748573272e-05, 'epoch': 0.42}
{'loss': 0.8193, 'learning_rate': 1.3120969807894186e-05, 'epoch': 0.42}
{'loss': 0.8672, 'learning_rate': 1.3113568973796224e-05, 'epoch': 0.42}
{'loss': 0.7703, 'learning_rate': 1.3106166250769297e-05, 'epoch': 0.42}
{'loss': 0.8401, 'learning_rate': 1.3098761643304461e-05, 'epoch': 0.42}
{'loss': 0.9451, 'learning_rate': 1.3091355155893912e-05, 'epoch': 0.42}
{'loss': 0.7916, 'learning_rate': 1.3083946793031003e-05, 'epoch': 0.42}
{'loss': 0.8987, 'learning_rate': 1.3076536559210204e-05, 'epoch': 0.42}
{'loss': 0.6054, 'learning_rate': 1.3069124458927136e-05, 'epoch': 0.42}
{'loss': 0.9229, 'learning_rate': 1.306171049667854e-05, 'epoch': 0.42}
{'loss': 0.7614, 'learning_rate': 1.3054294676962294e-05, 'epoch': 0.42}
{'loss': 0.8545, 'learning_rate': 1.30468770042774e-05, 'epoch': 0.42}
{'loss': 0.8112, 'learning_rate': 1.303945748312399e-05, 'epoch': 0.42}
{'loss': 0.8191, 'learning_rate': 1.303203611800331e-05, 'epoch': 0.42}
{'loss': 0.8088, 'learning_rate': 1.3024612913417725e-05, 'epoch': 0.42}
{'loss': 0.8309, 'learning_rate': 1.3017187873870721e-05, 'epoch': 0.42}
{'loss': 0.8178, 'learning_rate': 1.3009761003866892e-05, 'epoch': 0.42}
WARNING: tokenization mismatch: 1 vs. 1590. (ignored)
{'loss': 0.7458, 'learning_rate': 1.3002332307911952e-05, 'epoch': 0.42}
{'loss': 0.6727, 'learning_rate': 1.2994901790512708e-05, 'epoch': 0.42}
{'loss': 0.8747, 'learning_rate': 1.2987469456177084e-05, 'epoch': 0.42}
{'loss': 0.8221, 'learning_rate': 1.29800353094141e-05, 'epoch': 0.42}
{'loss': 0.7472, 'learning_rate': 1.2972599354733879e-05, 'epoch': 0.42}
{'loss': 0.7799, 'learning_rate': 1.2965161596647639e-05, 'epoch': 0.42}
{'loss': 0.8414, 'learning_rate': 1.2957722039667698e-05, 'epoch': 0.42}
{'loss': 0.8762, 'learning_rate': 1.295028068830745e-05, 'epoch': 0.42}
{'loss': 0.7582, 'learning_rate': 1.2942837547081396e-05, 'epoch': 0.42}
{'loss': 0.9446, 'learning_rate': 1.293539262050511e-05, 'epoch': 0.42}
{'loss': 0.8633, 'learning_rate': 1.2927945913095256e-05, 'epoch': 0.42}
{'loss': 0.8253, 'learning_rate': 1.2920497429369574e-05, 'epoch': 0.42}
{'loss': 0.8762, 'learning_rate': 1.2913047173846884e-05, 'epoch': 0.42}
{'loss': 0.8722, 'learning_rate': 1.290559515104708e-05, 'epoch': 0.42}
{'loss': 0.8282, 'learning_rate': 1.2898141365491132e-05, 'epoch': 0.42}
{'loss': 0.8489, 'learning_rate': 1.2890685821701074e-05, 'epoch': 0.42}
{'loss': 0.8514, 'learning_rate': 1.2883228524200006e-05, 'epoch': 0.42}
{'loss': 0.8451, 'learning_rate': 1.2875769477512101e-05, 'epoch': 0.42}
{'loss': 0.7988, 'learning_rate': 1.2868308686162583e-05, 'epoch': 0.43}
{'loss': 0.9299, 'learning_rate': 1.286084615467774e-05, 'epoch': 0.43}
{'loss': 0.8651, 'learning_rate': 1.285338188758491e-05, 'epoch': 0.43}
{'loss': 0.8889, 'learning_rate': 1.2845915889412492e-05, 'epoch': 0.43}
{'loss': 0.7891, 'learning_rate': 1.2838448164689932e-05, 'epoch': 0.43}
{'loss': 0.8395, 'learning_rate': 1.283097871794772e-05, 'epoch': 0.43}
{'loss': 0.7664, 'learning_rate': 1.2823507553717394e-05, 'epoch': 0.43}
{'loss': 0.8597, 'learning_rate': 1.2816034676531534e-05, 'epoch': 0.43}
{'loss': 0.7535, 'learning_rate': 1.280856009092376e-05, 'epoch': 0.43}
{'loss': 0.8715, 'learning_rate': 1.2801083801428724e-05, 'epoch': 0.43}
{'loss': 0.8412, 'learning_rate': 1.2793605812582114e-05, 'epoch': 0.43}
{'loss': 0.9015, 'learning_rate': 1.2786126128920655e-05, 'epoch': 0.43}
{'loss': 0.8093, 'learning_rate': 1.2778644754982091e-05, 'epoch': 0.43}
{'loss': 0.8391, 'learning_rate': 1.2771161695305198e-05, 'epoch': 0.43}
{'loss': 0.7943, 'learning_rate': 1.2763676954429766e-05, 'epoch': 0.43}
{'loss': 0.7956, 'learning_rate': 1.275619053689662e-05, 'epoch': 0.43}
{'loss': 0.8313, 'learning_rate': 1.2748702447247587e-05, 'epoch': 0.43}
{'loss': 0.7909, 'learning_rate': 1.2741212690025514e-05, 'epoch': 0.43}
{'loss': 0.8991, 'learning_rate': 1.2733721269774267e-05, 'epoch': 0.43}
{'loss': 0.9224, 'learning_rate': 1.2726228191038705e-05, 'epoch': 0.43}
{'loss': 0.8294, 'learning_rate': 1.271873345836471e-05, 'epoch': 0.43}
{'loss': 0.7226, 'learning_rate': 1.2711237076299155e-05, 'epoch': 0.43}
{'loss': 0.8669, 'learning_rate': 1.270373904938992e-05, 'epoch': 0.43}
{'loss': 0.8439, 'learning_rate': 1.2696239382185884e-05, 'epoch': 0.43}
{'loss': 0.8397, 'learning_rate': 1.2688738079236917e-05, 'epoch': 0.43}
{'loss': 0.8068, 'learning_rate': 1.2681235145093878e-05, 'epoch': 0.43}
{'loss': 0.818, 'learning_rate': 1.2673730584308629e-05, 'epoch': 0.43}
{'loss': 0.7752, 'learning_rate': 1.2666224401434003e-05, 'epoch': 0.43}
{'loss': 0.8282, 'learning_rate': 1.2658716601023824e-05, 'epoch': 0.43}
{'loss': 0.7915, 'learning_rate': 1.2651207187632903e-05, 'epoch': 0.43}
{'loss': 0.8312, 'learning_rate': 1.2643696165817026e-05, 'epoch': 0.43}
{'loss': 0.893, 'learning_rate': 1.2636183540132945e-05, 'epoch': 0.43}
{'loss': 0.7432, 'learning_rate': 1.2628669315138395e-05, 'epoch': 0.43}
[2025-12-09 18:10:49,500] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step9000 is about to be saved!
[2025-12-09 18:10:49,532] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9000/global_step9000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 18:10:49,532] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9000/global_step9000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 18:10:49,691] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9000/global_step9000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 18:10:49,694] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9000/global_step9000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 18:11:26,458] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9000/global_step9000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 18:11:26,461] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9000/global_step9000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 18:11:30,870] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step9000 is ready now!
{'loss': 0.7894, 'learning_rate': 1.2621153495392086e-05, 'epoch': 0.43}
{'loss': 0.8762, 'learning_rate': 1.2613636085453682e-05, 'epoch': 0.43}
{'loss': 0.8164, 'learning_rate': 1.2606117089883822e-05, 'epoch': 0.43}
{'loss': 0.8046, 'learning_rate': 1.2598596513244099e-05, 'epoch': 0.43}
{'loss': 0.8468, 'learning_rate': 1.2591074360097078e-05, 'epoch': 0.43}
{'loss': 0.675, 'learning_rate': 1.2583550635006263e-05, 'epoch': 0.43}
{'loss': 0.8478, 'learning_rate': 1.2576025342536129e-05, 'epoch': 0.43}
{'loss': 0.8921, 'learning_rate': 1.2568498487252086e-05, 'epoch': 0.43}
{'loss': 0.7419, 'learning_rate': 1.2560970073720506e-05, 'epoch': 0.44}
{'loss': 0.8422, 'learning_rate': 1.2553440106508696e-05, 'epoch': 0.44}
{'loss': 0.8155, 'learning_rate': 1.2545908590184914e-05, 'epoch': 0.44}
{'loss': 0.827, 'learning_rate': 1.253837552931835e-05, 'epoch': 0.44}
{'loss': 0.8213, 'learning_rate': 1.2530840928479132e-05, 'epoch': 0.44}
{'loss': 0.8333, 'learning_rate': 1.2523304792238332e-05, 'epoch': 0.44}
{'loss': 0.8218, 'learning_rate': 1.2515767125167944e-05, 'epoch': 0.44}
{'loss': 0.8468, 'learning_rate': 1.2508227931840888e-05, 'epoch': 0.44}
{'loss': 0.8399, 'learning_rate': 1.2500687216831022e-05, 'epoch': 0.44}
{'loss': 0.855, 'learning_rate': 1.2493144984713119e-05, 'epoch': 0.44}
{'loss': 0.832, 'learning_rate': 1.2485601240062868e-05, 'epoch': 0.44}
{'loss': 0.7804, 'learning_rate': 1.2478055987456887e-05, 'epoch': 0.44}
{'loss': 0.8375, 'learning_rate': 1.2470509231472698e-05, 'epoch': 0.44}
{'loss': 0.8343, 'learning_rate': 1.246296097668875e-05, 'epoch': 0.44}
{'loss': 0.8388, 'learning_rate': 1.2455411227684377e-05, 'epoch': 0.44}
{'loss': 0.8285, 'learning_rate': 1.2447859989039848e-05, 'epoch': 0.44}
{'loss': 0.8884, 'learning_rate': 1.244030726533631e-05, 'epoch': 0.44}
{'loss': 0.8411, 'learning_rate': 1.2432753061155833e-05, 'epoch': 0.44}
{'loss': 0.8025, 'learning_rate': 1.2425197381081364e-05, 'epoch': 0.44}
{'loss': 0.7575, 'learning_rate': 1.2417640229696766e-05, 'epoch': 0.44}
{'loss': 0.8376, 'learning_rate': 1.2410081611586775e-05, 'epoch': 0.44}
{'loss': 0.8946, 'learning_rate': 1.240252153133704e-05, 'epoch': 0.44}
{'loss': 0.7666, 'learning_rate': 1.2394959993534069e-05, 'epoch': 0.44}
{'loss': 0.8375, 'learning_rate': 1.2387397002765277e-05, 'epoch': 0.44}
{'loss': 0.8341, 'learning_rate': 1.2379832563618952e-05, 'epoch': 0.44}
{'loss': 0.7441, 'learning_rate': 1.2372266680684259e-05, 'epoch': 0.44}
{'loss': 0.8036, 'learning_rate': 1.2364699358551245e-05, 'epoch': 0.44}
{'loss': 0.7963, 'learning_rate': 1.235713060181082e-05, 'epoch': 0.44}
{'loss': 0.8691, 'learning_rate': 1.2349560415054775e-05, 'epoch': 0.44}
{'loss': 0.8079, 'learning_rate': 1.234198880287576e-05, 'epoch': 0.44}
{'loss': 0.7327, 'learning_rate': 1.23344157698673e-05, 'epoch': 0.44}
{'loss': 0.795, 'learning_rate': 1.2326841320623769e-05, 'epoch': 0.44}
{'loss': 0.8948, 'learning_rate': 1.2319265459740412e-05, 'epoch': 0.44}
{'loss': 0.8461, 'learning_rate': 1.2311688191813323e-05, 'epoch': 0.44}
{'loss': 0.8451, 'learning_rate': 1.2304109521439453e-05, 'epoch': 0.44}
{'loss': 0.857, 'learning_rate': 1.22965294532166e-05, 'epoch': 0.44}
{'loss': 0.8179, 'learning_rate': 1.228894799174342e-05, 'epoch': 0.44}
{'loss': 0.8734, 'learning_rate': 1.2281365141619397e-05, 'epoch': 0.44}
{'loss': 0.8218, 'learning_rate': 1.2273780907444875e-05, 'epoch': 0.44}
{'loss': 0.9162, 'learning_rate': 1.2266195293821027e-05, 'epoch': 0.44}
{'loss': 0.7832, 'learning_rate': 1.225860830534987e-05, 'epoch': 0.44}
{'loss': 0.8154, 'learning_rate': 1.2251019946634246e-05, 'epoch': 0.44}
{'loss': 0.8703, 'learning_rate': 1.2243430222277835e-05, 'epoch': 0.45}
{'loss': 0.729, 'learning_rate': 1.2235839136885148e-05, 'epoch': 0.45}
{'loss': 0.8582, 'learning_rate': 1.2228246695061511e-05, 'epoch': 0.45}
{'loss': 0.8251, 'learning_rate': 1.2220652901413086e-05, 'epoch': 0.45}
{'loss': 0.7947, 'learning_rate': 1.2213057760546845e-05, 'epoch': 0.45}
{'loss': 0.8666, 'learning_rate': 1.2205461277070584e-05, 'epoch': 0.45}
{'loss': 0.8031, 'learning_rate': 1.2197863455592906e-05, 'epoch': 0.45}
{'loss': 0.8578, 'learning_rate': 1.2190264300723238e-05, 'epoch': 0.45}
{'loss': 0.7754, 'learning_rate': 1.2182663817071801e-05, 'epoch': 0.45}
{'loss': 0.8379, 'learning_rate': 1.2175062009249631e-05, 'epoch': 0.45}
{'loss': 0.8217, 'learning_rate': 1.2167458881868566e-05, 'epoch': 0.45}
{'loss': 0.868, 'learning_rate': 1.2159854439541245e-05, 'epoch': 0.45}
{'loss': 0.7365, 'learning_rate': 1.2152248686881102e-05, 'epoch': 0.45}
{'loss': 0.9321, 'learning_rate': 1.2144641628502373e-05, 'epoch': 0.45}
{'loss': 0.7968, 'learning_rate': 1.213703326902008e-05, 'epoch': 0.45}
{'loss': 0.8942, 'learning_rate': 1.212942361305003e-05, 'epoch': 0.45}
{'loss': 0.84, 'learning_rate': 1.2121812665208827e-05, 'epoch': 0.45}
{'loss': 0.7286, 'learning_rate': 1.2114200430113854e-05, 'epoch': 0.45}
{'loss': 0.7228, 'learning_rate': 1.210658691238327e-05, 'epoch': 0.45}
{'loss': 0.8255, 'learning_rate': 1.2098972116636022e-05, 'epoch': 0.45}
{'loss': 0.7745, 'learning_rate': 1.2091356047491827e-05, 'epoch': 0.45}
{'loss': 0.7814, 'learning_rate': 1.2083738709571172e-05, 'epoch': 0.45}
{'loss': 0.811, 'learning_rate': 1.2076120107495317e-05, 'epoch': 0.45}
{'loss': 0.8521, 'learning_rate': 1.2068500245886288e-05, 'epoch': 0.45}
{'loss': 0.8005, 'learning_rate': 1.206087912936688e-05, 'epoch': 0.45}
{'loss': 0.8358, 'learning_rate': 1.2053256762560638e-05, 'epoch': 0.45}
{'loss': 0.8219, 'learning_rate': 1.204563315009188e-05, 'epoch': 0.45}
{'loss': 0.8488, 'learning_rate': 1.2038008296585667e-05, 'epoch': 0.45}
{'loss': 0.6742, 'learning_rate': 1.2030382206667816e-05, 'epoch': 0.45}
{'loss': 0.7335, 'learning_rate': 1.2022754884964902e-05, 'epoch': 0.45}
{'loss': 0.846, 'learning_rate': 1.201512633610424e-05, 'epoch': 0.45}
{'loss': 0.8533, 'learning_rate': 1.2007496564713888e-05, 'epoch': 0.45}
{'loss': 0.6701, 'learning_rate': 1.1999865575422652e-05, 'epoch': 0.45}
{'loss': 0.7969, 'learning_rate': 1.1992233372860068e-05, 'epoch': 0.45}
{'loss': 0.8242, 'learning_rate': 1.198459996165642e-05, 'epoch': 0.45}
{'loss': 0.8702, 'learning_rate': 1.1976965346442716e-05, 'epoch': 0.45}
{'loss': 0.8686, 'learning_rate': 1.1969329531850697e-05, 'epoch': 0.45}
{'loss': 0.7867, 'learning_rate': 1.1961692522512834e-05, 'epoch': 0.45}
{'loss': 0.7308, 'learning_rate': 1.1954054323062317e-05, 'epoch': 0.45}
{'loss': 0.9168, 'learning_rate': 1.1946414938133065e-05, 'epoch': 0.45}
{'loss': 0.8335, 'learning_rate': 1.193877437235971e-05, 'epoch': 0.45}
{'loss': 0.9161, 'learning_rate': 1.1931132630377607e-05, 'epoch': 0.46}
{'loss': 0.8343, 'learning_rate': 1.1923489716822818e-05, 'epoch': 0.46}
{'loss': 0.7545, 'learning_rate': 1.191584563633212e-05, 'epoch': 0.46}
{'loss': 0.8255, 'learning_rate': 1.1908200393542995e-05, 'epoch': 0.46}
{'loss': 0.8098, 'learning_rate': 1.190055399309363e-05, 'epoch': 0.46}
{'loss': 0.7836, 'learning_rate': 1.1892906439622923e-05, 'epoch': 0.46}
{'loss': 0.7109, 'learning_rate': 1.188525773777046e-05, 'epoch': 0.46}
{'loss': 0.807, 'learning_rate': 1.1877607892176527e-05, 'epoch': 0.46}
{'loss': 0.7488, 'learning_rate': 1.186995690748211e-05, 'epoch': 0.46}
[2025-12-09 18:36:45,712] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step9500 is about to be saved!
[2025-12-09 18:36:45,743] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9500/global_step9500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 18:36:45,744] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9500/global_step9500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 18:36:45,905] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9500/global_step9500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 18:36:45,908] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9500/global_step9500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 18:37:29,148] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9500/global_step9500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 18:37:29,151] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-9500/global_step9500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 18:37:30,525] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step9500 is ready now!
{'loss': 0.831, 'learning_rate': 1.1862304788328876e-05, 'epoch': 0.46}
{'loss': 0.8394, 'learning_rate': 1.1854651539359186e-05, 'epoch': 0.46}
{'loss': 0.8095, 'learning_rate': 1.1846997165216089e-05, 'epoch': 0.46}
{'loss': 0.8365, 'learning_rate': 1.1839341670543312e-05, 'epoch': 0.46}
{'loss': 0.8384, 'learning_rate': 1.1831685059985263e-05, 'epoch': 0.46}
{'loss': 0.8411, 'learning_rate': 1.1824027338187028e-05, 'epoch': 0.46}
{'loss': 0.7138, 'learning_rate': 1.1816368509794365e-05, 'epoch': 0.46}
{'loss': 0.8853, 'learning_rate': 1.1808708579453707e-05, 'epoch': 0.46}
{'loss': 0.8546, 'learning_rate': 1.1801047551812153e-05, 'epoch': 0.46}
{'loss': 0.8485, 'learning_rate': 1.1793385431517466e-05, 'epoch': 0.46}
{'loss': 0.7781, 'learning_rate': 1.1785722223218077e-05, 'epoch': 0.46}
{'loss': 0.9009, 'learning_rate': 1.177805793156307e-05, 'epoch': 0.46}
{'loss': 0.8747, 'learning_rate': 1.177039256120219e-05, 'epoch': 0.46}
{'loss': 0.8294, 'learning_rate': 1.1762726116785843e-05, 'epoch': 0.46}
{'loss': 0.9427, 'learning_rate': 1.1755058602965074e-05, 'epoch': 0.46}
{'loss': 0.8231, 'learning_rate': 1.1747390024391587e-05, 'epoch': 0.46}
{'loss': 0.8461, 'learning_rate': 1.1739720385717728e-05, 'epoch': 0.46}
{'loss': 0.7842, 'learning_rate': 1.173204969159648e-05, 'epoch': 0.46}
{'loss': 0.7748, 'learning_rate': 1.1724377946681482e-05, 'epoch': 0.46}
{'loss': 0.8594, 'learning_rate': 1.1716705155626993e-05, 'epoch': 0.46}
{'loss': 0.8842, 'learning_rate': 1.1709031323087918e-05, 'epoch': 0.46}
{'loss': 0.7315, 'learning_rate': 1.1701356453719787e-05, 'epoch': 0.46}
{'loss': 0.8717, 'learning_rate': 1.169368055217877e-05, 'epoch': 0.46}
{'loss': 0.8208, 'learning_rate': 1.168600362312165e-05, 'epoch': 0.46}
{'loss': 0.9193, 'learning_rate': 1.1678325671205841e-05, 'epoch': 0.46}
{'loss': 0.9109, 'learning_rate': 1.1670646701089374e-05, 'epoch': 0.46}
{'loss': 0.8203, 'learning_rate': 1.16629667174309e-05, 'epoch': 0.46}
{'loss': 0.7487, 'learning_rate': 1.1655285724889687e-05, 'epoch': 0.46}
{'loss': 0.8506, 'learning_rate': 1.1647603728125603e-05, 'epoch': 0.46}
{'loss': 0.7187, 'learning_rate': 1.1639920731799146e-05, 'epoch': 0.46}
{'loss': 0.769, 'learning_rate': 1.1632236740571403e-05, 'epoch': 0.46}
{'loss': 0.7862, 'learning_rate': 1.1624551759104075e-05, 'epoch': 0.46}
{'loss': 0.8085, 'learning_rate': 1.161686579205945e-05, 'epoch': 0.46}
{'loss': 0.8422, 'learning_rate': 1.1609178844100435e-05, 'epoch': 0.47}
{'loss': 0.7316, 'learning_rate': 1.160149091989051e-05, 'epoch': 0.47}
{'loss': 0.8287, 'learning_rate': 1.1593802024093765e-05, 'epoch': 0.47}
{'loss': 0.8716, 'learning_rate': 1.1586112161374867e-05, 'epoch': 0.47}
{'loss': 0.61, 'learning_rate': 1.1578421336399076e-05, 'epoch': 0.47}
{'loss': 0.8757, 'learning_rate': 1.1570729553832234e-05, 'epoch': 0.47}
{'loss': 0.7178, 'learning_rate': 1.156303681834077e-05, 'epoch': 0.47}
{'loss': 0.8498, 'learning_rate': 1.1555343134591674e-05, 'epoch': 0.47}
{'loss': 0.7414, 'learning_rate': 1.1547648507252534e-05, 'epoch': 0.47}
{'loss': 0.7634, 'learning_rate': 1.1539952940991495e-05, 'epoch': 0.47}
{'loss': 0.8372, 'learning_rate': 1.1532256440477273e-05, 'epoch': 0.47}
{'loss': 0.822, 'learning_rate': 1.1524559010379156e-05, 'epoch': 0.47}
{'loss': 0.7434, 'learning_rate': 1.1516860655366993e-05, 'epoch': 0.47}
{'loss': 0.749, 'learning_rate': 1.1509161380111198e-05, 'epoch': 0.47}
{'loss': 0.8183, 'learning_rate': 1.1501461189282734e-05, 'epoch': 0.47}
{'loss': 0.8416, 'learning_rate': 1.1493760087553133e-05, 'epoch': 0.47}
{'loss': 0.8676, 'learning_rate': 1.1486058079594461e-05, 'epoch': 0.47}
{'loss': 0.829, 'learning_rate': 1.1478355170079358e-05, 'epoch': 0.47}
{'loss': 0.8049, 'learning_rate': 1.1470651363680987e-05, 'epoch': 0.47}
{'loss': 0.8679, 'learning_rate': 1.1462946665073073e-05, 'epoch': 0.47}
{'loss': 0.7246, 'learning_rate': 1.1455241078929868e-05, 'epoch': 0.47}
{'loss': 0.8664, 'learning_rate': 1.1447534609926179e-05, 'epoch': 0.47}
{'loss': 0.7544, 'learning_rate': 1.143982726273733e-05, 'epoch': 0.47}
{'loss': 0.899, 'learning_rate': 1.1432119042039196e-05, 'epoch': 0.47}
{'loss': 0.7834, 'learning_rate': 1.1424409952508165e-05, 'epoch': 0.47}
{'loss': 0.8485, 'learning_rate': 1.141669999882116e-05, 'epoch': 0.47}
{'loss': 0.7164, 'learning_rate': 1.140898918565564e-05, 'epoch': 0.47}
{'loss': 0.8073, 'learning_rate': 1.140127751768956e-05, 'epoch': 0.47}
{'loss': 0.7907, 'learning_rate': 1.1393564999601415e-05, 'epoch': 0.47}
{'loss': 0.8241, 'learning_rate': 1.13858516360702e-05, 'epoch': 0.47}
{'loss': 0.8465, 'learning_rate': 1.137813743177544e-05, 'epoch': 0.47}
{'loss': 0.7751, 'learning_rate': 1.1370422391397158e-05, 'epoch': 0.47}
{'loss': 0.7903, 'learning_rate': 1.1362706519615889e-05, 'epoch': 0.47}
{'loss': 0.8334, 'learning_rate': 1.1354989821112667e-05, 'epoch': 0.47}
{'loss': 0.7557, 'learning_rate': 1.1347272300569034e-05, 'epoch': 0.47}
{'loss': 0.7993, 'learning_rate': 1.1339553962667024e-05, 'epoch': 0.47}
{'loss': 0.8486, 'learning_rate': 1.133183481208918e-05, 'epoch': 0.47}
{'loss': 0.8013, 'learning_rate': 1.1324114853518515e-05, 'epoch': 0.47}
{'loss': 0.8488, 'learning_rate': 1.1316394091638559e-05, 'epoch': 0.47}
{'loss': 0.8391, 'learning_rate': 1.1308672531133306e-05, 'epoch': 0.47}
{'loss': 0.8342, 'learning_rate': 1.1300950176687255e-05, 'epoch': 0.47}
{'loss': 0.8278, 'learning_rate': 1.129322703298537e-05, 'epoch': 0.47}
{'loss': 0.775, 'learning_rate': 1.12855031047131e-05, 'epoch': 0.48}
{'loss': 0.7326, 'learning_rate': 1.1277778396556376e-05, 'epoch': 0.48}
{'loss': 0.8368, 'learning_rate': 1.127005291320159e-05, 'epoch': 0.48}
{'loss': 0.7155, 'learning_rate': 1.1262326659335611e-05, 'epoch': 0.48}
{'loss': 0.7982, 'learning_rate': 1.1254599639645783e-05, 'epoch': 0.48}
{'loss': 0.8298, 'learning_rate': 1.1246871858819902e-05, 'epoch': 0.48}
{'loss': 0.8441, 'learning_rate': 1.1239143321546226e-05, 'epoch': 0.48}
{'loss': 0.843, 'learning_rate': 1.1231414032513484e-05, 'epoch': 0.48}
{'loss': 0.8847, 'learning_rate': 1.1223683996410847e-05, 'epoch': 0.48}
{'loss': 0.6838, 'learning_rate': 1.1215953217927956e-05, 'epoch': 0.48}
{'loss': 0.844, 'learning_rate': 1.120822170175488e-05, 'epoch': 0.48}
{'loss': 0.7857, 'learning_rate': 1.1200489452582156e-05, 'epoch': 0.48}
{'loss': 0.8441, 'learning_rate': 1.119275647510075e-05, 'epoch': 0.48}
{'loss': 0.8245, 'learning_rate': 1.1185022774002087e-05, 'epoch': 0.48}
{'loss': 0.8474, 'learning_rate': 1.1177288353978016e-05, 'epoch': 0.48}
{'loss': 0.831, 'learning_rate': 1.1169553219720828e-05, 'epoch': 0.48}
{'loss': 0.8875, 'learning_rate': 1.1161817375923243e-05, 'epoch': 0.48}
{'loss': 0.8686, 'learning_rate': 1.1154080827278422e-05, 'epoch': 0.48}
{'loss': 0.854, 'learning_rate': 1.1146343578479943e-05, 'epoch': 0.48}
{'loss': 0.814, 'learning_rate': 1.1138605634221815e-05, 'epoch': 0.48}
{'loss': 0.8251, 'learning_rate': 1.1130866999198461e-05, 'epoch': 0.48}
{'loss': 0.8719, 'learning_rate': 1.1123127678104734e-05, 'epoch': 0.48}
{'loss': 0.8246, 'learning_rate': 1.11153876756359e-05, 'epoch': 0.48}
{'loss': 0.8558, 'learning_rate': 1.1107646996487631e-05, 'epoch': 0.48}
{'loss': 0.8668, 'learning_rate': 1.1099905645356016e-05, 'epoch': 0.48}
[2025-12-09 19:02:13,540] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step10000 is about to be saved!
[2025-12-09 19:02:13,632] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10000/global_step10000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 19:02:13,633] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10000/global_step10000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 19:02:14,313] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10000/global_step10000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 19:02:14,315] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10000/global_step10000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 19:02:52,810] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10000/global_step10000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 19:02:52,822] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10000/global_step10000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 19:02:55,991] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step10000 is ready now!
{'loss': 0.7951, 'learning_rate': 1.1092163626937549e-05, 'epoch': 0.48}
{'loss': 0.8589, 'learning_rate': 1.1084420945929136e-05, 'epoch': 0.48}
{'loss': 0.8253, 'learning_rate': 1.107667760702807e-05, 'epoch': 0.48}
{'loss': 0.6874, 'learning_rate': 1.1068933614932061e-05, 'epoch': 0.48}
{'loss': 0.8408, 'learning_rate': 1.1061188974339201e-05, 'epoch': 0.48}
{'loss': 0.7754, 'learning_rate': 1.1053443689947984e-05, 'epoch': 0.48}
{'loss': 0.8468, 'learning_rate': 1.104569776645729e-05, 'epoch': 0.48}
{'loss': 0.8894, 'learning_rate': 1.1037951208566392e-05, 'epoch': 0.48}
{'loss': 0.8416, 'learning_rate': 1.1030204020974939e-05, 'epoch': 0.48}
{'loss': 0.8534, 'learning_rate': 1.102245620838297e-05, 'epoch': 0.48}
{'loss': 0.8761, 'learning_rate': 1.10147077754909e-05, 'epoch': 0.48}
{'loss': 0.8803, 'learning_rate': 1.1006958726999522e-05, 'epoch': 0.48}
{'loss': 0.7078, 'learning_rate': 1.0999209067609998e-05, 'epoch': 0.48}
{'loss': 0.6979, 'learning_rate': 1.0991458802023864e-05, 'epoch': 0.48}
{'loss': 0.8064, 'learning_rate': 1.0983707934943031e-05, 'epoch': 0.48}
{'loss': 0.8389, 'learning_rate': 1.0975956471069758e-05, 'epoch': 0.48}
{'loss': 0.6873, 'learning_rate': 1.0968204415106682e-05, 'epoch': 0.49}
{'loss': 0.78, 'learning_rate': 1.0960451771756788e-05, 'epoch': 0.49}
{'loss': 0.7881, 'learning_rate': 1.0952698545723428e-05, 'epoch': 0.49}
{'loss': 0.8653, 'learning_rate': 1.0944944741710295e-05, 'epoch': 0.49}
{'loss': 0.7387, 'learning_rate': 1.0937190364421442e-05, 'epoch': 0.49}
{'loss': 0.9201, 'learning_rate': 1.0929435418561268e-05, 'epoch': 0.49}
{'loss': 0.8141, 'learning_rate': 1.0921679908834518e-05, 'epoch': 0.49}
{'loss': 0.8154, 'learning_rate': 1.091392383994627e-05, 'epoch': 0.49}
{'loss': 0.8773, 'learning_rate': 1.0906167216601958e-05, 'epoch': 0.49}
{'loss': 0.8133, 'learning_rate': 1.0898410043507335e-05, 'epoch': 0.49}
{'loss': 0.7993, 'learning_rate': 1.0890652325368495e-05, 'epoch': 0.49}
{'loss': 0.883, 'learning_rate': 1.088289406689187e-05, 'epoch': 0.49}
{'loss': 0.8577, 'learning_rate': 1.0875135272784205e-05, 'epoch': 0.49}
{'loss': 0.7965, 'learning_rate': 1.0867375947752583e-05, 'epoch': 0.49}
{'loss': 0.8763, 'learning_rate': 1.0859616096504399e-05, 'epoch': 0.49}
{'loss': 0.8332, 'learning_rate': 1.085185572374738e-05, 'epoch': 0.49}
{'loss': 0.8497, 'learning_rate': 1.0844094834189553e-05, 'epoch': 0.49}
{'loss': 0.7594, 'learning_rate': 1.0836333432539272e-05, 'epoch': 0.49}
{'loss': 0.8418, 'learning_rate': 1.0828571523505192e-05, 'epoch': 0.49}
{'loss': 0.7983, 'learning_rate': 1.0820809111796285e-05, 'epoch': 0.49}
{'loss': 0.7774, 'learning_rate': 1.081304620212182e-05, 'epoch': 0.49}
{'loss': 0.9103, 'learning_rate': 1.0805282799191372e-05, 'epoch': 0.49}
{'loss': 0.8068, 'learning_rate': 1.0797518907714817e-05, 'epoch': 0.49}
{'loss': 0.8217, 'learning_rate': 1.0789754532402324e-05, 'epoch': 0.49}
{'loss': 0.8252, 'learning_rate': 1.0781989677964355e-05, 'epoch': 0.49}
{'loss': 0.8695, 'learning_rate': 1.0774224349111668e-05, 'epoch': 0.49}
{'loss': 0.8582, 'learning_rate': 1.0766458550555301e-05, 'epoch': 0.49}
{'loss': 0.7729, 'learning_rate': 1.0758692287006583e-05, 'epoch': 0.49}
{'loss': 0.8658, 'learning_rate': 1.0750925563177123e-05, 'epoch': 0.49}
{'loss': 0.784, 'learning_rate': 1.0743158383778811e-05, 'epoch': 0.49}
{'loss': 0.8344, 'learning_rate': 1.0735390753523806e-05, 'epoch': 0.49}
{'loss': 0.8261, 'learning_rate': 1.0727622677124554e-05, 'epoch': 0.49}
{'loss': 0.8455, 'learning_rate': 1.0719854159293761e-05, 'epoch': 0.49}
{'loss': 0.8421, 'learning_rate': 1.0712085204744402e-05, 'epoch': 0.49}
{'loss': 0.7203, 'learning_rate': 1.0704315818189723e-05, 'epoch': 0.49}
{'loss': 0.851, 'learning_rate': 1.0696546004343222e-05, 'epoch': 0.49}
{'loss': 0.7302, 'learning_rate': 1.0688775767918667e-05, 'epoch': 0.49}
{'loss': 0.8071, 'learning_rate': 1.0681005113630072e-05, 'epoch': 0.49}
{'loss': 0.8307, 'learning_rate': 1.0673234046191716e-05, 'epoch': 0.49}
{'loss': 0.8094, 'learning_rate': 1.0665462570318121e-05, 'epoch': 0.49}
{'loss': 0.8716, 'learning_rate': 1.0657690690724056e-05, 'epoch': 0.49}
{'loss': 0.8203, 'learning_rate': 1.064991841212454e-05, 'epoch': 0.49}
{'loss': 0.8224, 'learning_rate': 1.064214573923483e-05, 'epoch': 0.5}
{'loss': 0.7947, 'learning_rate': 1.0634372676770422e-05, 'epoch': 0.5}
{'loss': 0.8617, 'learning_rate': 1.0626599229447053e-05, 'epoch': 0.5}
{'loss': 0.8481, 'learning_rate': 1.0618825401980689e-05, 'epoch': 0.5}
{'loss': 0.9004, 'learning_rate': 1.0611051199087527e-05, 'epoch': 0.5}
{'loss': 0.8435, 'learning_rate': 1.0603276625483994e-05, 'epoch': 0.5}
{'loss': 0.7541, 'learning_rate': 1.059550168588674e-05, 'epoch': 0.5}
{'loss': 0.8266, 'learning_rate': 1.058772638501264e-05, 'epoch': 0.5}
{'loss': 0.8256, 'learning_rate': 1.0579950727578783e-05, 'epoch': 0.5}
{'loss': 0.8316, 'learning_rate': 1.0572174718302482e-05, 'epoch': 0.5}
{'loss': 0.7919, 'learning_rate': 1.0564398361901252e-05, 'epoch': 0.5}
{'loss': 0.8597, 'learning_rate': 1.0556621663092828e-05, 'epoch': 0.5}
{'loss': 0.8551, 'learning_rate': 1.0548844626595149e-05, 'epoch': 0.5}
{'loss': 0.7396, 'learning_rate': 1.0541067257126364e-05, 'epoch': 0.5}
{'loss': 0.8351, 'learning_rate': 1.0533289559404815e-05, 'epoch': 0.5}
{'loss': 0.7947, 'learning_rate': 1.0525511538149055e-05, 'epoch': 0.5}
{'loss': 0.8585, 'learning_rate': 1.0517733198077817e-05, 'epoch': 0.5}
{'loss': 0.8252, 'learning_rate': 1.0509954543910044e-05, 'epoch': 0.5}
{'loss': 0.8313, 'learning_rate': 1.0502175580364857e-05, 'epoch': 0.5}
{'loss': 0.7991, 'learning_rate': 1.0494396312161575e-05, 'epoch': 0.5}
{'loss': 0.8751, 'learning_rate': 1.0486616744019691e-05, 'epoch': 0.5}
{'loss': 0.8344, 'learning_rate': 1.0478836880658894e-05, 'epoch': 0.5}
{'loss': 0.8079, 'learning_rate': 1.0471056726799034e-05, 'epoch': 0.5}
{'loss': 0.7649, 'learning_rate': 1.0463276287160154e-05, 'epoch': 0.5}
{'loss': 0.7862, 'learning_rate': 1.0455495566462463e-05, 'epoch': 0.5}
{'loss': 0.8251, 'learning_rate': 1.0447714569426337e-05, 'epoch': 0.5}
{'loss': 0.8945, 'learning_rate': 1.043993330077233e-05, 'epoch': 0.5}
{'loss': 0.8758, 'learning_rate': 1.0432151765221148e-05, 'epoch': 0.5}
{'loss': 0.816, 'learning_rate': 1.0424369967493668e-05, 'epoch': 0.5}
{'loss': 0.8467, 'learning_rate': 1.0416587912310923e-05, 'epoch': 0.5}
{'loss': 0.7703, 'learning_rate': 1.0408805604394103e-05, 'epoch': 0.5}
{'loss': 0.8644, 'learning_rate': 1.040102304846455e-05, 'epoch': 0.5}
{'loss': 0.8726, 'learning_rate': 1.0393240249243763e-05, 'epoch': 0.5}
{'loss': 0.8146, 'learning_rate': 1.0385457211453374e-05, 'epoch': 0.5}
{'loss': 0.7034, 'learning_rate': 1.0377673939815176e-05, 'epoch': 0.5}
{'loss': 0.7241, 'learning_rate': 1.0369890439051092e-05, 'epoch': 0.5}
{'loss': 0.8908, 'learning_rate': 1.0362106713883188e-05, 'epoch': 0.5}
{'loss': 0.8222, 'learning_rate': 1.0354322769033671e-05, 'epoch': 0.5}
{'loss': 0.6905, 'learning_rate': 1.0346538609224877e-05, 'epoch': 0.5}
{'loss': 0.7564, 'learning_rate': 1.0338754239179267e-05, 'epoch': 0.5}
{'loss': 0.8134, 'learning_rate': 1.0330969663619438e-05, 'epoch': 0.5}
{'loss': 0.7944, 'learning_rate': 1.0323184887268111e-05, 'epoch': 0.51}
[2025-12-09 19:27:33,969] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step10500 is about to be saved!
[2025-12-09 19:27:33,999] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10500/global_step10500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 19:27:34,000] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10500/global_step10500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 19:27:34,156] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10500/global_step10500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 19:27:34,164] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10500/global_step10500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 19:28:18,839] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10500/global_step10500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 19:28:18,845] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-10500/global_step10500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 19:28:18,872] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step10500 is ready now!
{'loss': 0.8515, 'learning_rate': 1.0315399914848125e-05, 'epoch': 0.51}
{'loss': 0.8533, 'learning_rate': 1.030761475108244e-05, 'epoch': 0.51}
{'loss': 0.8172, 'learning_rate': 1.0299829400694128e-05, 'epoch': 0.51}
{'loss': 0.8289, 'learning_rate': 1.0292043868406379e-05, 'epoch': 0.51}
{'loss': 0.7426, 'learning_rate': 1.0284258158942494e-05, 'epoch': 0.51}
{'loss': 0.7457, 'learning_rate': 1.0276472277025882e-05, 'epoch': 0.51}
{'loss': 0.7438, 'learning_rate': 1.0268686227380047e-05, 'epoch': 0.51}
{'loss': 0.8498, 'learning_rate': 1.0260900014728609e-05, 'epoch': 0.51}
{'loss': 0.8249, 'learning_rate': 1.0253113643795273e-05, 'epoch': 0.51}
{'loss': 0.8028, 'learning_rate': 1.0245327119303856e-05, 'epoch': 0.51}
{'loss': 0.8653, 'learning_rate': 1.0237540445978248e-05, 'epoch': 0.51}
{'loss': 0.8016, 'learning_rate': 1.022975362854245e-05, 'epoch': 0.51}
{'loss': 0.8667, 'learning_rate': 1.0221966671720534e-05, 'epoch': 0.51}
{'loss': 0.8218, 'learning_rate': 1.0214179580236667e-05, 'epoch': 0.51}
{'loss': 0.8176, 'learning_rate': 1.0206392358815094e-05, 'epoch': 0.51}
{'loss': 0.8403, 'learning_rate': 1.0198605012180133e-05, 'epoch': 0.51}
{'loss': 0.7849, 'learning_rate': 1.0190817545056195e-05, 'epoch': 0.51}
{'loss': 0.7835, 'learning_rate': 1.0183029962167744e-05, 'epoch': 0.51}
{'loss': 0.829, 'learning_rate': 1.0175242268239327e-05, 'epoch': 0.51}
{'loss': 0.7494, 'learning_rate': 1.016745446799555e-05, 'epoch': 0.51}
{'loss': 0.846, 'learning_rate': 1.0159666566161093e-05, 'epoch': 0.51}
{'loss': 0.9017, 'learning_rate': 1.0151878567460689e-05, 'epoch': 0.51}
{'loss': 0.8508, 'learning_rate': 1.014409047661914e-05, 'epoch': 0.51}
{'loss': 0.8439, 'learning_rate': 1.0136302298361286e-05, 'epoch': 0.51}
{'loss': 0.8206, 'learning_rate': 1.0128514037412042e-05, 'epoch': 0.51}
{'loss': 0.717, 'learning_rate': 1.0120725698496356e-05, 'epoch': 0.51}
{'loss': 0.7959, 'learning_rate': 1.0112937286339234e-05, 'epoch': 0.51}
{'loss': 0.8769, 'learning_rate': 1.010514880566572e-05, 'epoch': 0.51}
{'loss': 0.7266, 'learning_rate': 1.0097360261200902e-05, 'epoch': 0.51}
{'loss': 0.8486, 'learning_rate': 1.0089571657669904e-05, 'epoch': 0.51}
{'loss': 0.8566, 'learning_rate': 1.0081782999797895e-05, 'epoch': 0.51}
{'loss': 0.8509, 'learning_rate': 1.0073994292310063e-05, 'epoch': 0.51}
{'loss': 0.7776, 'learning_rate': 1.0066205539931637e-05, 'epoch': 0.51}
{'loss': 0.8104, 'learning_rate': 1.0058416747387872e-05, 'epoch': 0.51}
{'loss': 0.8143, 'learning_rate': 1.0050627919404037e-05, 'epoch': 0.51}
{'loss': 0.7756, 'learning_rate': 1.004283906070544e-05, 'epoch': 0.51}
{'loss': 0.8186, 'learning_rate': 1.0035050176017392e-05, 'epoch': 0.51}
{'loss': 0.8045, 'learning_rate': 1.0027261270065227e-05, 'epoch': 0.51}
{'loss': 0.8294, 'learning_rate': 1.0019472347574293e-05, 'epoch': 0.51}
{'loss': 0.823, 'learning_rate': 1.0011683413269946e-05, 'epoch': 0.51}
{'loss': 0.6835, 'learning_rate': 1.0003894471877545e-05, 'epoch': 0.51}
{'loss': 0.7638, 'learning_rate': 9.99610552812246e-06, 'epoch': 0.52}
{'loss': 0.8075, 'learning_rate': 9.988316586730057e-06, 'epoch': 0.52}
{'loss': 0.726, 'learning_rate': 9.98052765242571e-06, 'epoch': 0.52}
{'loss': 0.8209, 'learning_rate': 9.972738729934775e-06, 'epoch': 0.52}
{'loss': 0.839, 'learning_rate': 9.964949823982613e-06, 'epoch': 0.52}
{'loss': 0.8078, 'learning_rate': 9.957160939294565e-06, 'epoch': 0.52}
{'loss': 0.8601, 'learning_rate': 9.949372080595964e-06, 'epoch': 0.52}
{'loss': 0.8841, 'learning_rate': 9.941583252612135e-06, 'epoch': 0.52}
{'loss': 0.7165, 'learning_rate': 9.933794460068364e-06, 'epoch': 0.52}
{'loss': 0.8902, 'learning_rate': 9.926005707689937e-06, 'epoch': 0.52}
{'loss': 0.8073, 'learning_rate': 9.918217000202108e-06, 'epoch': 0.52}
{'loss': 0.8022, 'learning_rate': 9.910428342330096e-06, 'epoch': 0.52}
{'loss': 0.821, 'learning_rate': 9.902639738799102e-06, 'epoch': 0.52}
{'loss': 0.8171, 'learning_rate': 9.894851194334283e-06, 'epoch': 0.52}
{'loss': 0.854, 'learning_rate': 9.887062713660767e-06, 'epoch': 0.52}
{'loss': 0.8563, 'learning_rate': 9.879274301503645e-06, 'epoch': 0.52}
{'loss': 0.8717, 'learning_rate': 9.87148596258796e-06, 'epoch': 0.52}
{'loss': 0.7801, 'learning_rate': 9.863697701638715e-06, 'epoch': 0.52}
{'loss': 0.8405, 'learning_rate': 9.855909523380865e-06, 'epoch': 0.52}
{'loss': 0.8555, 'learning_rate': 9.848121432539313e-06, 'epoch': 0.52}
{'loss': 0.8396, 'learning_rate': 9.84033343383891e-06, 'epoch': 0.52}
{'loss': 0.8306, 'learning_rate': 9.832545532004454e-06, 'epoch': 0.52}
{'loss': 0.8639, 'learning_rate': 9.824757731760678e-06, 'epoch': 0.52}
{'loss': 0.8572, 'learning_rate': 9.81697003783226e-06, 'epoch': 0.52}
{'loss': 0.8738, 'learning_rate': 9.80918245494381e-06, 'epoch': 0.52}
{'loss': 0.8743, 'learning_rate': 9.801394987819865e-06, 'epoch': 0.52}
{'loss': 0.7407, 'learning_rate': 9.793607641184908e-06, 'epoch': 0.52}
{'loss': 0.6988, 'learning_rate': 9.785820419763335e-06, 'epoch': 0.52}
{'loss': 0.8766, 'learning_rate': 9.778033328279468e-06, 'epoch': 0.52}
{'loss': 0.788, 'learning_rate': 9.770246371457553e-06, 'epoch': 0.52}
{'loss': 0.8341, 'learning_rate': 9.762459554021753e-06, 'epoch': 0.52}
{'loss': 0.7786, 'learning_rate': 9.754672880696147e-06, 'epoch': 0.52}
{'loss': 0.6568, 'learning_rate': 9.746886356204729e-06, 'epoch': 0.52}
{'loss': 0.7592, 'learning_rate': 9.739099985271394e-06, 'epoch': 0.52}
{'loss': 0.8193, 'learning_rate': 9.731313772619956e-06, 'epoch': 0.52}
{'loss': 0.8009, 'learning_rate': 9.723527722974121e-06, 'epoch': 0.52}
{'loss': 0.8589, 'learning_rate': 9.715741841057509e-06, 'epoch': 0.52}
{'loss': 0.855, 'learning_rate': 9.707956131593623e-06, 'epoch': 0.52}
{'loss': 0.8148, 'learning_rate': 9.700170599305877e-06, 'epoch': 0.52}
{'loss': 0.8531, 'learning_rate': 9.692385248917565e-06, 'epoch': 0.52}
{'loss': 0.8139, 'learning_rate': 9.684600085151877e-06, 'epoch': 0.52}
{'loss': 0.8467, 'learning_rate': 9.676815112731892e-06, 'epoch': 0.52}
{'loss': 0.7877, 'learning_rate': 9.669030336380562e-06, 'epoch': 0.53}
{'loss': 0.8189, 'learning_rate': 9.661245760820734e-06, 'epoch': 0.53}
{'loss': 0.8737, 'learning_rate': 9.653461390775127e-06, 'epoch': 0.53}
{'loss': 0.8631, 'learning_rate': 9.64567723096633e-06, 'epoch': 0.53}
{'loss': 0.7964, 'learning_rate': 9.637893286116814e-06, 'epoch': 0.53}
{'loss': 0.7602, 'learning_rate': 9.630109560948912e-06, 'epoch': 0.53}
{'loss': 0.8418, 'learning_rate': 9.622326060184827e-06, 'epoch': 0.53}
{'loss': 0.8285, 'learning_rate': 9.614542788546627e-06, 'epoch': 0.53}
{'loss': 0.7136, 'learning_rate': 9.606759750756239e-06, 'epoch': 0.53}
{'loss': 0.8658, 'learning_rate': 9.598976951535451e-06, 'epoch': 0.53}
{'loss': 0.7739, 'learning_rate': 9.591194395605899e-06, 'epoch': 0.53}
{'loss': 0.7506, 'learning_rate': 9.58341208768908e-06, 'epoch': 0.53}
{'loss': 0.7988, 'learning_rate': 9.575630032506335e-06, 'epoch': 0.53}
{'loss': 0.8576, 'learning_rate': 9.567848234778857e-06, 'epoch': 0.53}
{'loss': 0.8135, 'learning_rate': 9.560066699227675e-06, 'epoch': 0.53}
{'loss': 0.7848, 'learning_rate': 9.552285430573665e-06, 'epoch': 0.53}
{'loss': 0.7939, 'learning_rate': 9.544504433537537e-06, 'epoch': 0.53}
[2025-12-09 19:53:06,538] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step11000 is about to be saved!
[2025-12-09 19:53:07,013] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11000/global_step11000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 19:53:07,013] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11000/global_step11000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 19:53:07,164] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11000/global_step11000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 19:53:07,167] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11000/global_step11000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 19:54:06,214] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11000/global_step11000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 19:54:06,217] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11000/global_step11000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 19:54:22,985] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step11000 is ready now!
{'loss': 0.7643, 'learning_rate': 9.536723712839848e-06, 'epoch': 0.53}
{'loss': 0.7586, 'learning_rate': 9.528943273200965e-06, 'epoch': 0.53}
{'loss': 0.7755, 'learning_rate': 9.52116311934111e-06, 'epoch': 0.53}
{'loss': 0.891, 'learning_rate': 9.51338325598031e-06, 'epoch': 0.53}
{'loss': 0.8454, 'learning_rate': 9.50560368783843e-06, 'epoch': 0.53}
{'loss': 0.8708, 'learning_rate': 9.497824419635145e-06, 'epoch': 0.53}
{'loss': 0.7984, 'learning_rate': 9.490045456089958e-06, 'epoch': 0.53}
{'loss': 0.7356, 'learning_rate': 9.482266801922186e-06, 'epoch': 0.53}
{'loss': 0.8063, 'learning_rate': 9.474488461850948e-06, 'epoch': 0.53}
{'loss': 0.6352, 'learning_rate': 9.466710440595186e-06, 'epoch': 0.53}
{'loss': 0.7967, 'learning_rate': 9.458932742873639e-06, 'epoch': 0.53}
{'loss': 0.8627, 'learning_rate': 9.451155373404855e-06, 'epoch': 0.53}
{'loss': 0.8082, 'learning_rate': 9.443378336907177e-06, 'epoch': 0.53}
{'loss': 0.8243, 'learning_rate': 9.435601638098755e-06, 'epoch': 0.53}
{'loss': 0.7053, 'learning_rate': 9.427825281697523e-06, 'epoch': 0.53}
{'loss': 0.7469, 'learning_rate': 9.420049272421219e-06, 'epoch': 0.53}
{'loss': 0.8296, 'learning_rate': 9.412273614987359e-06, 'epoch': 0.53}
{'loss': 0.8323, 'learning_rate': 9.40449831411326e-06, 'epoch': 0.53}
{'loss': 0.8757, 'learning_rate': 9.396723374516006e-06, 'epoch': 0.53}
{'loss': 0.8998, 'learning_rate': 9.388948800912476e-06, 'epoch': 0.53}
{'loss': 0.786, 'learning_rate': 9.381174598019313e-06, 'epoch': 0.53}
{'loss': 0.7777, 'learning_rate': 9.37340077055295e-06, 'epoch': 0.53}
{'loss': 0.8173, 'learning_rate': 9.36562732322958e-06, 'epoch': 0.53}
{'loss': 0.8632, 'learning_rate': 9.357854260765173e-06, 'epoch': 0.53}
{'loss': 0.781, 'learning_rate': 9.350081587875463e-06, 'epoch': 0.54}
{'loss': 0.7942, 'learning_rate': 9.342309309275946e-06, 'epoch': 0.54}
{'loss': 0.8878, 'learning_rate': 9.334537429681882e-06, 'epoch': 0.54}
{'loss': 0.878, 'learning_rate': 9.326765953808285e-06, 'epoch': 0.54}
{'loss': 0.8826, 'learning_rate': 9.31899488636993e-06, 'epoch': 0.54}
{'loss': 0.8013, 'learning_rate': 9.311224232081338e-06, 'epoch': 0.54}
{'loss': 0.8749, 'learning_rate': 9.303453995656783e-06, 'epoch': 0.54}
{'loss': 0.7823, 'learning_rate': 9.295684181810282e-06, 'epoch': 0.54}
{'loss': 0.8392, 'learning_rate': 9.2879147952556e-06, 'epoch': 0.54}
{'loss': 0.8337, 'learning_rate': 9.280145840706239e-06, 'epoch': 0.54}
{'loss': 0.8119, 'learning_rate': 9.272377322875446e-06, 'epoch': 0.54}
{'loss': 0.8318, 'learning_rate': 9.264609246476194e-06, 'epoch': 0.54}
{'loss': 0.7971, 'learning_rate': 9.256841616221192e-06, 'epoch': 0.54}
{'loss': 0.7298, 'learning_rate': 9.249074436822878e-06, 'epoch': 0.54}
{'loss': 0.8596, 'learning_rate': 9.24130771299342e-06, 'epoch': 0.54}
{'loss': 0.8026, 'learning_rate': 9.233541449444702e-06, 'epoch': 0.54}
{'loss': 0.7923, 'learning_rate': 9.225775650888334e-06, 'epoch': 0.54}
{'loss': 0.8903, 'learning_rate': 9.218010322035648e-06, 'epoch': 0.54}
{'loss': 0.8439, 'learning_rate': 9.210245467597678e-06, 'epoch': 0.54}
{'loss': 0.8043, 'learning_rate': 9.202481092285187e-06, 'epoch': 0.54}
{'loss': 0.7861, 'learning_rate': 9.19471720080863e-06, 'epoch': 0.54}
{'loss': 0.782, 'learning_rate': 9.186953797878185e-06, 'epoch': 0.54}
{'loss': 0.7824, 'learning_rate': 9.17919088820372e-06, 'epoch': 0.54}
{'loss': 0.6853, 'learning_rate': 9.171428476494813e-06, 'epoch': 0.54}
{'loss': 0.8146, 'learning_rate': 9.163666567460735e-06, 'epoch': 0.54}
{'loss': 0.7879, 'learning_rate': 9.155905165810449e-06, 'epoch': 0.54}
{'loss': 0.7774, 'learning_rate': 9.148144276252621e-06, 'epoch': 0.54}
{'loss': 0.6458, 'learning_rate': 9.1403839034956e-06, 'epoch': 0.54}
{'loss': 0.7985, 'learning_rate': 9.132624052247417e-06, 'epoch': 0.54}
{'loss': 0.813, 'learning_rate': 9.124864727215796e-06, 'epoch': 0.54}
{'loss': 0.7157, 'learning_rate': 9.117105933108132e-06, 'epoch': 0.54}
{'loss': 0.8274, 'learning_rate': 9.109347674631508e-06, 'epoch': 0.54}
{'loss': 0.7537, 'learning_rate': 9.10158995649267e-06, 'epoch': 0.54}
{'loss': 0.806, 'learning_rate': 9.093832783398045e-06, 'epoch': 0.54}
{'loss': 0.8273, 'learning_rate': 9.086076160053732e-06, 'epoch': 0.54}
{'loss': 0.7718, 'learning_rate': 9.078320091165486e-06, 'epoch': 0.54}
{'loss': 0.8088, 'learning_rate': 9.070564581438734e-06, 'epoch': 0.54}
{'loss': 0.7267, 'learning_rate': 9.06280963557856e-06, 'epoch': 0.54}
{'loss': 0.7702, 'learning_rate': 9.05505525828971e-06, 'epoch': 0.54}
{'loss': 0.7421, 'learning_rate': 9.047301454276577e-06, 'epoch': 0.54}
{'loss': 0.8909, 'learning_rate': 9.039548228243216e-06, 'epoch': 0.54}
{'loss': 0.805, 'learning_rate': 9.031795584893323e-06, 'epoch': 0.54}
{'loss': 0.8692, 'learning_rate': 9.024043528930242e-06, 'epoch': 0.55}
{'loss': 0.8401, 'learning_rate': 9.01629206505697e-06, 'epoch': 0.55}
{'loss': 0.8008, 'learning_rate': 9.008541197976136e-06, 'epoch': 0.55}
{'loss': 0.8286, 'learning_rate': 9.000790932390004e-06, 'epoch': 0.55}
{'loss': 0.7192, 'learning_rate': 8.993041273000483e-06, 'epoch': 0.55}
{'loss': 0.8128, 'learning_rate': 8.985292224509103e-06, 'epoch': 0.55}
{'loss': 0.8781, 'learning_rate': 8.977543791617034e-06, 'epoch': 0.55}
{'loss': 0.8128, 'learning_rate': 8.969795979025065e-06, 'epoch': 0.55}
{'loss': 0.8266, 'learning_rate': 8.962048791433611e-06, 'epoch': 0.55}
{'loss': 0.8551, 'learning_rate': 8.954302233542712e-06, 'epoch': 0.55}
{'loss': 0.7558, 'learning_rate': 8.946556310052017e-06, 'epoch': 0.55}
{'loss': 0.8048, 'learning_rate': 8.938811025660802e-06, 'epoch': 0.55}
{'loss': 0.8313, 'learning_rate': 8.931066385067944e-06, 'epoch': 0.55}
{'loss': 0.7575, 'learning_rate': 8.923322392971935e-06, 'epoch': 0.55}
{'loss': 0.7977, 'learning_rate': 8.915579054070869e-06, 'epoch': 0.55}
{'loss': 0.8206, 'learning_rate': 8.907836373062456e-06, 'epoch': 0.55}
{'loss': 0.8596, 'learning_rate': 8.90009435464399e-06, 'epoch': 0.55}
{'loss': 0.838, 'learning_rate': 8.89235300351237e-06, 'epoch': 0.55}
{'loss': 0.7607, 'learning_rate': 8.8846123243641e-06, 'epoch': 0.55}
{'loss': 0.9072, 'learning_rate': 8.876872321895264e-06, 'epoch': 0.55}
{'loss': 0.8022, 'learning_rate': 8.869133000801539e-06, 'epoch': 0.55}
{'loss': 0.7707, 'learning_rate': 8.861394365778188e-06, 'epoch': 0.55}
{'loss': 0.7796, 'learning_rate': 8.853656421520059e-06, 'epoch': 0.55}
{'loss': 0.8135, 'learning_rate': 8.845919172721581e-06, 'epoch': 0.55}
{'loss': 0.8591, 'learning_rate': 8.838182624076759e-06, 'epoch': 0.55}
{'loss': 0.7848, 'learning_rate': 8.830446780279175e-06, 'epoch': 0.55}
{'loss': 0.7682, 'learning_rate': 8.82271164602199e-06, 'epoch': 0.55}
{'loss': 0.7989, 'learning_rate': 8.814977225997916e-06, 'epoch': 0.55}
{'loss': 0.6991, 'learning_rate': 8.807243524899253e-06, 'epoch': 0.55}
{'loss': 0.818, 'learning_rate': 8.79951054741785e-06, 'epoch': 0.55}
{'loss': 0.6747, 'learning_rate': 8.791778298245126e-06, 'epoch': 0.55}
{'loss': 0.762, 'learning_rate': 8.78404678207205e-06, 'epoch': 0.55}
{'loss': 0.6535, 'learning_rate': 8.776316003589156e-06, 'epoch': 0.55}
{'loss': 0.8219, 'learning_rate': 8.768585967486518e-06, 'epoch': 0.55}
[2025-12-09 20:21:11,312] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step11500 is about to be saved!
[2025-12-09 20:21:11,343] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11500/global_step11500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 20:21:11,343] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11500/global_step11500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 20:21:11,500] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11500/global_step11500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 20:21:11,503] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11500/global_step11500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 20:21:53,763] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11500/global_step11500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 20:21:53,766] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-11500/global_step11500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 20:21:56,035] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step11500 is ready now!
{'loss': 0.8712, 'learning_rate': 8.760856678453776e-06, 'epoch': 0.55}
{'loss': 0.7746, 'learning_rate': 8.7531281411801e-06, 'epoch': 0.55}
{'loss': 0.7953, 'learning_rate': 8.745400360354219e-06, 'epoch': 0.55}
{'loss': 0.8067, 'learning_rate': 8.737673340664387e-06, 'epoch': 0.55}
{'loss': 0.7918, 'learning_rate': 8.729947086798413e-06, 'epoch': 0.55}
{'loss': 0.8074, 'learning_rate': 8.722221603443627e-06, 'epoch': 0.55}
{'loss': 0.8836, 'learning_rate': 8.714496895286903e-06, 'epoch': 0.55}
{'loss': 0.8366, 'learning_rate': 8.706772967014633e-06, 'epoch': 0.56}
{'loss': 0.7612, 'learning_rate': 8.699049823312747e-06, 'epoch': 0.56}
{'loss': 0.8049, 'learning_rate': 8.691327468866695e-06, 'epoch': 0.56}
{'loss': 0.7136, 'learning_rate': 8.683605908361446e-06, 'epoch': 0.56}
{'loss': 0.8741, 'learning_rate': 8.675885146481489e-06, 'epoch': 0.56}
{'loss': 0.7187, 'learning_rate': 8.668165187910826e-06, 'epoch': 0.56}
{'loss': 0.8715, 'learning_rate': 8.660446037332979e-06, 'epoch': 0.56}
{'loss': 0.7639, 'learning_rate': 8.652727699430971e-06, 'epoch': 0.56}
{'loss': 0.8529, 'learning_rate': 8.645010178887338e-06, 'epoch': 0.56}
{'loss': 0.8216, 'learning_rate': 8.637293480384111e-06, 'epoch': 0.56}
{'loss': 0.8081, 'learning_rate': 8.629577608602842e-06, 'epoch': 0.56}
{'loss': 0.7513, 'learning_rate': 8.621862568224559e-06, 'epoch': 0.56}
{'loss': 0.8641, 'learning_rate': 8.614148363929802e-06, 'epoch': 0.56}
{'loss': 0.813, 'learning_rate': 8.60643500039859e-06, 'epoch': 0.56}
{'loss': 0.823, 'learning_rate': 8.598722482310445e-06, 'epoch': 0.56}
{'loss': 0.8379, 'learning_rate': 8.591010814344364e-06, 'epoch': 0.56}
{'loss': 0.7906, 'learning_rate': 8.58330000117884e-06, 'epoch': 0.56}
{'loss': 0.6946, 'learning_rate': 8.575590047491839e-06, 'epoch': 0.56}
{'loss': 0.8416, 'learning_rate': 8.567880957960807e-06, 'epoch': 0.56}
{'loss': 0.8392, 'learning_rate': 8.560172737262671e-06, 'epoch': 0.56}
{'loss': 0.798, 'learning_rate': 8.552465390073825e-06, 'epoch': 0.56}
{'loss': 0.8229, 'learning_rate': 8.544758921070134e-06, 'epoch': 0.56}
{'loss': 0.6839, 'learning_rate': 8.537053334926932e-06, 'epoch': 0.56}
{'loss': 0.7947, 'learning_rate': 8.529348636319017e-06, 'epoch': 0.56}
{'loss': 0.8466, 'learning_rate': 8.521644829920647e-06, 'epoch': 0.56}
{'loss': 0.8606, 'learning_rate': 8.513941920405544e-06, 'epoch': 0.56}
{'loss': 0.8918, 'learning_rate': 8.506239912446869e-06, 'epoch': 0.56}
{'loss': 0.7948, 'learning_rate': 8.498538810717267e-06, 'epoch': 0.56}
{'loss': 0.8365, 'learning_rate': 8.490838619888803e-06, 'epoch': 0.56}
{'loss': 0.7188, 'learning_rate': 8.483139344633009e-06, 'epoch': 0.56}
{'loss': 0.738, 'learning_rate': 8.475440989620845e-06, 'epoch': 0.56}
{'loss': 0.8256, 'learning_rate': 8.46774355952273e-06, 'epoch': 0.56}
{'loss': 0.8652, 'learning_rate': 8.460047059008508e-06, 'epoch': 0.56}
{'loss': 0.8223, 'learning_rate': 8.45235149274747e-06, 'epoch': 0.56}
{'loss': 0.8398, 'learning_rate': 8.444656865408328e-06, 'epoch': 0.56}
{'loss': 0.7432, 'learning_rate': 8.436963181659234e-06, 'epoch': 0.56}
{'loss': 0.8655, 'learning_rate': 8.429270446167768e-06, 'epoch': 0.56}
{'loss': 0.8638, 'learning_rate': 8.421578663600926e-06, 'epoch': 0.56}
{'loss': 0.7795, 'learning_rate': 8.41388783862514e-06, 'epoch': 0.56}
{'loss': 0.8049, 'learning_rate': 8.40619797590624e-06, 'epoch': 0.56}
{'loss': 0.7958, 'learning_rate': 8.398509080109495e-06, 'epoch': 0.56}
{'loss': 0.8561, 'learning_rate': 8.39082115589957e-06, 'epoch': 0.56}
{'loss': 0.8987, 'learning_rate': 8.383134207940548e-06, 'epoch': 0.57}
{'loss': 0.7549, 'learning_rate': 8.375448240895927e-06, 'epoch': 0.57}
{'loss': 0.8037, 'learning_rate': 8.367763259428597e-06, 'epoch': 0.57}
{'loss': 0.6352, 'learning_rate': 8.360079268200854e-06, 'epoch': 0.57}
{'loss': 0.8367, 'learning_rate': 8.352396271874398e-06, 'epoch': 0.57}
{'loss': 0.739, 'learning_rate': 8.344714275110318e-06, 'epoch': 0.57}
{'loss': 0.7634, 'learning_rate': 8.337033282569102e-06, 'epoch': 0.57}
{'loss': 0.772, 'learning_rate': 8.329353298910629e-06, 'epoch': 0.57}
{'loss': 0.8439, 'learning_rate': 8.321674328794162e-06, 'epoch': 0.57}
{'loss': 0.7097, 'learning_rate': 8.313996376878353e-06, 'epoch': 0.57}
{'loss': 0.8654, 'learning_rate': 8.306319447821234e-06, 'epoch': 0.57}
{'loss': 0.8562, 'learning_rate': 8.298643546280214e-06, 'epoch': 0.57}
{'loss': 0.7822, 'learning_rate': 8.290968676912085e-06, 'epoch': 0.57}
{'loss': 0.8037, 'learning_rate': 8.283294844373012e-06, 'epoch': 0.57}
{'loss': 0.8434, 'learning_rate': 8.275622053318523e-06, 'epoch': 0.57}
{'loss': 0.7702, 'learning_rate': 8.267950308403523e-06, 'epoch': 0.57}
{'loss': 0.7089, 'learning_rate': 8.260279614282277e-06, 'epoch': 0.57}
{'loss': 0.8365, 'learning_rate': 8.252609975608413e-06, 'epoch': 0.57}
{'loss': 0.8481, 'learning_rate': 8.244941397034924e-06, 'epoch': 0.57}
{'loss': 0.8006, 'learning_rate': 8.237273883214159e-06, 'epoch': 0.57}
{'loss': 0.7753, 'learning_rate': 8.22960743879781e-06, 'epoch': 0.57}
{'loss': 0.8567, 'learning_rate': 8.221942068436935e-06, 'epoch': 0.57}
{'loss': 0.8545, 'learning_rate': 8.214277776781928e-06, 'epoch': 0.57}
{'loss': 0.8234, 'learning_rate': 8.206614568482538e-06, 'epoch': 0.57}
{'loss': 0.7612, 'learning_rate': 8.19895244818785e-06, 'epoch': 0.57}
{'loss': 0.7845, 'learning_rate': 8.191291420546296e-06, 'epoch': 0.57}
{'loss': 0.797, 'learning_rate': 8.183631490205636e-06, 'epoch': 0.57}
{'loss': 0.8381, 'learning_rate': 8.175972661812977e-06, 'epoch': 0.57}
{'loss': 0.804, 'learning_rate': 8.168314940014742e-06, 'epoch': 0.57}
{'loss': 0.825, 'learning_rate': 8.160658329456692e-06, 'epoch': 0.57}
{'loss': 0.8434, 'learning_rate': 8.153002834783916e-06, 'epoch': 0.57}
{'loss': 0.8646, 'learning_rate': 8.145348460640817e-06, 'epoch': 0.57}
{'loss': 0.8127, 'learning_rate': 8.137695211671131e-06, 'epoch': 0.57}
{'loss': 0.7135, 'learning_rate': 8.130043092517895e-06, 'epoch': 0.57}
{'loss': 0.7562, 'learning_rate': 8.122392107823474e-06, 'epoch': 0.57}
{'loss': 0.8381, 'learning_rate': 8.114742262229542e-06, 'epoch': 0.57}
{'loss': 0.8229, 'learning_rate': 8.107093560377079e-06, 'epoch': 0.57}
{'loss': 0.765, 'learning_rate': 8.09944600690637e-06, 'epoch': 0.57}
{'loss': 0.8403, 'learning_rate': 8.09179960645701e-06, 'epoch': 0.57}
{'loss': 0.8517, 'learning_rate': 8.084154363667884e-06, 'epoch': 0.57}
{'loss': 0.7481, 'learning_rate': 8.076510283177186e-06, 'epoch': 0.57}
{'loss': 0.7582, 'learning_rate': 8.068867369622394e-06, 'epoch': 0.58}
{'loss': 0.7665, 'learning_rate': 8.061225627640294e-06, 'epoch': 0.58}
{'loss': 0.8533, 'learning_rate': 8.053585061866937e-06, 'epoch': 0.58}
{'loss': 0.788, 'learning_rate': 8.045945676937688e-06, 'epoch': 0.58}
{'loss': 0.8246, 'learning_rate': 8.03830747748717e-06, 'epoch': 0.58}
{'loss': 0.8553, 'learning_rate': 8.030670468149305e-06, 'epoch': 0.58}
{'loss': 0.7383, 'learning_rate': 8.023034653557287e-06, 'epoch': 0.58}
{'loss': 0.759, 'learning_rate': 8.015400038343582e-06, 'epoch': 0.58}
{'loss': 0.7995, 'learning_rate': 8.007766627139935e-06, 'epoch': 0.58}
{'loss': 0.7532, 'learning_rate': 8.000134424577351e-06, 'epoch': 0.58}
[2025-12-09 20:46:32,660] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step12000 is about to be saved!
[2025-12-09 20:46:33,156] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12000/global_step12000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 20:46:33,157] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12000/global_step12000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 20:46:33,310] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12000/global_step12000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 20:46:33,312] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12000/global_step12000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 20:47:10,282] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12000/global_step12000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 20:47:10,285] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12000/global_step12000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 20:47:17,260] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step12000 is ready now!
{'loss': 0.7538, 'learning_rate': 7.992503435286113e-06, 'epoch': 0.58}
{'loss': 0.8828, 'learning_rate': 7.984873663895762e-06, 'epoch': 0.58}
{'loss': 0.8571, 'learning_rate': 7.9772451150351e-06, 'epoch': 0.58}
{'loss': 0.8452, 'learning_rate': 7.969617793332184e-06, 'epoch': 0.58}
{'loss': 0.7351, 'learning_rate': 7.961991703414337e-06, 'epoch': 0.58}
{'loss': 0.8108, 'learning_rate': 7.954366849908121e-06, 'epoch': 0.58}
{'loss': 0.8652, 'learning_rate': 7.946743237439363e-06, 'epoch': 0.58}
{'loss': 0.6651, 'learning_rate': 7.939120870633123e-06, 'epoch': 0.58}
{'loss': 0.825, 'learning_rate': 7.931499754113713e-06, 'epoch': 0.58}
{'loss': 0.803, 'learning_rate': 7.923879892504686e-06, 'epoch': 0.58}
{'loss': 0.8382, 'learning_rate': 7.916261290428833e-06, 'epoch': 0.58}
{'loss': 0.7371, 'learning_rate': 7.908643952508177e-06, 'epoch': 0.58}
{'loss': 0.7992, 'learning_rate': 7.90102788336398e-06, 'epoch': 0.58}
{'loss': 0.7213, 'learning_rate': 7.893413087616733e-06, 'epoch': 0.58}
{'loss': 0.8381, 'learning_rate': 7.88579956988615e-06, 'epoch': 0.58}
{'loss': 0.8063, 'learning_rate': 7.878187334791176e-06, 'epoch': 0.58}
{'loss': 0.8264, 'learning_rate': 7.870576386949971e-06, 'epoch': 0.58}
{'loss': 0.6585, 'learning_rate': 7.862966730979922e-06, 'epoch': 0.58}
{'loss': 0.8155, 'learning_rate': 7.855358371497629e-06, 'epoch': 0.58}
{'loss': 0.7436, 'learning_rate': 7.847751313118898e-06, 'epoch': 0.58}
{'loss': 0.8123, 'learning_rate': 7.840145560458756e-06, 'epoch': 0.58}
{'loss': 0.8046, 'learning_rate': 7.832541118131437e-06, 'epoch': 0.58}
{'loss': 0.7364, 'learning_rate': 7.824937990750372e-06, 'epoch': 0.58}
{'loss': 0.864, 'learning_rate': 7.817336182928204e-06, 'epoch': 0.58}
{'loss': 0.7761, 'learning_rate': 7.809735699276765e-06, 'epoch': 0.58}
{'loss': 0.7629, 'learning_rate': 7.802136544407096e-06, 'epoch': 0.58}
{'loss': 0.8386, 'learning_rate': 7.794538722929417e-06, 'epoch': 0.58}
{'loss': 0.7163, 'learning_rate': 7.786942239453156e-06, 'epoch': 0.58}
{'loss': 0.7516, 'learning_rate': 7.779347098586916e-06, 'epoch': 0.58}
{'loss': 0.7662, 'learning_rate': 7.77175330493849e-06, 'epoch': 0.58}
{'loss': 0.797, 'learning_rate': 7.764160863114857e-06, 'epoch': 0.58}
{'loss': 0.7033, 'learning_rate': 7.756569777722167e-06, 'epoch': 0.58}
{'loss': 0.85, 'learning_rate': 7.74898005336576e-06, 'epoch': 0.59}
{'loss': 0.6819, 'learning_rate': 7.741391694650133e-06, 'epoch': 0.59}
{'loss': 0.8931, 'learning_rate': 7.733804706178974e-06, 'epoch': 0.59}
{'loss': 0.82, 'learning_rate': 7.726219092555127e-06, 'epoch': 0.59}
{'loss': 0.8083, 'learning_rate': 7.718634858380604e-06, 'epoch': 0.59}
{'loss': 0.7224, 'learning_rate': 7.711052008256583e-06, 'epoch': 0.59}
{'loss': 0.7922, 'learning_rate': 7.703470546783401e-06, 'epoch': 0.59}
{'loss': 0.6976, 'learning_rate': 7.695890478560548e-06, 'epoch': 0.59}
{'loss': 0.8208, 'learning_rate': 7.688311808186679e-06, 'epoch': 0.59}
{'loss': 0.802, 'learning_rate': 7.68073454025959e-06, 'epoch': 0.59}
{'loss': 0.8516, 'learning_rate': 7.673158679376233e-06, 'epoch': 0.59}
{'loss': 0.7849, 'learning_rate': 7.665584230132703e-06, 'epoch': 0.59}
{'loss': 0.832, 'learning_rate': 7.658011197124244e-06, 'epoch': 0.59}
{'loss': 0.8424, 'learning_rate': 7.65043958494523e-06, 'epoch': 0.59}
{'loss': 0.8326, 'learning_rate': 7.642869398189183e-06, 'epoch': 0.59}
{'loss': 0.7916, 'learning_rate': 7.63530064144876e-06, 'epoch': 0.59}
{'loss': 0.7775, 'learning_rate': 7.6277333193157435e-06, 'epoch': 0.59}
{'loss': 0.7676, 'learning_rate': 7.6201674363810475e-06, 'epoch': 0.59}
{'loss': 0.8213, 'learning_rate': 7.612602997234723e-06, 'epoch': 0.59}
{'loss': 0.7967, 'learning_rate': 7.605040006465931e-06, 'epoch': 0.59}
{'loss': 0.7811, 'learning_rate': 7.597478468662964e-06, 'epoch': 0.59}
{'loss': 0.8284, 'learning_rate': 7.589918388413224e-06, 'epoch': 0.59}
{'loss': 0.7763, 'learning_rate': 7.582359770303236e-06, 'epoch': 0.59}
{'loss': 0.8059, 'learning_rate': 7.5748026189186376e-06, 'epoch': 0.59}
{'loss': 0.7053, 'learning_rate': 7.567246938844171e-06, 'epoch': 0.59}
{'loss': 0.8529, 'learning_rate': 7.559692734663692e-06, 'epoch': 0.59}
{'loss': 0.7375, 'learning_rate': 7.552140010960155e-06, 'epoch': 0.59}
{'loss': 0.7745, 'learning_rate': 7.544588772315625e-06, 'epoch': 0.59}
{'loss': 0.7944, 'learning_rate': 7.537039023311255e-06, 'epoch': 0.59}
{'loss': 0.7941, 'learning_rate': 7.5294907685273035e-06, 'epoch': 0.59}
{'loss': 0.811, 'learning_rate': 7.521944012543117e-06, 'epoch': 0.59}
{'loss': 0.6856, 'learning_rate': 7.514398759937135e-06, 'epoch': 0.59}
{'loss': 0.834, 'learning_rate': 7.506855015286887e-06, 'epoch': 0.59}
{'loss': 0.7184, 'learning_rate': 7.499312783168981e-06, 'epoch': 0.59}
{'loss': 0.7939, 'learning_rate': 7.491772068159111e-06, 'epoch': 0.59}
{'loss': 0.7464, 'learning_rate': 7.484232874832059e-06, 'epoch': 0.59}
{'loss': 0.7423, 'learning_rate': 7.476695207761668e-06, 'epoch': 0.59}
{'loss': 0.8229, 'learning_rate': 7.469159071520871e-06, 'epoch': 0.59}
{'loss': 0.7421, 'learning_rate': 7.461624470681654e-06, 'epoch': 0.59}
{'loss': 0.6863, 'learning_rate': 7.45409140981509e-06, 'epoch': 0.59}
{'loss': 0.8138, 'learning_rate': 7.446559893491306e-06, 'epoch': 0.59}
{'loss': 0.7961, 'learning_rate': 7.439029926279498e-06, 'epoch': 0.59}
{'loss': 0.7841, 'learning_rate': 7.431501512747916e-06, 'epoch': 0.6}
{'loss': 0.8155, 'learning_rate': 7.423974657463875e-06, 'epoch': 0.6}
{'loss': 0.8258, 'learning_rate': 7.41644936499374e-06, 'epoch': 0.6}
WARNING: tokenization mismatch: 1 vs. 789. (ignored)
{'loss': 0.8013, 'learning_rate': 7.408925639902926e-06, 'epoch': 0.6}
{'loss': 0.6084, 'learning_rate': 7.401403486755903e-06, 'epoch': 0.6}
{'loss': 0.7878, 'learning_rate': 7.393882910116182e-06, 'epoch': 0.6}
{'loss': 0.8112, 'learning_rate': 7.386363914546322e-06, 'epoch': 0.6}
{'loss': 0.805, 'learning_rate': 7.3788465046079195e-06, 'epoch': 0.6}
{'loss': 0.8012, 'learning_rate': 7.371330684861607e-06, 'epoch': 0.6}
{'loss': 0.7347, 'learning_rate': 7.363816459867057e-06, 'epoch': 0.6}
{'loss': 0.8464, 'learning_rate': 7.356303834182978e-06, 'epoch': 0.6}
{'loss': 0.7561, 'learning_rate': 7.348792812367097e-06, 'epoch': 0.6}
{'loss': 0.6956, 'learning_rate': 7.341283398976178e-06, 'epoch': 0.6}
{'loss': 0.8652, 'learning_rate': 7.333775598566002e-06, 'epoch': 0.6}
{'loss': 0.8638, 'learning_rate': 7.326269415691375e-06, 'epoch': 0.6}
{'loss': 0.7551, 'learning_rate': 7.318764854906124e-06, 'epoch': 0.6}
{'loss': 0.7849, 'learning_rate': 7.311261920763087e-06, 'epoch': 0.6}
{'loss': 0.8077, 'learning_rate': 7.30376061781412e-06, 'epoch': 0.6}
{'loss': 0.807, 'learning_rate': 7.296260950610081e-06, 'epoch': 0.6}
{'loss': 0.7682, 'learning_rate': 7.2887629237008485e-06, 'epoch': 0.6}
{'loss': 0.6739, 'learning_rate': 7.281266541635293e-06, 'epoch': 0.6}
{'loss': 0.7887, 'learning_rate': 7.2737718089612985e-06, 'epoch': 0.6}
{'loss': 0.7996, 'learning_rate': 7.266278730225738e-06, 'epoch': 0.6}
{'loss': 0.8126, 'learning_rate': 7.258787309974488e-06, 'epoch': 0.6}
{'loss': 0.8517, 'learning_rate': 7.251297552752418e-06, 'epoch': 0.6}
{'loss': 0.7849, 'learning_rate': 7.243809463103381e-06, 'epoch': 0.6}
[2025-12-09 21:12:22,384] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step12500 is about to be saved!
[2025-12-09 21:12:22,473] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12500/global_step12500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 21:12:22,474] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12500/global_step12500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 21:12:23,066] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12500/global_step12500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 21:12:23,075] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12500/global_step12500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 21:13:10,833] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12500/global_step12500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 21:13:10,836] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-12500/global_step12500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 21:13:16,922] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step12500 is ready now!
{'loss': 0.7091, 'learning_rate': 7.236323045570233e-06, 'epoch': 0.6}
{'loss': 0.8672, 'learning_rate': 7.228838304694805e-06, 'epoch': 0.6}
{'loss': 0.8137, 'learning_rate': 7.221355245017909e-06, 'epoch': 0.6}
{'loss': 0.7386, 'learning_rate': 7.213873871079347e-06, 'epoch': 0.6}
{'loss': 0.7504, 'learning_rate': 7.206394187417887e-06, 'epoch': 0.6}
{'loss': 0.8433, 'learning_rate': 7.198916198571278e-06, 'epoch': 0.6}
{'loss': 0.8449, 'learning_rate': 7.191439909076243e-06, 'epoch': 0.6}
{'loss': 0.8259, 'learning_rate': 7.183965323468468e-06, 'epoch': 0.6}
{'loss': 0.831, 'learning_rate': 7.176492446282611e-06, 'epoch': 0.6}
{'loss': 0.6684, 'learning_rate': 7.169021282052283e-06, 'epoch': 0.6}
{'loss': 0.8545, 'learning_rate': 7.1615518353100726e-06, 'epoch': 0.6}
{'loss': 0.7182, 'learning_rate': 7.1540841105875105e-06, 'epoch': 0.6}
{'loss': 0.8389, 'learning_rate': 7.1466181124150935e-06, 'epoch': 0.6}
{'loss': 0.7951, 'learning_rate': 7.139153845322264e-06, 'epoch': 0.6}
{'loss': 0.7824, 'learning_rate': 7.131691313837419e-06, 'epoch': 0.6}
{'loss': 0.8107, 'learning_rate': 7.124230522487903e-06, 'epoch': 0.61}
{'loss': 0.8368, 'learning_rate': 7.116771475799993e-06, 'epoch': 0.61}
{'loss': 0.6489, 'learning_rate': 7.1093141782989275e-06, 'epoch': 0.61}
{'loss': 0.7223, 'learning_rate': 7.101858634508869e-06, 'epoch': 0.61}
{'loss': 0.8065, 'learning_rate': 7.0944048489529205e-06, 'epoch': 0.61}
{'loss': 0.7474, 'learning_rate': 7.08695282615312e-06, 'epoch': 0.61}
{'loss': 0.8661, 'learning_rate': 7.07950257063043e-06, 'epoch': 0.61}
{'loss': 0.8295, 'learning_rate': 7.072054086904747e-06, 'epoch': 0.61}
{'loss': 0.7652, 'learning_rate': 7.064607379494892e-06, 'epoch': 0.61}
{'loss': 0.8132, 'learning_rate': 7.057162452918607e-06, 'epoch': 0.61}
{'loss': 0.7104, 'learning_rate': 7.049719311692552e-06, 'epoch': 0.61}
{'loss': 0.8546, 'learning_rate': 7.042277960332305e-06, 'epoch': 0.61}
{'loss': 0.8239, 'learning_rate': 7.034838403352362e-06, 'epoch': 0.61}
{'loss': 0.8132, 'learning_rate': 7.027400645266123e-06, 'epoch': 0.61}
{'loss': 0.7543, 'learning_rate': 7.0199646905859055e-06, 'epoch': 0.61}
{'loss': 0.6692, 'learning_rate': 7.012530543822921e-06, 'epoch': 0.61}
{'loss': 0.8674, 'learning_rate': 7.005098209487295e-06, 'epoch': 0.61}
{'loss': 0.8492, 'learning_rate': 6.997667692088053e-06, 'epoch': 0.61}
{'loss': 0.7357, 'learning_rate': 6.990238996133109e-06, 'epoch': 0.61}
{'loss': 0.8708, 'learning_rate': 6.982812126129281e-06, 'epoch': 0.61}
{'loss': 0.8111, 'learning_rate': 6.975387086582279e-06, 'epoch': 0.61}
{'loss': 0.7923, 'learning_rate': 6.967963881996693e-06, 'epoch': 0.61}
{'loss': 0.7665, 'learning_rate': 6.960542516876014e-06, 'epoch': 0.61}
{'loss': 0.7486, 'learning_rate': 6.953122995722601e-06, 'epoch': 0.61}
{'loss': 0.8062, 'learning_rate': 6.945705323037709e-06, 'epoch': 0.61}
{'loss': 0.6435, 'learning_rate': 6.938289503321465e-06, 'epoch': 0.61}
{'loss': 0.8599, 'learning_rate': 6.930875541072868e-06, 'epoch': 0.61}
{'loss': 0.8085, 'learning_rate': 6.923463440789799e-06, 'epoch': 0.61}
{'loss': 0.778, 'learning_rate': 6.916053206969e-06, 'epoch': 0.61}
{'loss': 0.8066, 'learning_rate': 6.908644844106091e-06, 'epoch': 0.61}
{'loss': 0.8281, 'learning_rate': 6.901238356695545e-06, 'epoch': 0.61}
{'loss': 0.8862, 'learning_rate': 6.893833749230709e-06, 'epoch': 0.61}
{'loss': 0.6389, 'learning_rate': 6.8864310262037795e-06, 'epoch': 0.61}
{'loss': 0.7523, 'learning_rate': 6.8790301921058155e-06, 'epoch': 0.61}
{'loss': 0.7935, 'learning_rate': 6.871631251426729e-06, 'epoch': 0.61}
{'loss': 0.7332, 'learning_rate': 6.864234208655287e-06, 'epoch': 0.61}
{'loss': 0.7437, 'learning_rate': 6.856839068279096e-06, 'epoch': 0.61}
{'loss': 0.7322, 'learning_rate': 6.849445834784616e-06, 'epoch': 0.61}
{'loss': 0.7779, 'learning_rate': 6.842054512657146e-06, 'epoch': 0.61}
{'loss': 0.6827, 'learning_rate': 6.834665106380829e-06, 'epoch': 0.61}
{'loss': 0.7896, 'learning_rate': 6.827277620438641e-06, 'epoch': 0.61}
{'loss': 0.7742, 'learning_rate': 6.8198920593123966e-06, 'epoch': 0.61}
{'loss': 0.8525, 'learning_rate': 6.812508427482745e-06, 'epoch': 0.62}
{'loss': 0.82, 'learning_rate': 6.805126729429158e-06, 'epoch': 0.62}
{'loss': 0.7433, 'learning_rate': 6.797746969629941e-06, 'epoch': 0.62}
{'loss': 0.8032, 'learning_rate': 6.7903691525622166e-06, 'epoch': 0.62}
{'loss': 0.8222, 'learning_rate': 6.782993282701936e-06, 'epoch': 0.62}
{'loss': 0.839, 'learning_rate': 6.775619364523863e-06, 'epoch': 0.62}
{'loss': 0.6362, 'learning_rate': 6.768247402501585e-06, 'epoch': 0.62}
{'loss': 0.7763, 'learning_rate': 6.76087740110749e-06, 'epoch': 0.62}
{'loss': 0.8285, 'learning_rate': 6.753509364812789e-06, 'epoch': 0.62}
{'loss': 0.7532, 'learning_rate': 6.746143298087494e-06, 'epoch': 0.62}
{'loss': 0.7997, 'learning_rate': 6.738779205400429e-06, 'epoch': 0.62}
{'loss': 0.8508, 'learning_rate': 6.731417091219212e-06, 'epoch': 0.62}
{'loss': 0.7825, 'learning_rate': 6.724056960010268e-06, 'epoch': 0.62}
{'loss': 0.8081, 'learning_rate': 6.716698816238807e-06, 'epoch': 0.62}
{'loss': 0.6526, 'learning_rate': 6.70934266436885e-06, 'epoch': 0.62}
{'loss': 0.8472, 'learning_rate': 6.701988508863195e-06, 'epoch': 0.62}
{'loss': 0.7241, 'learning_rate': 6.694636354183439e-06, 'epoch': 0.62}
{'loss': 0.8293, 'learning_rate': 6.68728620478996e-06, 'epoch': 0.62}
{'loss': 0.7679, 'learning_rate': 6.679938065141918e-06, 'epoch': 0.62}
{'loss': 0.7541, 'learning_rate': 6.672591939697261e-06, 'epoch': 0.62}
{'loss': 0.8267, 'learning_rate': 6.665247832912707e-06, 'epoch': 0.62}
{'loss': 0.8087, 'learning_rate': 6.657905749243754e-06, 'epoch': 0.62}
{'loss': 0.7955, 'learning_rate': 6.650565693144669e-06, 'epoch': 0.62}
{'loss': 0.7752, 'learning_rate': 6.643227669068495e-06, 'epoch': 0.62}
{'loss': 0.8316, 'learning_rate': 6.635891681467034e-06, 'epoch': 0.62}
{'loss': 0.7994, 'learning_rate': 6.628557734790862e-06, 'epoch': 0.62}
{'loss': 0.7579, 'learning_rate': 6.6212258334893e-06, 'epoch': 0.62}
{'loss': 0.8362, 'learning_rate': 6.613895982010456e-06, 'epoch': 0.62}
{'loss': 0.6064, 'learning_rate': 6.60656818480117e-06, 'epoch': 0.62}
{'loss': 0.8777, 'learning_rate': 6.5992424463070455e-06, 'epoch': 0.62}
{'loss': 0.6394, 'learning_rate': 6.591918770972434e-06, 'epoch': 0.62}
{'loss': 0.7039, 'learning_rate': 6.584597163240438e-06, 'epoch': 0.62}
{'loss': 0.8045, 'learning_rate': 6.577277627552904e-06, 'epoch': 0.62}
{'loss': 0.8148, 'learning_rate': 6.569960168350422e-06, 'epoch': 0.62}
{'loss': 0.7795, 'learning_rate': 6.562644790072322e-06, 'epoch': 0.62}
{'loss': 0.7614, 'learning_rate': 6.555331497156671e-06, 'epoch': 0.62}
{'loss': 0.8237, 'learning_rate': 6.548020294040276e-06, 'epoch': 0.62}
{'loss': 0.7324, 'learning_rate': 6.5407111851586655e-06, 'epoch': 0.62}
{'loss': 0.8189, 'learning_rate': 6.533404174946107e-06, 'epoch': 0.62}
{'loss': 0.8204, 'learning_rate': 6.5260992678355904e-06, 'epoch': 0.62}
{'loss': 0.7952, 'learning_rate': 6.518796468258834e-06, 'epoch': 0.62}
{'loss': 0.7684, 'learning_rate': 6.511495780646269e-06, 'epoch': 0.63}
{'loss': 0.7977, 'learning_rate': 6.504197209427051e-06, 'epoch': 0.63}
[2025-12-09 21:38:16,137] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step13000 is about to be saved!
[2025-12-09 21:38:16,229] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13000/global_step13000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 21:38:16,230] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13000/global_step13000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 21:38:16,826] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13000/global_step13000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 21:38:16,834] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13000/global_step13000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 21:39:01,692] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13000/global_step13000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 21:39:01,695] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13000/global_step13000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 21:39:05,643] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step13000 is ready now!
{'loss': 0.8067, 'learning_rate': 6.496900759029055e-06, 'epoch': 0.63}
{'loss': 0.7154, 'learning_rate': 6.4896064338788674e-06, 'epoch': 0.63}
{'loss': 0.8498, 'learning_rate': 6.482314238401779e-06, 'epoch': 0.63}
{'loss': 0.7787, 'learning_rate': 6.475024177021795e-06, 'epoch': 0.63}
{'loss': 0.8381, 'learning_rate': 6.467736254161621e-06, 'epoch': 0.63}
{'loss': 0.7449, 'learning_rate': 6.460450474242672e-06, 'epoch': 0.63}
{'loss': 0.7851, 'learning_rate': 6.453166841685057e-06, 'epoch': 0.63}
{'loss': 0.7383, 'learning_rate': 6.445885360907586e-06, 'epoch': 0.63}
{'loss': 0.7144, 'learning_rate': 6.438606036327759e-06, 'epoch': 0.63}
{'loss': 0.7083, 'learning_rate': 6.431328872361773e-06, 'epoch': 0.63}
{'loss': 0.7563, 'learning_rate': 6.424053873424514e-06, 'epoch': 0.63}
{'loss': 0.7519, 'learning_rate': 6.416781043929547e-06, 'epoch': 0.63}
{'loss': 0.7796, 'learning_rate': 6.409510388289131e-06, 'epoch': 0.63}
{'loss': 0.8123, 'learning_rate': 6.402241910914198e-06, 'epoch': 0.63}
{'loss': 0.7152, 'learning_rate': 6.3949756162143665e-06, 'epoch': 0.63}
{'loss': 0.7933, 'learning_rate': 6.387711508597921e-06, 'epoch': 0.63}
{'loss': 0.7697, 'learning_rate': 6.380449592471826e-06, 'epoch': 0.63}
{'loss': 0.8676, 'learning_rate': 6.3731898722417186e-06, 'epoch': 0.63}
{'loss': 0.7191, 'learning_rate': 6.365932352311899e-06, 'epoch': 0.63}
{'loss': 0.8737, 'learning_rate': 6.358677037085331e-06, 'epoch': 0.63}
{'loss': 0.8519, 'learning_rate': 6.3514239309636474e-06, 'epoch': 0.63}
{'loss': 0.7216, 'learning_rate': 6.344173038347132e-06, 'epoch': 0.63}
{'loss': 0.8437, 'learning_rate': 6.336924363634734e-06, 'epoch': 0.63}
{'loss': 0.7056, 'learning_rate': 6.329677911224052e-06, 'epoch': 0.63}
{'loss': 0.8126, 'learning_rate': 6.32243368551134e-06, 'epoch': 0.63}
{'loss': 0.85, 'learning_rate': 6.315191690891496e-06, 'epoch': 0.63}
{'loss': 0.7508, 'learning_rate': 6.307951931758067e-06, 'epoch': 0.63}
{'loss': 0.7664, 'learning_rate': 6.30071441250325e-06, 'epoch': 0.63}
{'loss': 0.753, 'learning_rate': 6.2934791375178725e-06, 'epoch': 0.63}
{'loss': 0.8119, 'learning_rate': 6.28624611119141e-06, 'epoch': 0.63}
{'loss': 0.8442, 'learning_rate': 6.279015337911963e-06, 'epoch': 0.63}
{'loss': 0.8294, 'learning_rate': 6.271786822066277e-06, 'epoch': 0.63}
{'loss': 0.7499, 'learning_rate': 6.264560568039717e-06, 'epoch': 0.63}
{'loss': 0.7069, 'learning_rate': 6.2573365802162834e-06, 'epoch': 0.63}
{'loss': 0.8428, 'learning_rate': 6.250114862978601e-06, 'epoch': 0.63}
{'loss': 0.7786, 'learning_rate': 6.242895420707917e-06, 'epoch': 0.63}
{'loss': 0.8013, 'learning_rate': 6.235678257784094e-06, 'epoch': 0.63}
{'loss': 0.7644, 'learning_rate': 6.228463378585616e-06, 'epoch': 0.63}
{'loss': 0.7625, 'learning_rate': 6.221250787489578e-06, 'epoch': 0.63}
{'loss': 0.6236, 'learning_rate': 6.214040488871693e-06, 'epoch': 0.63}
{'loss': 0.8168, 'learning_rate': 6.206832487106276e-06, 'epoch': 0.64}
{'loss': 0.636, 'learning_rate': 6.199626786566253e-06, 'epoch': 0.64}
{'loss': 0.7879, 'learning_rate': 6.192423391623152e-06, 'epoch': 0.64}
{'loss': 0.7939, 'learning_rate': 6.185222306647105e-06, 'epoch': 0.64}
{'loss': 0.6924, 'learning_rate': 6.1780235360068404e-06, 'epoch': 0.64}
{'loss': 0.8128, 'learning_rate': 6.170827084069682e-06, 'epoch': 0.64}
{'loss': 0.7903, 'learning_rate': 6.163632955201547e-06, 'epoch': 0.64}
{'loss': 0.7803, 'learning_rate': 6.156441153766944e-06, 'epoch': 0.64}
{'loss': 0.8385, 'learning_rate': 6.149251684128973e-06, 'epoch': 0.64}
{'loss': 0.6593, 'learning_rate': 6.142064550649308e-06, 'epoch': 0.64}
{'loss': 0.7726, 'learning_rate': 6.1348797576882215e-06, 'epoch': 0.64}
{'loss': 0.7216, 'learning_rate': 6.1276973096045555e-06, 'epoch': 0.64}
{'loss': 0.8121, 'learning_rate': 6.120517210755734e-06, 'epoch': 0.64}
{'loss': 0.7612, 'learning_rate': 6.1133394654977495e-06, 'epoch': 0.64}
{'loss': 0.8258, 'learning_rate': 6.106164078185176e-06, 'epoch': 0.64}
{'loss': 0.774, 'learning_rate': 6.098991053171147e-06, 'epoch': 0.64}
{'loss': 0.7197, 'learning_rate': 6.091820394807373e-06, 'epoch': 0.64}
{'loss': 0.8044, 'learning_rate': 6.0846521074441176e-06, 'epoch': 0.64}
{'loss': 0.8521, 'learning_rate': 6.077486195430218e-06, 'epoch': 0.64}
{'loss': 0.7633, 'learning_rate': 6.070322663113059e-06, 'epoch': 0.64}
{'loss': 0.7405, 'learning_rate': 6.0631615148385895e-06, 'epoch': 0.64}
{'loss': 0.7797, 'learning_rate': 6.056002754951311e-06, 'epoch': 0.64}
{'loss': 0.7276, 'learning_rate': 6.0488463877942715e-06, 'epoch': 0.64}
{'loss': 0.7385, 'learning_rate': 6.041692417709073e-06, 'epoch': 0.64}
{'loss': 0.737, 'learning_rate': 6.034540849035857e-06, 'epoch': 0.64}
{'loss': 0.8106, 'learning_rate': 6.0273916861133176e-06, 'epoch': 0.64}
{'loss': 0.8063, 'learning_rate': 6.020244933278676e-06, 'epoch': 0.64}
{'loss': 0.9056, 'learning_rate': 6.013100594867704e-06, 'epoch': 0.64}
{'loss': 0.7836, 'learning_rate': 6.005958675214702e-06, 'epoch': 0.64}
{'loss': 0.8525, 'learning_rate': 5.998819178652508e-06, 'epoch': 0.64}
{'loss': 0.8408, 'learning_rate': 5.991682109512481e-06, 'epoch': 0.64}
{'loss': 0.7247, 'learning_rate': 5.9845474721245175e-06, 'epoch': 0.64}
{'loss': 0.7613, 'learning_rate': 5.977415270817029e-06, 'epoch': 0.64}
{'loss': 0.8222, 'learning_rate': 5.970285509916959e-06, 'epoch': 0.64}
{'loss': 0.7446, 'learning_rate': 5.963158193749761e-06, 'epoch': 0.64}
{'loss': 0.8974, 'learning_rate': 5.9560333266394135e-06, 'epoch': 0.64}
{'loss': 0.7282, 'learning_rate': 5.948910912908402e-06, 'epoch': 0.64}
{'loss': 0.8289, 'learning_rate': 5.941790956877729e-06, 'epoch': 0.64}
{'loss': 0.8368, 'learning_rate': 5.934673462866907e-06, 'epoch': 0.64}
{'loss': 0.7294, 'learning_rate': 5.9275584351939476e-06, 'epoch': 0.64}
{'loss': 0.7126, 'learning_rate': 5.920445878175374e-06, 'epoch': 0.64}
{'loss': 0.8444, 'learning_rate': 5.9133357961262024e-06, 'epoch': 0.64}
{'loss': 0.9029, 'learning_rate': 5.906228193359957e-06, 'epoch': 0.65}
{'loss': 0.8192, 'learning_rate': 5.899123074188648e-06, 'epoch': 0.65}
{'loss': 0.868, 'learning_rate': 5.892020442922788e-06, 'epoch': 0.65}
{'loss': 0.8277, 'learning_rate': 5.884920303871376e-06, 'epoch': 0.65}
{'loss': 0.7984, 'learning_rate': 5.877822661341899e-06, 'epoch': 0.65}
{'loss': 0.8012, 'learning_rate': 5.870727519640327e-06, 'epoch': 0.65}
{'loss': 0.8727, 'learning_rate': 5.86363488307112e-06, 'epoch': 0.65}
{'loss': 0.7666, 'learning_rate': 5.856544755937208e-06, 'epoch': 0.65}
{'loss': 0.7376, 'learning_rate': 5.849457142540008e-06, 'epoch': 0.65}
{'loss': 0.8576, 'learning_rate': 5.842372047179405e-06, 'epoch': 0.65}
{'loss': 0.823, 'learning_rate': 5.835289474153762e-06, 'epoch': 0.65}
{'loss': 0.7717, 'learning_rate': 5.82820942775991e-06, 'epoch': 0.65}
{'loss': 0.8416, 'learning_rate': 5.821131912293145e-06, 'epoch': 0.65}
{'loss': 0.8534, 'learning_rate': 5.814056932047226e-06, 'epoch': 0.65}
{'loss': 0.8164, 'learning_rate': 5.8069844913143824e-06, 'epoch': 0.65}
{'loss': 0.8252, 'learning_rate': 5.799914594385296e-06, 'epoch': 0.65}
{'loss': 0.8488, 'learning_rate': 5.792847245549104e-06, 'epoch': 0.65}
{'loss': 0.7561, 'learning_rate': 5.7857824490934e-06, 'epoch': 0.65}
[2025-12-09 22:03:49,743] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step13500 is about to be saved!
[2025-12-09 22:03:49,774] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13500/global_step13500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 22:03:49,774] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13500/global_step13500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 22:03:49,934] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13500/global_step13500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 22:03:49,937] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13500/global_step13500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 22:04:29,657] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13500/global_step13500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 22:04:29,661] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-13500/global_step13500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 22:04:29,861] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step13500 is ready now!
{'loss': 0.82, 'learning_rate': 5.7787202093042316e-06, 'epoch': 0.65}
{'loss': 0.7864, 'learning_rate': 5.771660530466097e-06, 'epoch': 0.65}
{'loss': 0.705, 'learning_rate': 5.7646034168619335e-06, 'epoch': 0.65}
{'loss': 0.8335, 'learning_rate': 5.757548872773122e-06, 'epoch': 0.65}
{'loss': 0.8382, 'learning_rate': 5.750496902479495e-06, 'epoch': 0.65}
{'loss': 0.7406, 'learning_rate': 5.743447510259315e-06, 'epoch': 0.65}
{'loss': 0.7862, 'learning_rate': 5.73640070038928e-06, 'epoch': 0.65}
{'loss': 0.8105, 'learning_rate': 5.729356477144521e-06, 'epoch': 0.65}
{'loss': 0.704, 'learning_rate': 5.722314844798611e-06, 'epoch': 0.65}
{'loss': 0.7915, 'learning_rate': 5.715275807623536e-06, 'epoch': 0.65}
{'loss': 0.8223, 'learning_rate': 5.7082393698897164e-06, 'epoch': 0.65}
{'loss': 0.849, 'learning_rate': 5.701205535865988e-06, 'epoch': 0.65}
{'loss': 0.805, 'learning_rate': 5.69417430981962e-06, 'epoch': 0.65}
{'loss': 0.8294, 'learning_rate': 5.68714569601629e-06, 'epoch': 0.65}
{'loss': 0.9001, 'learning_rate': 5.680119698720086e-06, 'epoch': 0.65}
{'loss': 0.8333, 'learning_rate': 5.673096322193523e-06, 'epoch': 0.65}
{'loss': 0.8234, 'learning_rate': 5.666075570697511e-06, 'epoch': 0.65}
{'loss': 0.8405, 'learning_rate': 5.659057448491384e-06, 'epoch': 0.65}
{'loss': 0.6097, 'learning_rate': 5.652041959832866e-06, 'epoch': 0.65}
{'loss': 0.8644, 'learning_rate': 5.645029108978083e-06, 'epoch': 0.65}
{'loss': 0.7702, 'learning_rate': 5.638018900181576e-06, 'epoch': 0.65}
{'loss': 0.7618, 'learning_rate': 5.631011337696272e-06, 'epoch': 0.65}
{'loss': 0.8068, 'learning_rate': 5.624006425773486e-06, 'epoch': 0.65}
{'loss': 0.8413, 'learning_rate': 5.617004168662944e-06, 'epoch': 0.66}
{'loss': 0.8051, 'learning_rate': 5.610004570612745e-06, 'epoch': 0.66}
{'loss': 0.7566, 'learning_rate': 5.60300763586938e-06, 'epoch': 0.66}
{'loss': 0.8114, 'learning_rate': 5.596013368677722e-06, 'epoch': 0.66}
{'loss': 0.7491, 'learning_rate': 5.589021773281036e-06, 'epoch': 0.66}
{'loss': 0.8051, 'learning_rate': 5.582032853920953e-06, 'epoch': 0.66}
{'loss': 0.7627, 'learning_rate': 5.5750466148374825e-06, 'epoch': 0.66}
{'loss': 0.7733, 'learning_rate': 5.568063060269019e-06, 'epoch': 0.66}
{'loss': 0.8161, 'learning_rate': 5.561082194452316e-06, 'epoch': 0.66}
{'loss': 0.8185, 'learning_rate': 5.554104021622503e-06, 'epoch': 0.66}
{'loss': 0.8271, 'learning_rate': 5.547128546013065e-06, 'epoch': 0.66}
{'loss': 0.7635, 'learning_rate': 5.540155771855866e-06, 'epoch': 0.66}
{'loss': 0.8041, 'learning_rate': 5.533185703381128e-06, 'epoch': 0.66}
{'loss': 0.811, 'learning_rate': 5.526218344817421e-06, 'epoch': 0.66}
{'loss': 0.6771, 'learning_rate': 5.519253700391676e-06, 'epoch': 0.66}
{'loss': 0.7343, 'learning_rate': 5.512291774329184e-06, 'epoch': 0.66}
{'loss': 0.8777, 'learning_rate': 5.505332570853579e-06, 'epoch': 0.66}
{'loss': 0.8436, 'learning_rate': 5.498376094186846e-06, 'epoch': 0.66}
{'loss': 0.7896, 'learning_rate': 5.49142234854931e-06, 'epoch': 0.66}
{'loss': 0.6867, 'learning_rate': 5.484471338159656e-06, 'epoch': 0.66}
{'loss': 0.8734, 'learning_rate': 5.477523067234891e-06, 'epoch': 0.66}
{'loss': 0.8015, 'learning_rate': 5.470577539990369e-06, 'epoch': 0.66}
{'loss': 0.6182, 'learning_rate': 5.463634760639773e-06, 'epoch': 0.66}
{'loss': 0.8731, 'learning_rate': 5.456694733395133e-06, 'epoch': 0.66}
{'loss': 0.811, 'learning_rate': 5.449757462466795e-06, 'epoch': 0.66}
{'loss': 0.8046, 'learning_rate': 5.4428229520634335e-06, 'epoch': 0.66}
{'loss': 0.7525, 'learning_rate': 5.435891206392059e-06, 'epoch': 0.66}
{'loss': 0.7431, 'learning_rate': 5.428962229657999e-06, 'epoch': 0.66}
{'loss': 0.7885, 'learning_rate': 5.422036026064899e-06, 'epoch': 0.66}
{'loss': 0.7926, 'learning_rate': 5.41511259981472e-06, 'epoch': 0.66}
{'loss': 0.7781, 'learning_rate': 5.408191955107743e-06, 'epoch': 0.66}
{'loss': 0.7471, 'learning_rate': 5.401274096142566e-06, 'epoch': 0.66}
{'loss': 0.715, 'learning_rate': 5.394359027116085e-06, 'epoch': 0.66}
{'loss': 0.7669, 'learning_rate': 5.387446752223507e-06, 'epoch': 0.66}
{'loss': 0.8416, 'learning_rate': 5.380537275658355e-06, 'epoch': 0.66}
{'loss': 0.8032, 'learning_rate': 5.373630601612443e-06, 'epoch': 0.66}
{'loss': 0.7909, 'learning_rate': 5.366726734275883e-06, 'epoch': 0.66}
{'loss': 0.762, 'learning_rate': 5.3598256778370886e-06, 'epoch': 0.66}
{'loss': 0.7535, 'learning_rate': 5.352927436482776e-06, 'epoch': 0.66}
{'loss': 0.8675, 'learning_rate': 5.346032014397938e-06, 'epoch': 0.66}
{'loss': 0.7664, 'learning_rate': 5.339139415765866e-06, 'epoch': 0.66}
{'loss': 0.7011, 'learning_rate': 5.332249644768142e-06, 'epoch': 0.66}
{'loss': 0.6386, 'learning_rate': 5.325362705584623e-06, 'epoch': 0.67}
{'loss': 0.8089, 'learning_rate': 5.318478602393453e-06, 'epoch': 0.67}
{'loss': 0.7455, 'learning_rate': 5.31159733937106e-06, 'epoch': 0.67}
{'loss': 0.7588, 'learning_rate': 5.3047189206921354e-06, 'epoch': 0.67}
{'loss': 0.7834, 'learning_rate': 5.297843350529664e-06, 'epoch': 0.67}
{'loss': 0.83, 'learning_rate': 5.290970633054888e-06, 'epoch': 0.67}
{'loss': 0.7747, 'learning_rate': 5.2841007724373195e-06, 'epoch': 0.67}
{'loss': 0.7735, 'learning_rate': 5.277233772844748e-06, 'epoch': 0.67}
{'loss': 0.7994, 'learning_rate': 5.270369638443216e-06, 'epoch': 0.67}
{'loss': 0.8293, 'learning_rate': 5.263508373397033e-06, 'epoch': 0.67}
{'loss': 0.6788, 'learning_rate': 5.256649981868763e-06, 'epoch': 0.67}
{'loss': 0.7705, 'learning_rate': 5.2497944680192395e-06, 'epoch': 0.67}
{'loss': 0.8397, 'learning_rate': 5.242941836007536e-06, 'epoch': 0.67}
{'loss': 0.7595, 'learning_rate': 5.236092089990983e-06, 'epoch': 0.67}
{'loss': 0.7826, 'learning_rate': 5.229245234125156e-06, 'epoch': 0.67}
{'loss': 0.6888, 'learning_rate': 5.222401272563891e-06, 'epoch': 0.67}
{'loss': 0.7849, 'learning_rate': 5.215560209459252e-06, 'epoch': 0.67}
{'loss': 0.7741, 'learning_rate': 5.208722048961548e-06, 'epoch': 0.67}
{'loss': 0.685, 'learning_rate': 5.201886795219333e-06, 'epoch': 0.67}
{'loss': 0.849, 'learning_rate': 5.1950544523794e-06, 'epoch': 0.67}
{'loss': 0.7901, 'learning_rate': 5.188225024586764e-06, 'epoch': 0.67}
{'loss': 0.7902, 'learning_rate': 5.181398515984682e-06, 'epoch': 0.67}
{'loss': 0.7678, 'learning_rate': 5.174574930714627e-06, 'epoch': 0.67}
{'loss': 0.8395, 'learning_rate': 5.167754272916321e-06, 'epoch': 0.67}
{'loss': 0.7595, 'learning_rate': 5.160936546727687e-06, 'epoch': 0.67}
{'loss': 0.8086, 'learning_rate': 5.154121756284879e-06, 'epoch': 0.67}
{'loss': 0.7949, 'learning_rate': 5.147309905722276e-06, 'epoch': 0.67}
{'loss': 0.7817, 'learning_rate': 5.140500999172463e-06, 'epoch': 0.67}
{'loss': 0.8239, 'learning_rate': 5.133695040766244e-06, 'epoch': 0.67}
{'loss': 0.7897, 'learning_rate': 5.12689203463263e-06, 'epoch': 0.67}
{'loss': 0.8047, 'learning_rate': 5.120091984898852e-06, 'epoch': 0.67}
{'loss': 0.9103, 'learning_rate': 5.113294895690335e-06, 'epoch': 0.67}
{'loss': 0.7106, 'learning_rate': 5.106500771130711e-06, 'epoch': 0.67}
{'loss': 0.7936, 'learning_rate': 5.099709615341824e-06, 'epoch': 0.67}
{'loss': 0.7091, 'learning_rate': 5.092921432443696e-06, 'epoch': 0.67}
[2025-12-09 22:38:46,895] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step14000 is about to be saved!
[2025-12-09 22:38:46,986] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14000/global_step14000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 22:38:46,987] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14000/global_step14000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 22:38:47,585] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14000/global_step14000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 22:38:47,593] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14000/global_step14000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 22:39:45,940] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14000/global_step14000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 22:39:45,943] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14000/global_step14000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 22:39:45,956] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step14000 is ready now!
{'loss': 0.8528, 'learning_rate': 5.08613622655457e-06, 'epoch': 0.67}
WARNING: tokenization mismatch: 1 vs. 737. (ignored)
{'loss': 0.8379, 'learning_rate': 5.079354001790865e-06, 'epoch': 0.67}
{'loss': 0.7132, 'learning_rate': 5.072574762267193e-06, 'epoch': 0.67}
{'loss': 0.8352, 'learning_rate': 5.065798512096367e-06, 'epoch': 0.67}
{'loss': 0.7919, 'learning_rate': 5.059025255389373e-06, 'epoch': 0.67}
{'loss': 0.8304, 'learning_rate': 5.052254996255386e-06, 'epoch': 0.67}
{'loss': 0.7803, 'learning_rate': 5.045487738801766e-06, 'epoch': 0.68}
{'loss': 0.7528, 'learning_rate': 5.038723487134049e-06, 'epoch': 0.68}
{'loss': 0.6153, 'learning_rate': 5.031962245355943e-06, 'epoch': 0.68}
{'loss': 0.7302, 'learning_rate': 5.025204017569336e-06, 'epoch': 0.68}
{'loss': 0.779, 'learning_rate': 5.018448807874288e-06, 'epoch': 0.68}
{'loss': 0.8023, 'learning_rate': 5.011696620369024e-06, 'epoch': 0.68}
{'loss': 0.851, 'learning_rate': 5.004947459149937e-06, 'epoch': 0.68}
{'loss': 0.8103, 'learning_rate': 4.998201328311581e-06, 'epoch': 0.68}
{'loss': 0.8312, 'learning_rate': 4.99145823194668e-06, 'epoch': 0.68}
{'loss': 0.7753, 'learning_rate': 4.984718174146111e-06, 'epoch': 0.68}
{'loss': 0.7526, 'learning_rate': 4.977981158998901e-06, 'epoch': 0.68}
{'loss': 0.7442, 'learning_rate': 4.9712471905922465e-06, 'epoch': 0.68}
{'loss': 0.809, 'learning_rate': 4.964516273011488e-06, 'epoch': 0.68}
{'loss': 0.7104, 'learning_rate': 4.957788410340112e-06, 'epoch': 0.68}
{'loss': 0.7969, 'learning_rate': 4.951063606659754e-06, 'epoch': 0.68}
{'loss': 0.7803, 'learning_rate': 4.94434186605019e-06, 'epoch': 0.68}
{'loss': 0.7659, 'learning_rate': 4.937623192589351e-06, 'epoch': 0.68}
{'loss': 0.7139, 'learning_rate': 4.9309075903532935e-06, 'epoch': 0.68}
{'loss': 0.7954, 'learning_rate': 4.92419506341621e-06, 'epoch': 0.68}
{'loss': 0.7687, 'learning_rate': 4.9174856158504405e-06, 'epoch': 0.68}
{'loss': 0.8046, 'learning_rate': 4.910779251726447e-06, 'epoch': 0.68}
{'loss': 0.7999, 'learning_rate': 4.90407597511282e-06, 'epoch': 0.68}
{'loss': 0.7197, 'learning_rate': 4.8973757900762765e-06, 'epoch': 0.68}
{'loss': 0.7339, 'learning_rate': 4.890678700681669e-06, 'epoch': 0.68}
{'loss': 0.7461, 'learning_rate': 4.883984710991961e-06, 'epoch': 0.68}
{'loss': 0.8956, 'learning_rate': 4.877293825068233e-06, 'epoch': 0.68}
{'loss': 0.8216, 'learning_rate': 4.8706060469696966e-06, 'epoch': 0.68}
{'loss': 0.6897, 'learning_rate': 4.863921380753661e-06, 'epoch': 0.68}
{'loss': 0.7625, 'learning_rate': 4.857239830475564e-06, 'epoch': 0.68}
{'loss': 0.8442, 'learning_rate': 4.85056140018894e-06, 'epoch': 0.68}
{'loss': 0.7691, 'learning_rate': 4.8438860939454325e-06, 'epoch': 0.68}
{'loss': 0.791, 'learning_rate': 4.8372139157948e-06, 'epoch': 0.68}
{'loss': 0.7688, 'learning_rate': 4.830544869784891e-06, 'epoch': 0.68}
{'loss': 0.7952, 'learning_rate': 4.823878959961656e-06, 'epoch': 0.68}
{'loss': 0.7578, 'learning_rate': 4.817216190369154e-06, 'epoch': 0.68}
{'loss': 0.7532, 'learning_rate': 4.810556565049524e-06, 'epoch': 0.68}
{'loss': 0.7936, 'learning_rate': 4.803900088043007e-06, 'epoch': 0.68}
{'loss': 0.7925, 'learning_rate': 4.797246763387922e-06, 'epoch': 0.68}
{'loss': 0.7905, 'learning_rate': 4.790596595120699e-06, 'epoch': 0.68}
{'loss': 0.7795, 'learning_rate': 4.783949587275829e-06, 'epoch': 0.68}
{'loss': 0.7909, 'learning_rate': 4.7773057438858975e-06, 'epoch': 0.68}
{'loss': 0.7784, 'learning_rate': 4.770665068981563e-06, 'epoch': 0.68}
{'loss': 0.7207, 'learning_rate': 4.7640275665915745e-06, 'epoch': 0.69}
{'loss': 0.8646, 'learning_rate': 4.757393240742742e-06, 'epoch': 0.69}
{'loss': 0.7962, 'learning_rate': 4.75076209545996e-06, 'epoch': 0.69}
{'loss': 0.8148, 'learning_rate': 4.744134134766183e-06, 'epoch': 0.69}
{'loss': 0.7351, 'learning_rate': 4.737509362682444e-06, 'epoch': 0.69}
{'loss': 0.812, 'learning_rate': 4.730887783227834e-06, 'epoch': 0.69}
{'loss': 0.7358, 'learning_rate': 4.72426940041951e-06, 'epoch': 0.69}
{'loss': 0.7831, 'learning_rate': 4.717654218272684e-06, 'epoch': 0.69}
{'loss': 0.8214, 'learning_rate': 4.711042240800637e-06, 'epoch': 0.69}
{'loss': 0.738, 'learning_rate': 4.704433472014699e-06, 'epoch': 0.69}
{'loss': 0.7904, 'learning_rate': 4.697827915924249e-06, 'epoch': 0.69}
{'loss': 0.7865, 'learning_rate': 4.691225576536732e-06, 'epoch': 0.69}
{'loss': 0.7427, 'learning_rate': 4.684626457857625e-06, 'epoch': 0.69}
{'loss': 0.7906, 'learning_rate': 4.67803056389046e-06, 'epoch': 0.69}
{'loss': 0.8147, 'learning_rate': 4.671437898636806e-06, 'epoch': 0.69}
{'loss': 0.7844, 'learning_rate': 4.664848466096286e-06, 'epoch': 0.69}
{'loss': 0.8629, 'learning_rate': 4.658262270266548e-06, 'epoch': 0.69}
{'loss': 0.7408, 'learning_rate': 4.65167931514328e-06, 'epoch': 0.69}
{'loss': 0.8222, 'learning_rate': 4.645099604720209e-06, 'epoch': 0.69}
{'loss': 0.8116, 'learning_rate': 4.638523142989094e-06, 'epoch': 0.69}
{'loss': 0.7125, 'learning_rate': 4.6319499339397155e-06, 'epoch': 0.69}
{'loss': 0.7792, 'learning_rate': 4.625379981559885e-06, 'epoch': 0.69}
{'loss': 0.7276, 'learning_rate': 4.6188132898354345e-06, 'epoch': 0.69}
{'loss': 0.8117, 'learning_rate': 4.6122498627502276e-06, 'epoch': 0.69}
{'loss': 0.765, 'learning_rate': 4.6056897042861385e-06, 'epoch': 0.69}
{'loss': 0.8007, 'learning_rate': 4.599132818423056e-06, 'epoch': 0.69}
{'loss': 0.6778, 'learning_rate': 4.592579209138896e-06, 'epoch': 0.69}
{'loss': 0.8077, 'learning_rate': 4.586028880409575e-06, 'epoch': 0.69}
{'loss': 0.8217, 'learning_rate': 4.579481836209023e-06, 'epoch': 0.69}
{'loss': 0.8114, 'learning_rate': 4.572938080509175e-06, 'epoch': 0.69}
{'loss': 0.8056, 'learning_rate': 4.566397617279979e-06, 'epoch': 0.69}
{'loss': 0.8312, 'learning_rate': 4.55986045048938e-06, 'epoch': 0.69}
{'loss': 0.8098, 'learning_rate': 4.553326584103318e-06, 'epoch': 0.69}
{'loss': 0.7486, 'learning_rate': 4.546796022085736e-06, 'epoch': 0.69}
{'loss': 0.8101, 'learning_rate': 4.540268768398578e-06, 'epoch': 0.69}
{'loss': 0.8008, 'learning_rate': 4.533744827001768e-06, 'epoch': 0.69}
{'loss': 0.7972, 'learning_rate': 4.527224201853235e-06, 'epoch': 0.69}
{'loss': 0.6533, 'learning_rate': 4.520706896908882e-06, 'epoch': 0.69}
{'loss': 0.825, 'learning_rate': 4.514192916122611e-06, 'epoch': 0.69}
{'loss': 0.7617, 'learning_rate': 4.507682263446297e-06, 'epoch': 0.69}
{'loss': 0.8009, 'learning_rate': 4.501174942829799e-06, 'epoch': 0.69}
{'loss': 0.8315, 'learning_rate': 4.494670958220954e-06, 'epoch': 0.7}
{'loss': 0.6981, 'learning_rate': 4.48817031356558e-06, 'epoch': 0.7}
{'loss': 0.8196, 'learning_rate': 4.4816730128074635e-06, 'epoch': 0.7}
{'loss': 0.6938, 'learning_rate': 4.475179059888361e-06, 'epoch': 0.7}
{'loss': 0.7719, 'learning_rate': 4.468688458748006e-06, 'epoch': 0.7}
{'loss': 0.7552, 'learning_rate': 4.462201213324092e-06, 'epoch': 0.7}
{'loss': 0.8365, 'learning_rate': 4.455717327552276e-06, 'epoch': 0.7}
{'loss': 0.7892, 'learning_rate': 4.449236805366175e-06, 'epoch': 0.7}
{'loss': 0.8062, 'learning_rate': 4.442759650697379e-06, 'epoch': 0.7}
{'loss': 0.6736, 'learning_rate': 4.436285867475418e-06, 'epoch': 0.7}
{'loss': 0.7292, 'learning_rate': 4.429815459627784e-06, 'epoch': 0.7}
[2025-12-09 23:04:43,227] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step14500 is about to be saved!
[2025-12-09 23:04:43,680] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14500/global_step14500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 23:04:43,681] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14500/global_step14500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 23:04:43,833] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14500/global_step14500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 23:04:43,835] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14500/global_step14500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 23:05:59,560] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14500/global_step14500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 23:05:59,563] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-14500/global_step14500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 23:06:58,182] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step14500 is ready now!
{'loss': 0.7309, 'learning_rate': 4.4233484310799215e-06, 'epoch': 0.7}
{'loss': 0.7975, 'learning_rate': 4.41688478575523e-06, 'epoch': 0.7}
{'loss': 0.7872, 'learning_rate': 4.410424527575047e-06, 'epoch': 0.7}
{'loss': 0.6988, 'learning_rate': 4.403967660458657e-06, 'epoch': 0.7}
{'loss': 0.7733, 'learning_rate': 4.397514188323289e-06, 'epoch': 0.7}
{'loss': 0.809, 'learning_rate': 4.391064115084116e-06, 'epoch': 0.7}
{'loss': 0.8244, 'learning_rate': 4.3846174446542445e-06, 'epoch': 0.7}
{'loss': 0.5784, 'learning_rate': 4.378174180944714e-06, 'epoch': 0.7}
{'loss': 0.7486, 'learning_rate': 4.371734327864508e-06, 'epoch': 0.7}
{'loss': 0.7274, 'learning_rate': 4.365297889320528e-06, 'epoch': 0.7}
{'loss': 0.8164, 'learning_rate': 4.3588648692176115e-06, 'epoch': 0.7}
{'loss': 0.7239, 'learning_rate': 4.3524352714585165e-06, 'epoch': 0.7}
{'loss': 0.8587, 'learning_rate': 4.346009099943936e-06, 'epoch': 0.7}
{'loss': 0.7601, 'learning_rate': 4.339586358572472e-06, 'epoch': 0.7}
{'loss': 0.7784, 'learning_rate': 4.333167051240652e-06, 'epoch': 0.7}
{'loss': 0.7124, 'learning_rate': 4.3267511818429135e-06, 'epoch': 0.7}
{'loss': 0.665, 'learning_rate': 4.320338754271618e-06, 'epoch': 0.7}
{'loss': 0.7222, 'learning_rate': 4.313929772417038e-06, 'epoch': 0.7}
{'loss': 0.8412, 'learning_rate': 4.307524240167348e-06, 'epoch': 0.7}
{'loss': 0.6236, 'learning_rate': 4.3011221614086295e-06, 'epoch': 0.7}
{'loss': 0.6919, 'learning_rate': 4.294723540024881e-06, 'epoch': 0.7}
{'loss': 0.7067, 'learning_rate': 4.288328379897991e-06, 'epoch': 0.7}
{'loss': 0.7796, 'learning_rate': 4.281936684907753e-06, 'epoch': 0.7}
{'loss': 0.7977, 'learning_rate': 4.275548458931853e-06, 'epoch': 0.7}
{'loss': 0.7862, 'learning_rate': 4.269163705845886e-06, 'epoch': 0.7}
{'loss': 0.6861, 'learning_rate': 4.262782429523328e-06, 'epoch': 0.7}
{'loss': 0.7442, 'learning_rate': 4.2564046338355436e-06, 'epoch': 0.7}
{'loss': 0.7401, 'learning_rate': 4.250030322651799e-06, 'epoch': 0.7}
{'loss': 0.7758, 'learning_rate': 4.243659499839236e-06, 'epoch': 0.7}
{'loss': 0.781, 'learning_rate': 4.2372921692628825e-06, 'epoch': 0.7}
{'loss': 0.8264, 'learning_rate': 4.230928334785644e-06, 'epoch': 0.7}
{'loss': 0.7701, 'learning_rate': 4.2245680002683165e-06, 'epoch': 0.71}
{'loss': 0.8098, 'learning_rate': 4.218211169569562e-06, 'epoch': 0.71}
{'loss': 0.7609, 'learning_rate': 4.211857846545914e-06, 'epoch': 0.71}
{'loss': 0.7658, 'learning_rate': 4.20550803505179e-06, 'epoch': 0.71}
{'loss': 0.8578, 'learning_rate': 4.199161738939474e-06, 'epoch': 0.71}
{'loss': 0.6867, 'learning_rate': 4.192818962059112e-06, 'epoch': 0.71}
{'loss': 0.7858, 'learning_rate': 4.186479708258716e-06, 'epoch': 0.71}
{'loss': 0.6518, 'learning_rate': 4.180143981384157e-06, 'epoch': 0.71}
{'loss': 0.7818, 'learning_rate': 4.173811785279182e-06, 'epoch': 0.71}
{'loss': 0.7849, 'learning_rate': 4.167483123785378e-06, 'epoch': 0.71}
{'loss': 0.7982, 'learning_rate': 4.161158000742197e-06, 'epoch': 0.71}
{'loss': 0.7027, 'learning_rate': 4.154836419986939e-06, 'epoch': 0.71}
WARNING: tokenization mismatch: 1 vs. 64. (ignored)
{'loss': 0.7639, 'learning_rate': 4.148518385354763e-06, 'epoch': 0.71}
{'loss': 0.7072, 'learning_rate': 4.14220390067867e-06, 'epoch': 0.71}
{'loss': 0.7207, 'learning_rate': 4.135892969789506e-06, 'epoch': 0.71}
{'loss': 0.7442, 'learning_rate': 4.129585596515969e-06, 'epoch': 0.71}
{'loss': 0.7348, 'learning_rate': 4.123281784684593e-06, 'epoch': 0.71}
{'loss': 0.7937, 'learning_rate': 4.116981538119751e-06, 'epoch': 0.71}
{'loss': 0.7765, 'learning_rate': 4.11068486064365e-06, 'epoch': 0.71}
{'loss': 0.7937, 'learning_rate': 4.10439175607634e-06, 'epoch': 0.71}
{'loss': 0.7142, 'learning_rate': 4.0981022282357045e-06, 'epoch': 0.71}
{'loss': 0.7836, 'learning_rate': 4.091816280937445e-06, 'epoch': 0.71}
{'loss': 0.8109, 'learning_rate': 4.085533917995097e-06, 'epoch': 0.71}
{'loss': 0.7453, 'learning_rate': 4.079255143220027e-06, 'epoch': 0.71}
{'loss': 0.8322, 'learning_rate': 4.072979960421418e-06, 'epoch': 0.71}
{'loss': 0.7887, 'learning_rate': 4.066708373406275e-06, 'epoch': 0.71}
{'loss': 0.7629, 'learning_rate': 4.0604403859794195e-06, 'epoch': 0.71}
{'loss': 0.7815, 'learning_rate': 4.054176001943497e-06, 'epoch': 0.71}
{'loss': 0.7463, 'learning_rate': 4.047915225098959e-06, 'epoch': 0.71}
{'loss': 0.797, 'learning_rate': 4.041658059244069e-06, 'epoch': 0.71}
{'loss': 0.772, 'learning_rate': 4.035404508174908e-06, 'epoch': 0.71}
{'loss': 0.8201, 'learning_rate': 4.029154575685354e-06, 'epoch': 0.71}
{'loss': 0.8326, 'learning_rate': 4.022908265567097e-06, 'epoch': 0.71}
{'loss': 0.7764, 'learning_rate': 4.016665581609619e-06, 'epoch': 0.71}
{'loss': 0.7886, 'learning_rate': 4.010426527600218e-06, 'epoch': 0.71}
{'loss': 0.791, 'learning_rate': 4.004191107323974e-06, 'epoch': 0.71}
{'loss': 0.7136, 'learning_rate': 3.997959324563776e-06, 'epoch': 0.71}
{'loss': 0.848, 'learning_rate': 3.991731183100293e-06, 'epoch': 0.71}
{'loss': 0.7878, 'learning_rate': 3.985506686712001e-06, 'epoch': 0.71}
{'loss': 0.776, 'learning_rate': 3.979285839175149e-06, 'epoch': 0.71}
{'loss': 0.8594, 'learning_rate': 3.97306864426378e-06, 'epoch': 0.71}
{'loss': 0.7169, 'learning_rate': 3.966855105749716e-06, 'epoch': 0.71}
{'loss': 0.809, 'learning_rate': 3.960645227402571e-06, 'epoch': 0.72}
{'loss': 0.7266, 'learning_rate': 3.9544390129897295e-06, 'epoch': 0.72}
{'loss': 0.7816, 'learning_rate': 3.948236466276354e-06, 'epoch': 0.72}
{'loss': 0.7505, 'learning_rate': 3.9420375910253816e-06, 'epoch': 0.72}
{'loss': 0.7252, 'learning_rate': 3.93584239099753e-06, 'epoch': 0.72}
{'loss': 0.718, 'learning_rate': 3.929650869951278e-06, 'epoch': 0.72}
{'loss': 0.7656, 'learning_rate': 3.923463031642873e-06, 'epoch': 0.72}
{'loss': 0.7636, 'learning_rate': 3.917278879826335e-06, 'epoch': 0.72}
{'loss': 0.7132, 'learning_rate': 3.911098418253443e-06, 'epoch': 0.72}
{'loss': 0.7669, 'learning_rate': 3.904921650673735e-06, 'epoch': 0.72}
{'loss': 0.7701, 'learning_rate': 3.898748580834508e-06, 'epoch': 0.72}
{'loss': 0.74, 'learning_rate': 3.892579212480823e-06, 'epoch': 0.72}
{'loss': 0.8392, 'learning_rate': 3.886413549355491e-06, 'epoch': 0.72}
{'loss': 0.6894, 'learning_rate': 3.880251595199074e-06, 'epoch': 0.72}
{'loss': 0.6872, 'learning_rate': 3.874093353749878e-06, 'epoch': 0.72}
{'loss': 0.6427, 'learning_rate': 3.867938828743973e-06, 'epoch': 0.72}
{'loss': 0.7612, 'learning_rate': 3.861788023915159e-06, 'epoch': 0.72}
{'loss': 0.79, 'learning_rate': 3.855640942994985e-06, 'epoch': 0.72}
{'loss': 0.8321, 'learning_rate': 3.8494975897127365e-06, 'epoch': 0.72}
{'loss': 0.8123, 'learning_rate': 3.843357967795448e-06, 'epoch': 0.72}
{'loss': 0.7598, 'learning_rate': 3.837222080967882e-06, 'epoch': 0.72}
{'loss': 0.8363, 'learning_rate': 3.83108993295253e-06, 'epoch': 0.72}
{'loss': 0.7515, 'learning_rate': 3.82496152746963e-06, 'epoch': 0.72}
{'loss': 0.792, 'learning_rate': 3.818836868237139e-06, 'epoch': 0.72}
{'loss': 0.7911, 'learning_rate': 3.8127159589707417e-06, 'epoch': 0.72}
{'loss': 0.8229, 'learning_rate': 3.8065988033838475e-06, 'epoch': 0.72}
{'loss': 0.804, 'learning_rate': 3.800485405187594e-06, 'epoch': 0.72}
[2025-12-09 23:31:48,279] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step15000 is about to be saved!
[2025-12-09 23:31:48,310] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15000/global_step15000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 23:31:48,310] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15000/global_step15000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 23:31:48,468] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15000/global_step15000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 23:31:48,472] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15000/global_step15000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 23:32:28,110] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15000/global_step15000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 23:32:28,113] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15000/global_step15000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 23:32:28,986] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step15000 is ready now!
{'loss': 0.8242, 'learning_rate': 3.7943757680908377e-06, 'epoch': 0.72}
{'loss': 0.7711, 'learning_rate': 3.788269895800151e-06, 'epoch': 0.72}
{'loss': 0.7908, 'learning_rate': 3.7821677920198164e-06, 'epoch': 0.72}
{'loss': 0.7954, 'learning_rate': 3.7760694604518445e-06, 'epoch': 0.72}
{'loss': 0.7288, 'learning_rate': 3.7699749047959466e-06, 'epoch': 0.72}
{'loss': 0.7623, 'learning_rate': 3.7638841287495455e-06, 'epoch': 0.72}
{'loss': 0.7471, 'learning_rate': 3.757797136007768e-06, 'epoch': 0.72}
{'loss': 0.7915, 'learning_rate': 3.7517139302634564e-06, 'epoch': 0.72}
{'loss': 0.8266, 'learning_rate': 3.745634515207146e-06, 'epoch': 0.72}
{'loss': 0.7944, 'learning_rate': 3.739558894527072e-06, 'epoch': 0.72}
{'loss': 0.7492, 'learning_rate': 3.7334870719091697e-06, 'epoch': 0.72}
{'loss': 0.7615, 'learning_rate': 3.7274190510370766e-06, 'epoch': 0.72}
{'loss': 0.7026, 'learning_rate': 3.721354835592115e-06, 'epoch': 0.72}
{'loss': 0.7452, 'learning_rate': 3.7152944292532966e-06, 'epoch': 0.72}
{'loss': 0.7955, 'learning_rate': 3.7092378356973357e-06, 'epoch': 0.73}
{'loss': 0.763, 'learning_rate': 3.7031850585986217e-06, 'epoch': 0.73}
{'loss': 0.7791, 'learning_rate': 3.6971361016292274e-06, 'epoch': 0.73}
{'loss': 0.8102, 'learning_rate': 3.6910909684589203e-06, 'epoch': 0.73}
{'loss': 0.8247, 'learning_rate': 3.6850496627551322e-06, 'epoch': 0.73}
{'loss': 0.8149, 'learning_rate': 3.67901218818299e-06, 'epoch': 0.73}
{'loss': 0.7539, 'learning_rate': 3.6729785484052815e-06, 'epoch': 0.73}
{'loss': 0.7452, 'learning_rate': 3.6669487470824717e-06, 'epoch': 0.73}
{'loss': 0.6968, 'learning_rate': 3.6609227878727062e-06, 'epoch': 0.73}
{'loss': 0.6906, 'learning_rate': 3.6549006744317882e-06, 'epoch': 0.73}
{'loss': 0.694, 'learning_rate': 3.6488824104131927e-06, 'epoch': 0.73}
{'loss': 0.6156, 'learning_rate': 3.642867999468055e-06, 'epoch': 0.73}
{'loss': 0.8044, 'learning_rate': 3.6368574452451834e-06, 'epoch': 0.73}
{'loss': 0.8211, 'learning_rate': 3.630850751391036e-06, 'epoch': 0.73}
{'loss': 0.8064, 'learning_rate': 3.62484792154973e-06, 'epoch': 0.73}
{'loss': 0.7421, 'learning_rate': 3.618848959363046e-06, 'epoch': 0.73}
{'loss': 0.665, 'learning_rate': 3.6128538684704117e-06, 'epoch': 0.73}
{'loss': 0.7298, 'learning_rate': 3.606862652508907e-06, 'epoch': 0.73}
{'loss': 0.7594, 'learning_rate': 3.600875315113257e-06, 'epoch': 0.73}
{'loss': 0.7299, 'learning_rate': 3.5948918599158432e-06, 'epoch': 0.73}
{'loss': 0.7908, 'learning_rate': 3.588912290546689e-06, 'epoch': 0.73}
{'loss': 0.8288, 'learning_rate': 3.582936610633455e-06, 'epoch': 0.73}
{'loss': 0.8169, 'learning_rate': 3.5769648238014433e-06, 'epoch': 0.73}
{'loss': 0.805, 'learning_rate': 3.5709969336736017e-06, 'epoch': 0.73}
{'loss': 0.81, 'learning_rate': 3.5650329438705067e-06, 'epoch': 0.73}
{'loss': 0.7947, 'learning_rate': 3.5590728580103685e-06, 'epoch': 0.73}
{'loss': 0.7136, 'learning_rate': 3.553116679709029e-06, 'epoch': 0.73}
{'loss': 0.8086, 'learning_rate': 3.5471644125799675e-06, 'epoch': 0.73}
{'loss': 0.7992, 'learning_rate': 3.5412160602342816e-06, 'epoch': 0.73}
{'loss': 0.7177, 'learning_rate': 3.5352716262806953e-06, 'epoch': 0.73}
{'loss': 0.7621, 'learning_rate': 3.529331114325555e-06, 'epoch': 0.73}
{'loss': 0.7478, 'learning_rate': 3.523394527972833e-06, 'epoch': 0.73}
{'loss': 0.7932, 'learning_rate': 3.517461870824117e-06, 'epoch': 0.73}
{'loss': 0.7669, 'learning_rate': 3.5115331464786053e-06, 'epoch': 0.73}
{'loss': 0.7857, 'learning_rate': 3.5056083585331204e-06, 'epoch': 0.73}
{'loss': 0.806, 'learning_rate': 3.499687510582087e-06, 'epoch': 0.73}
{'loss': 0.7836, 'learning_rate': 3.4937706062175513e-06, 'epoch': 0.73}
{'loss': 0.7979, 'learning_rate': 3.4878576490291537e-06, 'epoch': 0.73}
{'loss': 0.7429, 'learning_rate': 3.481948642604146e-06, 'epoch': 0.73}
{'loss': 0.6598, 'learning_rate': 3.476043590527387e-06, 'epoch': 0.73}
{'loss': 0.7747, 'learning_rate': 3.4701424963813313e-06, 'epoch': 0.73}
{'loss': 0.8094, 'learning_rate': 3.4642453637460295e-06, 'epoch': 0.73}
{'loss': 0.6428, 'learning_rate': 3.458352196199141e-06, 'epoch': 0.74}
{'loss': 0.8062, 'learning_rate': 3.4524629973159063e-06, 'epoch': 0.74}
{'loss': 0.8004, 'learning_rate': 3.446577770669165e-06, 'epoch': 0.74}
{'loss': 0.8457, 'learning_rate': 3.4406965198293428e-06, 'epoch': 0.74}
{'loss': 0.846, 'learning_rate': 3.4348192483644614e-06, 'epoch': 0.74}
{'loss': 0.7893, 'learning_rate': 3.4289459598401197e-06, 'epoch': 0.74}
{'loss': 0.7538, 'learning_rate': 3.4230766578195016e-06, 'epoch': 0.74}
{'loss': 0.7245, 'learning_rate': 3.4172113458633803e-06, 'epoch': 0.74}
{'loss': 0.6918, 'learning_rate': 3.411350027530098e-06, 'epoch': 0.74}
{'loss': 0.8012, 'learning_rate': 3.4054927063755793e-06, 'epoch': 0.74}
{'loss': 0.6776, 'learning_rate': 3.3996393859533204e-06, 'epoch': 0.74}
{'loss': 0.7591, 'learning_rate': 3.3937900698143967e-06, 'epoch': 0.74}
{'loss': 0.6728, 'learning_rate': 3.3879447615074514e-06, 'epoch': 0.74}
{'loss': 0.8265, 'learning_rate': 3.3821034645786934e-06, 'epoch': 0.74}
{'loss': 0.7154, 'learning_rate': 3.376266182571897e-06, 'epoch': 0.74}
{'loss': 0.8072, 'learning_rate': 3.3704329190284104e-06, 'epoch': 0.74}
{'loss': 0.8303, 'learning_rate': 3.3646036774871338e-06, 'epoch': 0.74}
{'loss': 0.7895, 'learning_rate': 3.35877846148453e-06, 'epoch': 0.74}
{'loss': 0.7282, 'learning_rate': 3.352957274554618e-06, 'epoch': 0.74}
{'loss': 0.7349, 'learning_rate': 3.34714012022898e-06, 'epoch': 0.74}
{'loss': 0.8341, 'learning_rate': 3.341327002036745e-06, 'epoch': 0.74}
{'loss': 0.7945, 'learning_rate': 3.3355179235045944e-06, 'epoch': 0.74}
{'loss': 0.7631, 'learning_rate': 3.329712888156755e-06, 'epoch': 0.74}
{'loss': 0.8053, 'learning_rate': 3.323911899515013e-06, 'epoch': 0.74}
{'loss': 0.7343, 'learning_rate': 3.3181149610986874e-06, 'epoch': 0.74}
{'loss': 0.74, 'learning_rate': 3.312322076424641e-06, 'epoch': 0.74}
{'loss': 0.6926, 'learning_rate': 3.3065332490072877e-06, 'epoch': 0.74}
{'loss': 0.8015, 'learning_rate': 3.3007484823585655e-06, 'epoch': 0.74}
{'loss': 0.838, 'learning_rate': 3.294967779987963e-06, 'epoch': 0.74}
{'loss': 0.8627, 'learning_rate': 3.289191145402493e-06, 'epoch': 0.74}
{'loss': 0.8193, 'learning_rate': 3.2834185821067e-06, 'epoch': 0.74}
{'loss': 0.7579, 'learning_rate': 3.277650093602668e-06, 'epoch': 0.74}
{'loss': 0.7935, 'learning_rate': 3.2718856833900013e-06, 'epoch': 0.74}
{'loss': 0.8279, 'learning_rate': 3.266125354965829e-06, 'epoch': 0.74}
{'loss': 0.7997, 'learning_rate': 3.2603691118248115e-06, 'epoch': 0.74}
{'loss': 0.8074, 'learning_rate': 3.2546169574591233e-06, 'epoch': 0.74}
{'loss': 0.6824, 'learning_rate': 3.2488688953584612e-06, 'epoch': 0.74}
{'loss': 0.8068, 'learning_rate': 3.2431249290100365e-06, 'epoch': 0.74}
{'loss': 0.8047, 'learning_rate': 3.2373850618985826e-06, 'epoch': 0.74}
{'loss': 0.8002, 'learning_rate': 3.2316492975063407e-06, 'epoch': 0.74}
{'loss': 0.6399, 'learning_rate': 3.2259176393130596e-06, 'epoch': 0.74}
{'loss': 0.6967, 'learning_rate': 3.220190090796008e-06, 'epoch': 0.75}
{'loss': 0.7945, 'learning_rate': 3.214466655429952e-06, 'epoch': 0.75}
{'loss': 0.7675, 'learning_rate': 3.2087473366871615e-06, 'epoch': 0.75}
[2025-12-09 23:57:33,027] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step15500 is about to be saved!
[2025-12-09 23:57:33,116] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15500/global_step15500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-09 23:57:33,117] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15500/global_step15500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-09 23:57:33,727] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15500/global_step15500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-09 23:57:33,736] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15500/global_step15500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-09 23:58:28,238] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15500/global_step15500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-09 23:58:28,241] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-15500/global_step15500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-09 23:58:28,254] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step15500 is ready now!
{'loss': 0.779, 'learning_rate': 3.2030321380374185e-06, 'epoch': 0.75}
{'loss': 0.819, 'learning_rate': 3.1973210629479936e-06, 'epoch': 0.75}
{'loss': 0.8232, 'learning_rate': 3.1916141148836678e-06, 'epoch': 0.75}
{'loss': 0.7795, 'learning_rate': 3.1859112973067086e-06, 'epoch': 0.75}
{'loss': 0.8022, 'learning_rate': 3.1802126136768776e-06, 'epoch': 0.75}
{'loss': 0.6227, 'learning_rate': 3.1745180674514388e-06, 'epoch': 0.75}
{'loss': 0.648, 'learning_rate': 3.1688276620851368e-06, 'epoch': 0.75}
{'loss': 0.6556, 'learning_rate': 3.163141401030205e-06, 'epoch': 0.75}
{'loss': 0.7194, 'learning_rate': 3.157459287736362e-06, 'epoch': 0.75}
{'loss': 0.7325, 'learning_rate': 3.1517813256508177e-06, 'epoch': 0.75}
{'loss': 0.727, 'learning_rate': 3.1461075182182565e-06, 'epoch': 0.75}
{'loss': 0.7833, 'learning_rate': 3.140437868880841e-06, 'epoch': 0.75}
{'loss': 0.7654, 'learning_rate': 3.134772381078214e-06, 'epoch': 0.75}
{'loss': 0.6908, 'learning_rate': 3.129111058247497e-06, 'epoch': 0.75}
{'loss': 0.7346, 'learning_rate': 3.123453903823279e-06, 'epoch': 0.75}
{'loss': 0.7165, 'learning_rate': 3.1178009212376193e-06, 'epoch': 0.75}
{'loss': 0.8552, 'learning_rate': 3.112152113920053e-06, 'epoch': 0.75}
{'loss': 0.6583, 'learning_rate': 3.1065074852975806e-06, 'epoch': 0.75}
{'loss': 0.7661, 'learning_rate': 3.1008670387946625e-06, 'epoch': 0.75}
{'loss': 0.7107, 'learning_rate': 3.0952307778332256e-06, 'epoch': 0.75}
{'loss': 0.7609, 'learning_rate': 3.0895987058326528e-06, 'epoch': 0.75}
{'loss': 0.7575, 'learning_rate': 3.0839708262097955e-06, 'epoch': 0.75}
{'loss': 0.7246, 'learning_rate': 3.0783471423789536e-06, 'epoch': 0.75}
{'loss': 0.8127, 'learning_rate': 3.0727276577518795e-06, 'epoch': 0.75}
{'loss': 0.7683, 'learning_rate': 3.0671123757377898e-06, 'epoch': 0.75}
{'loss': 0.6676, 'learning_rate': 3.061501299743338e-06, 'epoch': 0.75}
{'loss': 0.7946, 'learning_rate': 3.055894433172635e-06, 'epoch': 0.75}
{'loss': 0.7296, 'learning_rate': 3.050291779427229e-06, 'epoch': 0.75}
{'loss': 0.7504, 'learning_rate': 3.0446933419061263e-06, 'epoch': 0.75}
{'loss': 0.7173, 'learning_rate': 3.039099124005762e-06, 'epoch': 0.75}
{'loss': 0.7964, 'learning_rate': 3.0335091291200193e-06, 'epoch': 0.75}
{'loss': 0.7796, 'learning_rate': 3.0279233606402094e-06, 'epoch': 0.75}
{'loss': 0.7725, 'learning_rate': 3.022341821955096e-06, 'epoch': 0.75}
{'loss': 0.8424, 'learning_rate': 3.0167645164508584e-06, 'epoch': 0.75}
{'loss': 0.7769, 'learning_rate': 3.0111914475111247e-06, 'epoch': 0.75}
{'loss': 0.8005, 'learning_rate': 3.005622618516938e-06, 'epoch': 0.75}
{'loss': 0.739, 'learning_rate': 3.000058032846782e-06, 'epoch': 0.75}
{'loss': 0.7951, 'learning_rate': 2.9944976938765557e-06, 'epoch': 0.75}
{'loss': 0.8051, 'learning_rate': 2.9889416049795826e-06, 'epoch': 0.75}
{'loss': 0.7814, 'learning_rate': 2.983389769526619e-06, 'epoch': 0.76}
{'loss': 0.823, 'learning_rate': 2.9778421908858267e-06, 'epoch': 0.76}
{'loss': 0.8244, 'learning_rate': 2.972298872422794e-06, 'epoch': 0.76}
{'loss': 0.6449, 'learning_rate': 2.9667598175005176e-06, 'epoch': 0.76}
{'loss': 0.8489, 'learning_rate': 2.9612250294794166e-06, 'epoch': 0.76}
{'loss': 0.7381, 'learning_rate': 2.9556945117173154e-06, 'epoch': 0.76}
{'loss': 0.7792, 'learning_rate': 2.9501682675694466e-06, 'epoch': 0.76}
{'loss': 0.6649, 'learning_rate': 2.944646300388452e-06, 'epoch': 0.76}
{'loss': 0.7938, 'learning_rate': 2.9391286135243823e-06, 'epoch': 0.76}
{'loss': 0.795, 'learning_rate': 2.9336152103246873e-06, 'epoch': 0.76}
{'loss': 0.7526, 'learning_rate': 2.9281060941342143e-06, 'epoch': 0.76}
{'loss': 0.6858, 'learning_rate': 2.9226012682952186e-06, 'epoch': 0.76}
{'loss': 0.663, 'learning_rate': 2.9171007361473512e-06, 'epoch': 0.76}
{'loss': 0.8177, 'learning_rate': 2.911604501027653e-06, 'epoch': 0.76}
{'loss': 0.6939, 'learning_rate': 2.906112566270558e-06, 'epoch': 0.76}
{'loss': 0.6339, 'learning_rate': 2.900624935207893e-06, 'epoch': 0.76}
{'loss': 0.6274, 'learning_rate': 2.89514161116888e-06, 'epoch': 0.76}
{'loss': 0.7656, 'learning_rate': 2.8896625974801184e-06, 'epoch': 0.76}
{'loss': 0.7508, 'learning_rate': 2.8841878974655957e-06, 'epoch': 0.76}
{'loss': 0.7417, 'learning_rate': 2.8787175144466873e-06, 'epoch': 0.76}
{'loss': 0.7815, 'learning_rate': 2.873251451742145e-06, 'epoch': 0.76}
{'loss': 0.7417, 'learning_rate': 2.8677897126680988e-06, 'epoch': 0.76}
{'loss': 0.8045, 'learning_rate': 2.862332300538053e-06, 'epoch': 0.76}
{'loss': 0.7753, 'learning_rate': 2.8568792186629e-06, 'epoch': 0.76}
{'loss': 0.8083, 'learning_rate': 2.851430470350892e-06, 'epoch': 0.76}
{'loss': 0.7882, 'learning_rate': 2.845986058907655e-06, 'epoch': 0.76}
{'loss': 0.7536, 'learning_rate': 2.8405459876361842e-06, 'epoch': 0.76}
{'loss': 0.8231, 'learning_rate': 2.8351102598368442e-06, 'epoch': 0.76}
{'loss': 0.7072, 'learning_rate': 2.829678878807366e-06, 'epoch': 0.76}
{'loss': 0.614, 'learning_rate': 2.824251847842838e-06, 'epoch': 0.76}
{'loss': 0.6413, 'learning_rate': 2.8188291702357095e-06, 'epoch': 0.76}
{'loss': 0.7681, 'learning_rate': 2.813410849275797e-06, 'epoch': 0.76}
{'loss': 0.7843, 'learning_rate': 2.807996888250265e-06, 'epoch': 0.76}
{'loss': 0.799, 'learning_rate': 2.802587290443637e-06, 'epoch': 0.76}
{'loss': 0.7412, 'learning_rate': 2.7971820591377842e-06, 'epoch': 0.76}
{'loss': 0.7378, 'learning_rate': 2.791781197611939e-06, 'epoch': 0.76}
{'loss': 0.6558, 'learning_rate': 2.7863847091426755e-06, 'epoch': 0.76}
{'loss': 0.7935, 'learning_rate': 2.780992597003913e-06, 'epoch': 0.76}
{'loss': 0.8006, 'learning_rate': 2.775604864466923e-06, 'epoch': 0.76}
{'loss': 0.8179, 'learning_rate': 2.7702215148003153e-06, 'epoch': 0.76}
{'loss': 0.7998, 'learning_rate': 2.7648425512700393e-06, 'epoch': 0.76}
{'loss': 0.711, 'learning_rate': 2.759467977139384e-06, 'epoch': 0.76}
{'loss': 0.7795, 'learning_rate': 2.7540977956689817e-06, 'epoch': 0.77}
{'loss': 0.7963, 'learning_rate': 2.7487320101167935e-06, 'epoch': 0.77}
{'loss': 0.6873, 'learning_rate': 2.743370623738112e-06, 'epoch': 0.77}
{'loss': 0.7743, 'learning_rate': 2.738013639785565e-06, 'epoch': 0.77}
{'loss': 0.6923, 'learning_rate': 2.732661061509113e-06, 'epoch': 0.77}
{'loss': 0.8123, 'learning_rate': 2.7273128921560365e-06, 'epoch': 0.77}
{'loss': 0.601, 'learning_rate': 2.7219691349709433e-06, 'epoch': 0.77}
{'loss': 0.7611, 'learning_rate': 2.7166297931957632e-06, 'epoch': 0.77}
{'loss': 0.7649, 'learning_rate': 2.7112948700697528e-06, 'epoch': 0.77}
{'loss': 0.833, 'learning_rate': 2.7059643688294824e-06, 'epoch': 0.77}
{'loss': 0.7555, 'learning_rate': 2.700638292708839e-06, 'epoch': 0.77}
{'loss': 0.6878, 'learning_rate': 2.6953166449390344e-06, 'epoch': 0.77}
{'loss': 0.7812, 'learning_rate': 2.689999428748582e-06, 'epoch': 0.77}
{'loss': 0.6068, 'learning_rate': 2.6846866473633126e-06, 'epoch': 0.77}
{'loss': 0.7503, 'learning_rate': 2.6793783040063627e-06, 'epoch': 0.77}
{'loss': 0.7803, 'learning_rate': 2.6740744018981846e-06, 'epoch': 0.77}
{'loss': 0.7441, 'learning_rate': 2.668774944256528e-06, 'epoch': 0.77}
{'loss': 0.6294, 'learning_rate': 2.663479934296449e-06, 'epoch': 0.77}
{'loss': 0.7089, 'learning_rate': 2.6581893752303e-06, 'epoch': 0.77}
[2025-12-10 00:24:11,340] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step16000 is about to be saved!
[2025-12-10 00:24:11,371] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16000/global_step16000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-10 00:24:11,371] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16000/global_step16000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-10 00:24:11,531] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16000/global_step16000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-10 00:24:11,536] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16000/global_step16000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-10 00:24:56,154] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16000/global_step16000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-10 00:24:56,169] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16000/global_step16000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-10 00:24:56,218] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step16000 is ready now!
{'loss': 0.7087, 'learning_rate': 2.6529032702677503e-06, 'epoch': 0.77}
{'loss': 0.7866, 'learning_rate': 2.647621622615749e-06, 'epoch': 0.77}
{'loss': 0.8263, 'learning_rate': 2.642344435478548e-06, 'epoch': 0.77}
{'loss': 0.7555, 'learning_rate': 2.6370717120576885e-06, 'epoch': 0.77}
{'loss': 0.7701, 'learning_rate': 2.6318034555520134e-06, 'epoch': 0.77}
{'loss': 0.7918, 'learning_rate': 2.6265396691576485e-06, 'epoch': 0.77}
{'loss': 0.7362, 'learning_rate': 2.621280356068008e-06, 'epoch': 0.77}
{'loss': 0.6273, 'learning_rate': 2.6160255194737895e-06, 'epoch': 0.77}
{'loss': 0.7996, 'learning_rate': 2.6107751625629863e-06, 'epoch': 0.77}
{'loss': 0.7994, 'learning_rate': 2.6055292885208615e-06, 'epoch': 0.77}
{'loss': 0.814, 'learning_rate': 2.600287900529962e-06, 'epoch': 0.77}
{'loss': 0.7041, 'learning_rate': 2.5950510017701194e-06, 'epoch': 0.77}
{'loss': 0.7507, 'learning_rate': 2.5898185954184342e-06, 'epoch': 0.77}
{'loss': 0.7592, 'learning_rate': 2.584590684649284e-06, 'epoch': 0.77}
{'loss': 0.7974, 'learning_rate': 2.579367272634317e-06, 'epoch': 0.77}
{'loss': 0.7042, 'learning_rate': 2.574148362542458e-06, 'epoch': 0.77}
{'loss': 0.7707, 'learning_rate': 2.568933957539893e-06, 'epoch': 0.77}
{'loss': 0.7505, 'learning_rate': 2.5637240607900837e-06, 'epoch': 0.77}
{'loss': 0.8025, 'learning_rate': 2.558518675453746e-06, 'epoch': 0.77}
{'loss': 0.7855, 'learning_rate': 2.553317804688872e-06, 'epoch': 0.77}
{'loss': 0.7636, 'learning_rate': 2.5481214516507015e-06, 'epoch': 0.77}
{'loss': 0.7423, 'learning_rate': 2.542929619491742e-06, 'epoch': 0.77}
{'loss': 0.7187, 'learning_rate': 2.537742311361752e-06, 'epoch': 0.78}
{'loss': 0.7673, 'learning_rate': 2.5325595304077532e-06, 'epoch': 0.78}
{'loss': 0.8621, 'learning_rate': 2.527381279774017e-06, 'epoch': 0.78}
{'loss': 0.759, 'learning_rate': 2.5222075626020624e-06, 'epoch': 0.78}
{'loss': 0.6501, 'learning_rate': 2.5170383820306667e-06, 'epoch': 0.78}
{'loss': 0.7379, 'learning_rate': 2.511873741195847e-06, 'epoch': 0.78}
{'loss': 0.6596, 'learning_rate': 2.506713643230869e-06, 'epoch': 0.78}
{'loss': 0.7923, 'learning_rate': 2.501558091266242e-06, 'epoch': 0.78}
{'loss': 0.8036, 'learning_rate': 2.496407088429721e-06, 'epoch': 0.78}
{'loss': 0.7724, 'learning_rate': 2.491260637846297e-06, 'epoch': 0.78}
{'loss': 0.7559, 'learning_rate': 2.4861187426381993e-06, 'epoch': 0.78}
{'loss': 0.7268, 'learning_rate': 2.4809814059248882e-06, 'epoch': 0.78}
{'loss': 0.7552, 'learning_rate': 2.475848630823079e-06, 'epoch': 0.78}
{'loss': 0.687, 'learning_rate': 2.470720420446697e-06, 'epoch': 0.78}
{'loss': 0.797, 'learning_rate': 2.465596777906909e-06, 'epoch': 0.78}
{'loss': 0.779, 'learning_rate': 2.460477706312103e-06, 'epoch': 0.78}
{'loss': 0.8378, 'learning_rate': 2.455363208767908e-06, 'epoch': 0.78}
{'loss': 0.6723, 'learning_rate': 2.450253288377162e-06, 'epoch': 0.78}
{'loss': 0.8049, 'learning_rate': 2.4451479482399377e-06, 'epoch': 0.78}
{'loss': 0.7346, 'learning_rate': 2.4400471914535193e-06, 'epoch': 0.78}
{'loss': 0.7692, 'learning_rate': 2.434951021112423e-06, 'epoch': 0.78}
{'loss': 0.7387, 'learning_rate': 2.4298594403083696e-06, 'epoch': 0.78}
{'loss': 0.8548, 'learning_rate': 2.4247724521303017e-06, 'epoch': 0.78}
{'loss': 0.8553, 'learning_rate': 2.4196900596643804e-06, 'epoch': 0.78}
{'loss': 0.7379, 'learning_rate': 2.4146122659939687e-06, 'epoch': 0.78}
{'loss': 0.6909, 'learning_rate': 2.409539074199646e-06, 'epoch': 0.78}
{'loss': 0.7798, 'learning_rate': 2.4044704873591964e-06, 'epoch': 0.78}
{'loss': 0.8326, 'learning_rate': 2.3994065085476125e-06, 'epoch': 0.78}
{'loss': 0.825, 'learning_rate': 2.3943471408370943e-06, 'epoch': 0.78}
{'loss': 0.8173, 'learning_rate': 2.3892923872970406e-06, 'epoch': 0.78}
{'loss': 0.8656, 'learning_rate': 2.3842422509940454e-06, 'epoch': 0.78}
{'loss': 0.7209, 'learning_rate': 2.3791967349919152e-06, 'epoch': 0.78}
{'loss': 0.6714, 'learning_rate': 2.374155842351643e-06, 'epoch': 0.78}
{'loss': 0.7854, 'learning_rate': 2.3691195761314178e-06, 'epoch': 0.78}
{'loss': 0.7558, 'learning_rate': 2.364087939386622e-06, 'epoch': 0.78}
{'loss': 0.8243, 'learning_rate': 2.3590609351698367e-06, 'epoch': 0.78}
{'loss': 0.8005, 'learning_rate': 2.354038566530825e-06, 'epoch': 0.78}
{'loss': 0.7993, 'learning_rate': 2.3490208365165356e-06, 'epoch': 0.78}
{'loss': 0.8237, 'learning_rate': 2.344007748171113e-06, 'epoch': 0.78}
{'loss': 0.7721, 'learning_rate': 2.338999304535877e-06, 'epoch': 0.78}
{'loss': 0.8376, 'learning_rate': 2.3339955086493327e-06, 'epoch': 0.78}
{'loss': 0.8061, 'learning_rate': 2.3289963635471622e-06, 'epoch': 0.78}
{'loss': 0.7325, 'learning_rate': 2.3240018722622347e-06, 'epoch': 0.79}
{'loss': 0.7893, 'learning_rate': 2.3190120378245884e-06, 'epoch': 0.79}
{'loss': 0.7922, 'learning_rate': 2.3140268632614337e-06, 'epoch': 0.79}
{'loss': 0.7092, 'learning_rate': 2.309046351597164e-06, 'epoch': 0.79}
{'loss': 0.7845, 'learning_rate': 2.3040705058533384e-06, 'epoch': 0.79}
{'loss': 0.7756, 'learning_rate': 2.299099329048685e-06, 'epoch': 0.79}
{'loss': 0.7237, 'learning_rate': 2.294132824199098e-06, 'epoch': 0.79}
{'loss': 0.8262, 'learning_rate': 2.2891709943176366e-06, 'epoch': 0.79}
{'loss': 0.8137, 'learning_rate': 2.284213842414532e-06, 'epoch': 0.79}
{'loss': 0.7495, 'learning_rate': 2.279261371497169e-06, 'epoch': 0.79}
{'loss': 0.7897, 'learning_rate': 2.2743135845700935e-06, 'epoch': 0.79}
{'loss': 0.8059, 'learning_rate': 2.2693704846350108e-06, 'epoch': 0.79}
{'loss': 0.7573, 'learning_rate': 2.2644320746907867e-06, 'epoch': 0.79}
{'loss': 0.7466, 'learning_rate': 2.2594983577334374e-06, 'epoch': 0.79}
{'loss': 0.7135, 'learning_rate': 2.2545693367561282e-06, 'epoch': 0.79}
{'loss': 0.7609, 'learning_rate': 2.2496450147491867e-06, 'epoch': 0.79}
{'loss': 0.7629, 'learning_rate': 2.244725394700079e-06, 'epoch': 0.79}
{'loss': 0.6659, 'learning_rate': 2.239810479593424e-06, 'epoch': 0.79}
{'loss': 0.7721, 'learning_rate': 2.2349002724109826e-06, 'epoch': 0.79}
{'loss': 0.7206, 'learning_rate': 2.229994776131663e-06, 'epoch': 0.79}
{'loss': 0.787, 'learning_rate': 2.2250939937315186e-06, 'epoch': 0.79}
{'loss': 0.841, 'learning_rate': 2.220197928183735e-06, 'epoch': 0.79}
{'loss': 0.7931, 'learning_rate': 2.2153065824586363e-06, 'epoch': 0.79}
{'loss': 0.7948, 'learning_rate': 2.2104199595236943e-06, 'epoch': 0.79}
{'loss': 0.8307, 'learning_rate': 2.205538062343504e-06, 'epoch': 0.79}
{'loss': 0.832, 'learning_rate': 2.200660893879797e-06, 'epoch': 0.79}
{'loss': 0.8325, 'learning_rate': 2.1957884570914357e-06, 'epoch': 0.79}
{'loss': 0.7643, 'learning_rate': 2.190920754934416e-06, 'epoch': 0.79}
{'loss': 0.7957, 'learning_rate': 2.1860577903618564e-06, 'epoch': 0.79}
{'loss': 0.793, 'learning_rate': 2.1811995663240006e-06, 'epoch': 0.79}
{'loss': 0.7111, 'learning_rate': 2.1763460857682237e-06, 'epoch': 0.79}
{'loss': 0.7273, 'learning_rate': 2.1714973516390157e-06, 'epoch': 0.79}
{'loss': 0.7727, 'learning_rate': 2.1666533668779886e-06, 'epoch': 0.79}
{'loss': 0.7929, 'learning_rate': 2.161814134423872e-06, 'epoch': 0.79}
{'loss': 0.7731, 'learning_rate': 2.156979657212519e-06, 'epoch': 0.79}
{'loss': 0.6508, 'learning_rate': 2.1521499381768886e-06, 'epoch': 0.79}
[2025-12-10 00:49:50,342] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step16500 is about to be saved!
[2025-12-10 00:49:50,374] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16500/global_step16500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-10 00:49:50,375] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16500/global_step16500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-10 00:49:50,531] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16500/global_step16500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-10 00:49:50,537] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16500/global_step16500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-10 00:50:45,975] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16500/global_step16500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-10 00:50:45,979] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-16500/global_step16500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-10 00:50:45,991] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step16500 is ready now!
{'loss': 0.7429, 'learning_rate': 2.147324980247062e-06, 'epoch': 0.79}
{'loss': 0.6898, 'learning_rate': 2.1425047863502223e-06, 'epoch': 0.79}
{'loss': 0.7962, 'learning_rate': 2.137689359410674e-06, 'epoch': 0.79}
{'loss': 0.7849, 'learning_rate': 2.13287870234982e-06, 'epoch': 0.79}
{'loss': 0.6972, 'learning_rate': 2.128072818086171e-06, 'epoch': 0.79}
{'loss': 0.7846, 'learning_rate': 2.1232717095353437e-06, 'epoch': 0.8}
{'loss': 0.8445, 'learning_rate': 2.118475379610061e-06, 'epoch': 0.8}
{'loss': 0.7104, 'learning_rate': 2.1136838312201423e-06, 'epoch': 0.8}
{'loss': 0.6728, 'learning_rate': 2.108897067272505e-06, 'epoch': 0.8}
{'loss': 0.6965, 'learning_rate': 2.1041150906711662e-06, 'epoch': 0.8}
{'loss': 0.7946, 'learning_rate': 2.099337904317241e-06, 'epoch': 0.8}
{'loss': 0.7816, 'learning_rate': 2.0945655111089345e-06, 'epoch': 0.8}
{'loss': 0.6968, 'learning_rate': 2.0897979139415426e-06, 'epoch': 0.8}
{'loss': 0.665, 'learning_rate': 2.08503511570746e-06, 'epoch': 0.8}
{'loss': 0.8257, 'learning_rate': 2.080277119296161e-06, 'epoch': 0.8}
{'loss': 0.8095, 'learning_rate': 2.0755239275942097e-06, 'epoch': 0.8}
{'loss': 0.6516, 'learning_rate': 2.070775543485253e-06, 'epoch': 0.8}
{'loss': 0.798, 'learning_rate': 2.0660319698500264e-06, 'epoch': 0.8}
{'loss': 0.7658, 'learning_rate': 2.0612932095663473e-06, 'epoch': 0.8}
{'loss': 0.7032, 'learning_rate': 2.056559265509108e-06, 'epoch': 0.8}
{'loss': 0.7365, 'learning_rate': 2.0518301405502763e-06, 'epoch': 0.8}
{'loss': 0.8026, 'learning_rate': 2.047105837558907e-06, 'epoch': 0.8}
{'loss': 0.7246, 'learning_rate': 2.0423863594011217e-06, 'epoch': 0.8}
{'loss': 0.7772, 'learning_rate': 2.0376717089401166e-06, 'epoch': 0.8}
{'loss': 0.6352, 'learning_rate': 2.0329618890361547e-06, 'epoch': 0.8}
{'loss': 0.8215, 'learning_rate': 2.0282569025465805e-06, 'epoch': 0.8}
{'loss': 0.7231, 'learning_rate': 2.0235567523257937e-06, 'epoch': 0.8}
{'loss': 0.6885, 'learning_rate': 2.0188614412252625e-06, 'epoch': 0.8}
{'loss': 0.661, 'learning_rate': 2.014170972093529e-06, 'epoch': 0.8}
{'loss': 0.8102, 'learning_rate': 2.0094853477761845e-06, 'epoch': 0.8}
{'loss': 0.7704, 'learning_rate': 2.0048045711158894e-06, 'epoch': 0.8}
{'loss': 0.8638, 'learning_rate': 2.000128644952357e-06, 'epoch': 0.8}
{'loss': 0.7479, 'learning_rate': 1.9954575721223667e-06, 'epoch': 0.8}
{'loss': 0.769, 'learning_rate': 1.9907913554597434e-06, 'epoch': 0.8}
{'loss': 0.7246, 'learning_rate': 1.9861299977953764e-06, 'epoch': 0.8}
{'loss': 0.7708, 'learning_rate': 1.981473501957195e-06, 'epoch': 0.8}
{'loss': 0.7807, 'learning_rate': 1.9768218707701924e-06, 'epoch': 0.8}
{'loss': 0.6688, 'learning_rate': 1.972175107056401e-06, 'epoch': 0.8}
{'loss': 0.7796, 'learning_rate': 1.9675332136349023e-06, 'epoch': 0.8}
{'loss': 0.688, 'learning_rate': 1.9628961933218216e-06, 'epoch': 0.8}
{'loss': 0.7466, 'learning_rate': 1.958264048930334e-06, 'epoch': 0.8}
{'loss': 0.7054, 'learning_rate': 1.9536367832706503e-06, 'epoch': 0.8}
{'loss': 0.7582, 'learning_rate': 1.9490143991500245e-06, 'epoch': 0.8}
{'loss': 0.7687, 'learning_rate': 1.9443968993727447e-06, 'epoch': 0.8}
{'loss': 0.7409, 'learning_rate': 1.939784286740145e-06, 'epoch': 0.8}
{'loss': 0.7726, 'learning_rate': 1.935176564050586e-06, 'epoch': 0.8}
{'loss': 0.8188, 'learning_rate': 1.930573734099461e-06, 'epoch': 0.8}
{'loss': 0.7494, 'learning_rate': 1.925975799679205e-06, 'epoch': 0.81}
{'loss': 0.7169, 'learning_rate': 1.9213827635792737e-06, 'epoch': 0.81}
{'loss': 0.8104, 'learning_rate': 1.9167946285861515e-06, 'epoch': 0.81}
{'loss': 0.8048, 'learning_rate': 1.9122113974833558e-06, 'epoch': 0.81}
{'loss': 0.8036, 'learning_rate': 1.9076330730514214e-06, 'epoch': 0.81}
{'loss': 0.8188, 'learning_rate': 1.9030596580679139e-06, 'epoch': 0.81}
{'loss': 0.6594, 'learning_rate': 1.8984911553074148e-06, 'epoch': 0.81}
{'loss': 0.7414, 'learning_rate': 1.8939275675415236e-06, 'epoch': 0.81}
{'loss': 0.8017, 'learning_rate': 1.889368897538868e-06, 'epoch': 0.81}
{'loss': 0.7702, 'learning_rate': 1.8848151480650812e-06, 'epoch': 0.81}
{'loss': 0.7774, 'learning_rate': 1.8802663218828177e-06, 'epoch': 0.81}
{'loss': 0.7847, 'learning_rate': 1.875722421751739e-06, 'epoch': 0.81}
{'loss': 0.8112, 'learning_rate': 1.8711834504285287e-06, 'epoch': 0.81}
{'loss': 0.74, 'learning_rate': 1.8666494106668709e-06, 'epoch': 0.81}
{'loss': 0.7881, 'learning_rate': 1.8621203052174596e-06, 'epoch': 0.81}
{'loss': 0.7327, 'learning_rate': 1.857596136827996e-06, 'epoch': 0.81}
{'loss': 0.7759, 'learning_rate': 1.85307690824319e-06, 'epoch': 0.81}
{'loss': 0.7431, 'learning_rate': 1.8485626222047492e-06, 'epoch': 0.81}
{'loss': 0.7651, 'learning_rate': 1.8440532814513812e-06, 'epoch': 0.81}
{'loss': 0.7705, 'learning_rate': 1.8395488887188007e-06, 'epoch': 0.81}
{'loss': 0.6687, 'learning_rate': 1.8350494467397196e-06, 'epoch': 0.81}
{'loss': 0.7735, 'learning_rate': 1.8305549582438387e-06, 'epoch': 0.81}
{'loss': 0.8186, 'learning_rate': 1.8260654259578592e-06, 'epoch': 0.81}
{'loss': 0.7883, 'learning_rate': 1.8215808526054734e-06, 'epoch': 0.81}
{'loss': 0.7446, 'learning_rate': 1.8171012409073696e-06, 'epoch': 0.81}
{'loss': 0.7834, 'learning_rate': 1.8126265935812215e-06, 'epoch': 0.81}
{'loss': 0.7651, 'learning_rate': 1.8081569133416888e-06, 'epoch': 0.81}
{'loss': 0.7857, 'learning_rate': 1.8036922029004266e-06, 'epoch': 0.81}
{'loss': 0.8051, 'learning_rate': 1.7992324649660664e-06, 'epoch': 0.81}
{'loss': 0.7565, 'learning_rate': 1.7947777022442281e-06, 'epoch': 0.81}
{'loss': 0.8079, 'learning_rate': 1.7903279174375065e-06, 'epoch': 0.81}
WARNING: tokenization mismatch: 1 vs. 624. (ignored)
{'loss': 0.7747, 'learning_rate': 1.785883113245488e-06, 'epoch': 0.81}
{'loss': 0.6851, 'learning_rate': 1.7814432923647274e-06, 'epoch': 0.81}
{'loss': 0.7101, 'learning_rate': 1.777008457488757e-06, 'epoch': 0.81}
{'loss': 0.8391, 'learning_rate': 1.7725786113080924e-06, 'epoch': 0.81}
{'loss': 0.6583, 'learning_rate': 1.7681537565102124e-06, 'epoch': 0.81}
{'loss': 0.6732, 'learning_rate': 1.7637338957795714e-06, 'epoch': 0.81}
{'loss': 0.7724, 'learning_rate': 1.7593190317975994e-06, 'epoch': 0.81}
{'loss': 0.7647, 'learning_rate': 1.7549091672426866e-06, 'epoch': 0.81}
{'loss': 0.8043, 'learning_rate': 1.750504304790196e-06, 'epoch': 0.81}
{'loss': 0.8003, 'learning_rate': 1.7461044471124545e-06, 'epoch': 0.81}
{'loss': 0.7567, 'learning_rate': 1.7417095968787478e-06, 'epoch': 0.82}
{'loss': 0.7262, 'learning_rate': 1.7373197567553335e-06, 'epoch': 0.82}
{'loss': 0.7784, 'learning_rate': 1.732934929405422e-06, 'epoch': 0.82}
{'loss': 0.7157, 'learning_rate': 1.7285551174891846e-06, 'epoch': 0.82}
{'loss': 0.755, 'learning_rate': 1.7241803236637478e-06, 'epoch': 0.82}
{'loss': 0.7131, 'learning_rate': 1.7198105505831997e-06, 'epoch': 0.82}
{'loss': 0.7535, 'learning_rate': 1.7154458008985775e-06, 'epoch': 0.82}
{'loss': 0.7973, 'learning_rate': 1.711086077257872e-06, 'epoch': 0.82}
{'loss': 0.7709, 'learning_rate': 1.7067313823060216e-06, 'epoch': 0.82}
{'loss': 0.5571, 'learning_rate': 1.7023817186849235e-06, 'epoch': 0.82}
{'loss': 0.8689, 'learning_rate': 1.698037089033413e-06, 'epoch': 0.82}
{'loss': 0.7642, 'learning_rate': 1.693697495987271e-06, 'epoch': 0.82}
[2025-12-10 01:16:12,966] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step17000 is about to be saved!
[2025-12-10 01:16:12,997] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17000/global_step17000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-10 01:16:12,998] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17000/global_step17000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-10 01:16:13,158] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17000/global_step17000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-10 01:16:13,175] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17000/global_step17000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-10 01:17:41,730] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17000/global_step17000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-10 01:17:41,734] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17000/global_step17000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-10 01:17:41,747] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step17000 is ready now!
{'loss': 0.818, 'learning_rate': 1.6893629421792302e-06, 'epoch': 0.82}
{'loss': 0.8097, 'learning_rate': 1.6850334302389638e-06, 'epoch': 0.82}
{'loss': 0.7281, 'learning_rate': 1.680708962793084e-06, 'epoch': 0.82}
{'loss': 0.747, 'learning_rate': 1.676389542465141e-06, 'epoch': 0.82}
{'loss': 0.7316, 'learning_rate': 1.6720751718756244e-06, 'epoch': 0.82}
{'loss': 0.818, 'learning_rate': 1.6677658536419661e-06, 'epoch': 0.82}
{'loss': 0.6602, 'learning_rate': 1.6634615903785255e-06, 'epoch': 0.82}
{'loss': 0.7942, 'learning_rate': 1.6591623846965942e-06, 'epoch': 0.82}
{'loss': 0.7779, 'learning_rate': 1.6548682392044057e-06, 'epoch': 0.82}
{'loss': 0.8012, 'learning_rate': 1.6505791565071139e-06, 'epoch': 0.82}
{'loss': 0.8074, 'learning_rate': 1.6462951392068027e-06, 'epoch': 0.82}
{'loss': 0.7703, 'learning_rate': 1.6420161899024845e-06, 'epoch': 0.82}
{'loss': 0.7443, 'learning_rate': 1.6377423111900993e-06, 'epoch': 0.82}
{'loss': 0.625, 'learning_rate': 1.6334735056625096e-06, 'epoch': 0.82}
{'loss': 0.8159, 'learning_rate': 1.6292097759094927e-06, 'epoch': 0.82}
{'loss': 0.6771, 'learning_rate': 1.6249511245177619e-06, 'epoch': 0.82}
{'loss': 0.7881, 'learning_rate': 1.6206975540709325e-06, 'epoch': 0.82}
{'loss': 0.7431, 'learning_rate': 1.6164490671495525e-06, 'epoch': 0.82}
{'loss': 0.7957, 'learning_rate': 1.612205666331076e-06, 'epoch': 0.82}
{'loss': 0.7834, 'learning_rate': 1.607967354189871e-06, 'epoch': 0.82}
{'loss': 0.6062, 'learning_rate': 1.603734133297228e-06, 'epoch': 0.82}
{'loss': 0.8033, 'learning_rate': 1.5995060062213385e-06, 'epoch': 0.82}
{'loss': 0.7835, 'learning_rate': 1.5952829755273057e-06, 'epoch': 0.82}
{'loss': 0.7876, 'learning_rate': 1.591065043777148e-06, 'epoch': 0.82}
{'loss': 0.7892, 'learning_rate': 1.5868522135297827e-06, 'epoch': 0.82}
{'loss': 0.8135, 'learning_rate': 1.5826444873410352e-06, 'epoch': 0.82}
{'loss': 0.7094, 'learning_rate': 1.5784418677636304e-06, 'epoch': 0.82}
{'loss': 0.8109, 'learning_rate': 1.5742443573472032e-06, 'epoch': 0.82}
{'loss': 0.7707, 'learning_rate': 1.5700519586382834e-06, 'epoch': 0.82}
{'loss': 0.7383, 'learning_rate': 1.5658646741803008e-06, 'epoch': 0.82}
{'loss': 0.7606, 'learning_rate': 1.5616825065135778e-06, 'epoch': 0.83}
{'loss': 0.7787, 'learning_rate': 1.5575054581753435e-06, 'epoch': 0.83}
{'loss': 0.7277, 'learning_rate': 1.553333531699711e-06, 'epoch': 0.83}
{'loss': 0.7318, 'learning_rate': 1.5491667296176882e-06, 'epoch': 0.83}
{'loss': 0.7144, 'learning_rate': 1.5450050544571792e-06, 'epoch': 0.83}
{'loss': 0.7556, 'learning_rate': 1.5408485087429747e-06, 'epoch': 0.83}
{'loss': 0.7327, 'learning_rate': 1.5366970949967518e-06, 'epoch': 0.83}
{'loss': 0.7852, 'learning_rate': 1.5325508157370761e-06, 'epoch': 0.83}
{'loss': 0.7731, 'learning_rate': 1.528409673479394e-06, 'epoch': 0.83}
{'loss': 0.7962, 'learning_rate': 1.5242736707360438e-06, 'epoch': 0.83}
{'loss': 0.7895, 'learning_rate': 1.5201428100162397e-06, 'epoch': 0.83}
{'loss': 0.6856, 'learning_rate': 1.5160170938260742e-06, 'epoch': 0.83}
{'loss': 0.8258, 'learning_rate': 1.5118965246685269e-06, 'epoch': 0.83}
{'loss': 0.7738, 'learning_rate': 1.5077811050434477e-06, 'epoch': 0.83}
{'loss': 0.7584, 'learning_rate': 1.5036708374475662e-06, 'epoch': 0.83}
{'loss': 0.7378, 'learning_rate': 1.4995657243744798e-06, 'epoch': 0.83}
{'loss': 0.8184, 'learning_rate': 1.495465768314671e-06, 'epoch': 0.83}
{'loss': 0.7217, 'learning_rate': 1.4913709717554836e-06, 'epoch': 0.83}
{'loss': 0.8152, 'learning_rate': 1.4872813371811324e-06, 'epoch': 0.83}
{'loss': 0.7, 'learning_rate': 1.4831968670727038e-06, 'epoch': 0.83}
{'loss': 0.7506, 'learning_rate': 1.4791175639081513e-06, 'epoch': 0.83}
{'loss': 0.8355, 'learning_rate': 1.4750434301622907e-06, 'epoch': 0.83}
{'loss': 0.772, 'learning_rate': 1.470974468306804e-06, 'epoch': 0.83}
{'loss': 0.7501, 'learning_rate': 1.4669106808102307e-06, 'epoch': 0.83}
{'loss': 0.6995, 'learning_rate': 1.462852070137979e-06, 'epoch': 0.83}
{'loss': 0.7215, 'learning_rate': 1.4587986387523123e-06, 'epoch': 0.83}
{'loss': 0.7983, 'learning_rate': 1.4547503891123483e-06, 'epoch': 0.83}
{'loss': 0.7102, 'learning_rate': 1.4507073236740698e-06, 'epoch': 0.83}
{'loss': 0.746, 'learning_rate': 1.4466694448903063e-06, 'epoch': 0.83}
{'loss': 0.8059, 'learning_rate': 1.4426367552107435e-06, 'epoch': 0.83}
{'loss': 0.7362, 'learning_rate': 1.4386092570819188e-06, 'epoch': 0.83}
{'loss': 0.776, 'learning_rate': 1.4345869529472235e-06, 'epoch': 0.83}
{'loss': 0.7983, 'learning_rate': 1.430569845246893e-06, 'epoch': 0.83}
{'loss': 0.7527, 'learning_rate': 1.4265579364180126e-06, 'epoch': 0.83}
{'loss': 0.7804, 'learning_rate': 1.4225512288945088e-06, 'epoch': 0.83}
{'loss': 0.7358, 'learning_rate': 1.4185497251071633e-06, 'epoch': 0.83}
{'loss': 0.8447, 'learning_rate': 1.4145534274835882e-06, 'epoch': 0.83}
{'loss': 0.8006, 'learning_rate': 1.410562338448248e-06, 'epoch': 0.83}
{'loss': 0.7828, 'learning_rate': 1.4065764604224386e-06, 'epoch': 0.83}
{'loss': 0.8495, 'learning_rate': 1.402595795824302e-06, 'epoch': 0.83}
{'loss': 0.7556, 'learning_rate': 1.3986203470688109e-06, 'epoch': 0.83}
{'loss': 0.6972, 'learning_rate': 1.3946501165677783e-06, 'epoch': 0.83}
{'loss': 0.8396, 'learning_rate': 1.3906851067298466e-06, 'epoch': 0.84}
{'loss': 0.6669, 'learning_rate': 1.3867253199604969e-06, 'epoch': 0.84}
{'loss': 0.7668, 'learning_rate': 1.3827707586620375e-06, 'epoch': 0.84}
{'loss': 0.6898, 'learning_rate': 1.3788214252336063e-06, 'epoch': 0.84}
{'loss': 0.7962, 'learning_rate': 1.3748773220711741e-06, 'epoch': 0.84}
{'loss': 0.7267, 'learning_rate': 1.3709384515675327e-06, 'epoch': 0.84}
{'loss': 0.8234, 'learning_rate': 1.367004816112303e-06, 'epoch': 0.84}
{'loss': 0.7572, 'learning_rate': 1.3630764180919276e-06, 'epoch': 0.84}
{'loss': 0.7375, 'learning_rate': 1.3591532598896751e-06, 'epoch': 0.84}
{'loss': 0.6835, 'learning_rate': 1.3552353438856324e-06, 'epoch': 0.84}
{'loss': 0.6466, 'learning_rate': 1.3513226724567053e-06, 'epoch': 0.84}
{'loss': 0.6391, 'learning_rate': 1.347415247976621e-06, 'epoch': 0.84}
{'loss': 0.6953, 'learning_rate': 1.343513072815924e-06, 'epoch': 0.84}
{'loss': 0.7703, 'learning_rate': 1.339616149341969e-06, 'epoch': 0.84}
{'loss': 0.7926, 'learning_rate': 1.3357244799189295e-06, 'epoch': 0.84}
{'loss': 0.858, 'learning_rate': 1.3318380669077857e-06, 'epoch': 0.84}
{'loss': 0.8316, 'learning_rate': 1.3279569126663384e-06, 'epoch': 0.84}
{'loss': 0.794, 'learning_rate': 1.3240810195491904e-06, 'epoch': 0.84}
{'loss': 0.8109, 'learning_rate': 1.3202103899077512e-06, 'epoch': 0.84}
{'loss': 0.7599, 'learning_rate': 1.3163450260902466e-06, 'epoch': 0.84}
{'loss': 0.7504, 'learning_rate': 1.3124849304416986e-06, 'epoch': 0.84}
{'loss': 0.8287, 'learning_rate': 1.3086301053039373e-06, 'epoch': 0.84}
{'loss': 0.8138, 'learning_rate': 1.304780553015591e-06, 'epoch': 0.84}
{'loss': 0.7219, 'learning_rate': 1.300936275912098e-06, 'epoch': 0.84}
{'loss': 0.7243, 'learning_rate': 1.2970972763256872e-06, 'epoch': 0.84}
{'loss': 0.7757, 'learning_rate': 1.293263556585389e-06, 'epoch': 0.84}
{'loss': 0.8245, 'learning_rate': 1.2894351190170306e-06, 'epoch': 0.84}
{'loss': 0.7683, 'learning_rate': 1.2856119659432365e-06, 'epoch': 0.84}
[2025-12-10 01:42:39,774] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step17500 is about to be saved!
[2025-12-10 01:42:39,866] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17500/global_step17500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-10 01:42:39,866] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17500/global_step17500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-10 01:42:40,458] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17500/global_step17500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-10 01:42:40,469] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17500/global_step17500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-10 01:43:36,515] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17500/global_step17500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-10 01:43:36,518] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-17500/global_step17500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-10 01:43:36,546] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step17500 is ready now!
{'loss': 0.7128, 'learning_rate': 1.2817940996834243e-06, 'epoch': 0.84}
{'loss': 0.8146, 'learning_rate': 1.2779815225538028e-06, 'epoch': 0.84}
{'loss': 0.7612, 'learning_rate': 1.2741742368673693e-06, 'epoch': 0.84}
{'loss': 0.7876, 'learning_rate': 1.2703722449339206e-06, 'epoch': 0.84}
{'loss': 0.7772, 'learning_rate': 1.2665755490600318e-06, 'epoch': 0.84}
{'loss': 0.7836, 'learning_rate': 1.2627841515490703e-06, 'epoch': 0.84}
{'loss': 0.8065, 'learning_rate': 1.2589980547011837e-06, 'epoch': 0.84}
{'loss': 0.7726, 'learning_rate': 1.255217260813314e-06, 'epoch': 0.84}
{'loss': 0.787, 'learning_rate': 1.251441772179176e-06, 'epoch': 0.84}
{'loss': 0.7673, 'learning_rate': 1.247671591089269e-06, 'epoch': 0.84}
{'loss': 0.7264, 'learning_rate': 1.2439067198308762e-06, 'epoch': 0.84}
{'loss': 0.7456, 'learning_rate': 1.2401471606880554e-06, 'epoch': 0.84}
{'loss': 0.5685, 'learning_rate': 1.236392915941641e-06, 'epoch': 0.84}
{'loss': 0.7992, 'learning_rate': 1.2326439878692441e-06, 'epoch': 0.85}
{'loss': 0.6903, 'learning_rate': 1.228900378745256e-06, 'epoch': 0.85}
{'loss': 0.7121, 'learning_rate': 1.2251620908408312e-06, 'epoch': 0.85}
{'loss': 0.8167, 'learning_rate': 1.2214291264239009e-06, 'epoch': 0.85}
{'loss': 0.7528, 'learning_rate': 1.2177014877591687e-06, 'epoch': 0.85}
{'loss': 0.7936, 'learning_rate': 1.2139791771081078e-06, 'epoch': 0.85}
{'loss': 0.7037, 'learning_rate': 1.2102621967289519e-06, 'epoch': 0.85}
{'loss': 0.7713, 'learning_rate': 1.206550548876708e-06, 'epoch': 0.85}
{'loss': 0.716, 'learning_rate': 1.2028442358031433e-06, 'epoch': 0.85}
{'loss': 0.8338, 'learning_rate': 1.199143259756792e-06, 'epoch': 0.85}
{'loss': 0.7494, 'learning_rate': 1.1954476229829504e-06, 'epoch': 0.85}
{'loss': 0.759, 'learning_rate': 1.1917573277236705e-06, 'epoch': 0.85}
{'loss': 0.7429, 'learning_rate': 1.1880723762177714e-06, 'epoch': 0.85}
{'loss': 0.6813, 'learning_rate': 1.1843927707008262e-06, 'epoch': 0.85}
{'loss': 0.852, 'learning_rate': 1.1807185134051624e-06, 'epoch': 0.85}
{'loss': 0.6798, 'learning_rate': 1.1770496065598647e-06, 'epoch': 0.85}
{'loss': 0.6464, 'learning_rate': 1.173386052390777e-06, 'epoch': 0.85}
{'loss': 0.7528, 'learning_rate': 1.169727853120488e-06, 'epoch': 0.85}
{'loss': 0.7967, 'learning_rate': 1.1660750109683415e-06, 'epoch': 0.85}
{'loss': 0.6299, 'learning_rate': 1.1624275281504294e-06, 'epoch': 0.85}
{'loss': 0.7253, 'learning_rate': 1.1587854068795957e-06, 'epoch': 0.85}
{'loss': 0.7648, 'learning_rate': 1.1551486493654307e-06, 'epoch': 0.85}
{'loss': 0.6675, 'learning_rate': 1.1515172578142675e-06, 'epoch': 0.85}
{'loss': 0.7617, 'learning_rate': 1.1478912344291848e-06, 'epoch': 0.85}
{'loss': 0.7644, 'learning_rate': 1.1442705814100085e-06, 'epoch': 0.85}
{'loss': 0.756, 'learning_rate': 1.1406553009533028e-06, 'epoch': 0.85}
{'loss': 0.6518, 'learning_rate': 1.1370453952523719e-06, 'epoch': 0.85}
{'loss': 0.7867, 'learning_rate': 1.1334408664972596e-06, 'epoch': 0.85}
{'loss': 0.7459, 'learning_rate': 1.1298417168747522e-06, 'epoch': 0.85}
{'loss': 0.756, 'learning_rate': 1.1262479485683663e-06, 'epoch': 0.85}
{'loss': 0.7653, 'learning_rate': 1.122659563758356e-06, 'epoch': 0.85}
{'loss': 0.7383, 'learning_rate': 1.1190765646217128e-06, 'epoch': 0.85}
{'loss': 0.7605, 'learning_rate': 1.1154989533321558e-06, 'epoch': 0.85}
{'loss': 0.7743, 'learning_rate': 1.111926732060138e-06, 'epoch': 0.85}
{'loss': 0.8345, 'learning_rate': 1.1083599029728399e-06, 'epoch': 0.85}
{'loss': 0.7731, 'learning_rate': 1.1047984682341762e-06, 'epoch': 0.85}
{'loss': 0.8075, 'learning_rate': 1.1012424300047818e-06, 'epoch': 0.85}
{'loss': 0.69, 'learning_rate': 1.0976917904420247e-06, 'epoch': 0.85}
{'loss': 0.7653, 'learning_rate': 1.0941465516999917e-06, 'epoch': 0.85}
{'loss': 0.8113, 'learning_rate': 1.0906067159294987e-06, 'epoch': 0.85}
{'loss': 0.657, 'learning_rate': 1.087072285278079e-06, 'epoch': 0.85}
{'loss': 0.7814, 'learning_rate': 1.0835432618899887e-06, 'epoch': 0.85}
{'loss': 0.7768, 'learning_rate': 1.0800196479062008e-06, 'epoch': 0.86}
{'loss': 0.8061, 'learning_rate': 1.076501445464413e-06, 'epoch': 0.86}
{'loss': 0.7645, 'learning_rate': 1.0729886566990333e-06, 'epoch': 0.86}
{'loss': 0.8226, 'learning_rate': 1.069481283741186e-06, 'epoch': 0.86}
{'loss': 0.7973, 'learning_rate': 1.065979328718716e-06, 'epoch': 0.86}
{'loss': 0.725, 'learning_rate': 1.0624827937561755e-06, 'epoch': 0.86}
{'loss': 0.7328, 'learning_rate': 1.0589916809748301e-06, 'epoch': 0.86}
{'loss': 0.777, 'learning_rate': 1.0555059924926513e-06, 'epoch': 0.86}
{'loss': 0.6135, 'learning_rate': 1.052025730424332e-06, 'epoch': 0.86}
{'loss': 0.779, 'learning_rate': 1.0485508968812596e-06, 'epoch': 0.86}
{'loss': 0.8502, 'learning_rate': 1.0450814939715358e-06, 'epoch': 0.86}
{'loss': 0.7734, 'learning_rate': 1.0416175237999615e-06, 'epoch': 0.86}
{'loss': 0.822, 'learning_rate': 1.0381589884680522e-06, 'epoch': 0.86}
{'loss': 0.8332, 'learning_rate': 1.0347058900740182e-06, 'epoch': 0.86}
{'loss': 0.697, 'learning_rate': 1.0312582307127717e-06, 'epoch': 0.86}
{'loss': 0.7423, 'learning_rate': 1.0278160124759251e-06, 'epoch': 0.86}
{'loss': 0.7818, 'learning_rate': 1.0243792374517937e-06, 'epoch': 0.86}
{'loss': 0.7471, 'learning_rate': 1.020947907725387e-06, 'epoch': 0.86}
{'loss': 0.8033, 'learning_rate': 1.0175220253784123e-06, 'epoch': 0.86}
{'loss': 0.7839, 'learning_rate': 1.0141015924892693e-06, 'epoch': 0.86}
{'loss': 0.6898, 'learning_rate': 1.0106866111330572e-06, 'epoch': 0.86}
{'loss': 0.6584, 'learning_rate': 1.007277083381565e-06, 'epoch': 0.86}
{'loss': 0.7743, 'learning_rate': 1.003873011303268e-06, 'epoch': 0.86}
{'loss': 0.6396, 'learning_rate': 1.0004743969633423e-06, 'epoch': 0.86}
{'loss': 0.6731, 'learning_rate': 9.970812424236464e-07, 'epoch': 0.86}
{'loss': 0.6777, 'learning_rate': 9.936935497427248e-07, 'epoch': 0.86}
{'loss': 0.8052, 'learning_rate': 9.903113209758098e-07, 'epoch': 0.86}
{'loss': 0.755, 'learning_rate': 9.869345581748236e-07, 'epoch': 0.86}
{'loss': 0.7843, 'learning_rate': 9.83563263388365e-07, 'epoch': 0.86}
{'loss': 0.7871, 'learning_rate': 9.801974386617241e-07, 'epoch': 0.86}
{'loss': 0.7523, 'learning_rate': 9.768370860368614e-07, 'epoch': 0.86}
{'loss': 0.8033, 'learning_rate': 9.734822075524298e-07, 'epoch': 0.86}
{'loss': 0.8164, 'learning_rate': 9.70132805243752e-07, 'epoch': 0.86}
{'loss': 0.7738, 'learning_rate': 9.667888811428316e-07, 'epoch': 0.86}
{'loss': 0.7846, 'learning_rate': 9.634504372783459e-07, 'epoch': 0.86}
{'loss': 0.7661, 'learning_rate': 9.601174756756558e-07, 'epoch': 0.86}
{'loss': 0.8183, 'learning_rate': 9.567899983567875e-07, 'epoch': 0.86}
{'loss': 0.8245, 'learning_rate': 9.534680073404423e-07, 'epoch': 0.86}
{'loss': 0.8188, 'learning_rate': 9.50151504641994e-07, 'epoch': 0.86}
{'loss': 0.8376, 'learning_rate': 9.468404922734897e-07, 'epoch': 0.86}
{'loss': 0.7437, 'learning_rate': 9.435349722436404e-07, 'epoch': 0.86}
{'loss': 0.8188, 'learning_rate': 9.402349465578242e-07, 'epoch': 0.87}
{'loss': 0.7752, 'learning_rate': 9.369404172180952e-07, 'epoch': 0.87}
{'loss': 0.7884, 'learning_rate': 9.336513862231644e-07, 'epoch': 0.87}
{'loss': 0.7662, 'learning_rate': 9.303678555684059e-07, 'epoch': 0.87}
[2025-12-10 02:09:01,823] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step18000 is about to be saved!
[2025-12-10 02:09:01,856] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18000/global_step18000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-10 02:09:01,856] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18000/global_step18000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-10 02:09:02,014] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18000/global_step18000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-10 02:09:02,020] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18000/global_step18000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-10 02:09:48,727] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18000/global_step18000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-10 02:09:48,730] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18000/global_step18000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-10 02:09:53,608] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step18000 is ready now!
{'loss': 0.8102, 'learning_rate': 9.27089827245865e-07, 'epoch': 0.87}
{'loss': 0.7388, 'learning_rate': 9.23817303244241e-07, 'epoch': 0.87}
{'loss': 0.7598, 'learning_rate': 9.205502855489001e-07, 'epoch': 0.87}
{'loss': 0.7357, 'learning_rate': 9.172887761418637e-07, 'epoch': 0.87}
{'loss': 0.8322, 'learning_rate': 9.140327770018109e-07, 'epoch': 0.87}
{'loss': 0.7823, 'learning_rate': 9.107822901040841e-07, 'epoch': 0.87}
{'loss': 0.8114, 'learning_rate': 9.075373174206737e-07, 'epoch': 0.87}
{'loss': 0.7847, 'learning_rate': 9.04297860920228e-07, 'epoch': 0.87}
{'loss': 0.8089, 'learning_rate': 9.010639225680496e-07, 'epoch': 0.87}
{'loss': 0.7644, 'learning_rate': 8.978355043260945e-07, 'epoch': 0.87}
{'loss': 0.68, 'learning_rate': 8.94612608152966e-07, 'epoch': 0.87}
{'loss': 0.6538, 'learning_rate': 8.91395236003918e-07, 'epoch': 0.87}
{'loss': 0.8295, 'learning_rate': 8.88183389830859e-07, 'epoch': 0.87}
{'loss': 0.7555, 'learning_rate': 8.849770715823369e-07, 'epoch': 0.87}
{'loss': 0.8016, 'learning_rate': 8.817762832035504e-07, 'epoch': 0.87}
{'loss': 0.762, 'learning_rate': 8.785810266363404e-07, 'epoch': 0.87}
{'loss': 0.6762, 'learning_rate': 8.753913038191964e-07, 'epoch': 0.87}
{'loss': 0.6836, 'learning_rate': 8.722071166872481e-07, 'epoch': 0.87}
{'loss': 0.7298, 'learning_rate': 8.690284671722671e-07, 'epoch': 0.87}
{'loss': 0.7914, 'learning_rate': 8.658553572026618e-07, 'epoch': 0.87}
{'loss': 0.78, 'learning_rate': 8.626877887034879e-07, 'epoch': 0.87}
{'loss': 0.7318, 'learning_rate': 8.595257635964316e-07, 'epoch': 0.87}
{'loss': 0.8196, 'learning_rate': 8.563692837998217e-07, 'epoch': 0.87}
{'loss': 0.6151, 'learning_rate': 8.532183512286152e-07, 'epoch': 0.87}
{'loss': 0.7975, 'learning_rate': 8.50072967794413e-07, 'epoch': 0.87}
{'loss': 0.6068, 'learning_rate': 8.469331354054456e-07, 'epoch': 0.87}
{'loss': 0.7246, 'learning_rate': 8.437988559665733e-07, 'epoch': 0.87}
{'loss': 0.7119, 'learning_rate': 8.406701313792875e-07, 'epoch': 0.87}
{'loss': 0.7593, 'learning_rate': 8.375469635417166e-07, 'epoch': 0.87}
{'loss': 0.7385, 'learning_rate': 8.344293543486104e-07, 'epoch': 0.87}
{'loss': 0.7315, 'learning_rate': 8.313173056913471e-07, 'epoch': 0.87}
{'loss': 0.7139, 'learning_rate': 8.282108194579386e-07, 'epoch': 0.87}
{'loss': 0.7127, 'learning_rate': 8.25109897533013e-07, 'epoch': 0.87}
{'loss': 0.7456, 'learning_rate': 8.220145417978254e-07, 'epoch': 0.87}
{'loss': 0.7124, 'learning_rate': 8.189247541302592e-07, 'epoch': 0.87}
{'loss': 0.8123, 'learning_rate': 8.158405364048116e-07, 'epoch': 0.87}
{'loss': 0.7204, 'learning_rate': 8.127618904926094e-07, 'epoch': 0.87}
{'loss': 0.7588, 'learning_rate': 8.096888182613916e-07, 'epoch': 0.87}
{'loss': 0.7984, 'learning_rate': 8.066213215755181e-07, 'epoch': 0.88}
{'loss': 0.799, 'learning_rate': 8.035594022959692e-07, 'epoch': 0.88}
{'loss': 0.7343, 'learning_rate': 8.005030622803389e-07, 'epoch': 0.88}
{'loss': 0.7934, 'learning_rate': 7.974523033828363e-07, 'epoch': 0.88}
{'loss': 0.8101, 'learning_rate': 7.94407127454283e-07, 'epoch': 0.88}
{'loss': 0.7086, 'learning_rate': 7.91367536342118e-07, 'epoch': 0.88}
{'loss': 0.7997, 'learning_rate': 7.883335318903895e-07, 'epoch': 0.88}
{'loss': 0.7737, 'learning_rate': 7.85305115939754e-07, 'epoch': 0.88}
{'loss': 0.727, 'learning_rate': 7.822822903274829e-07, 'epoch': 0.88}
{'loss': 0.8408, 'learning_rate': 7.792650568874538e-07, 'epoch': 0.88}
{'loss': 0.7046, 'learning_rate': 7.762534174501491e-07, 'epoch': 0.88}
{'loss': 0.8135, 'learning_rate': 7.732473738426582e-07, 'epoch': 0.88}
{'loss': 0.6331, 'learning_rate': 7.702469278886793e-07, 'epoch': 0.88}
{'loss': 0.8343, 'learning_rate': 7.672520814085138e-07, 'epoch': 0.88}
{'loss': 0.7777, 'learning_rate': 7.642628362190618e-07, 'epoch': 0.88}
{'loss': 0.7736, 'learning_rate': 7.612791941338282e-07, 'epoch': 0.88}
{'loss': 0.8051, 'learning_rate': 7.583011569629206e-07, 'epoch': 0.88}
{'loss': 0.8731, 'learning_rate': 7.553287265130415e-07, 'epoch': 0.88}
{'loss': 0.7034, 'learning_rate': 7.523619045874964e-07, 'epoch': 0.88}
{'loss': 0.6919, 'learning_rate': 7.49400692986183e-07, 'epoch': 0.88}
{'loss': 0.7057, 'learning_rate': 7.464450935056023e-07, 'epoch': 0.88}
{'loss': 0.8085, 'learning_rate': 7.434951079388463e-07, 'epoch': 0.88}
{'loss': 0.748, 'learning_rate': 7.405507380756005e-07, 'epoch': 0.88}
{'loss': 0.6813, 'learning_rate': 7.376119857021435e-07, 'epoch': 0.88}
{'loss': 0.7862, 'learning_rate': 7.346788526013504e-07, 'epoch': 0.88}
{'loss': 0.7747, 'learning_rate': 7.317513405526821e-07, 'epoch': 0.88}
{'loss': 0.7311, 'learning_rate': 7.288294513321902e-07, 'epoch': 0.88}
{'loss': 0.736, 'learning_rate': 7.259131867125202e-07, 'epoch': 0.88}
{'loss': 0.7066, 'learning_rate': 7.230025484628955e-07, 'epoch': 0.88}
{'loss': 0.8143, 'learning_rate': 7.20097538349136e-07, 'epoch': 0.88}
{'loss': 0.6953, 'learning_rate': 7.171981581336429e-07, 'epoch': 0.88}
{'loss': 0.8106, 'learning_rate': 7.143044095753982e-07, 'epoch': 0.88}
{'loss': 0.7626, 'learning_rate': 7.11416294429974e-07, 'epoch': 0.88}
{'loss': 0.6997, 'learning_rate': 7.085338144495224e-07, 'epoch': 0.88}
{'loss': 0.8299, 'learning_rate': 7.056569713827732e-07, 'epoch': 0.88}
{'loss': 0.7741, 'learning_rate': 7.027857669750415e-07, 'epoch': 0.88}
{'loss': 0.7586, 'learning_rate': 6.999202029682195e-07, 'epoch': 0.88}
{'loss': 0.7411, 'learning_rate': 6.970602811007765e-07, 'epoch': 0.88}
{'loss': 0.7387, 'learning_rate': 6.942060031077591e-07, 'epoch': 0.88}
{'loss': 0.6571, 'learning_rate': 6.913573707207921e-07, 'epoch': 0.88}
{'loss': 0.7966, 'learning_rate': 6.885143856680731e-07, 'epoch': 0.88}
{'loss': 0.8181, 'learning_rate': 6.856770496743737e-07, 'epoch': 0.88}
{'loss': 0.7774, 'learning_rate': 6.828453644610388e-07, 'epoch': 0.89}
{'loss': 0.7659, 'learning_rate': 6.800193317459869e-07, 'epoch': 0.89}
{'loss': 0.8238, 'learning_rate': 6.771989532437039e-07, 'epoch': 0.89}
{'loss': 0.7726, 'learning_rate': 6.743842306652459e-07, 'epoch': 0.89}
{'loss': 0.7006, 'learning_rate': 6.71575165718239e-07, 'epoch': 0.89}
{'loss': 0.7294, 'learning_rate': 6.687717601068799e-07, 'epoch': 0.89}
{'loss': 0.6913, 'learning_rate': 6.659740155319272e-07, 'epoch': 0.89}
{'loss': 0.6959, 'learning_rate': 6.631819336907042e-07, 'epoch': 0.89}
{'loss': 0.6385, 'learning_rate': 6.603955162771047e-07, 'epoch': 0.89}
{'loss': 0.7797, 'learning_rate': 6.576147649815812e-07, 'epoch': 0.89}
{'loss': 0.7196, 'learning_rate': 6.548396814911495e-07, 'epoch': 0.89}
{'loss': 0.766, 'learning_rate': 6.520702674893864e-07, 'epoch': 0.89}
{'loss': 0.8151, 'learning_rate': 6.493065246564334e-07, 'epoch': 0.89}
{'loss': 0.7938, 'learning_rate': 6.465484546689849e-07, 'epoch': 0.89}
{'loss': 0.7568, 'learning_rate': 6.43796059200299e-07, 'epoch': 0.89}
{'loss': 0.7835, 'learning_rate': 6.410493399201878e-07, 'epoch': 0.89}
{'loss': 0.7615, 'learning_rate': 6.383082984950217e-07, 'epoch': 0.89}
{'loss': 0.8472, 'learning_rate': 6.355729365877283e-07, 'epoch': 0.89}
{'loss': 0.8147, 'learning_rate': 6.328432558577824e-07, 'epoch': 0.89}
{'loss': 0.779, 'learning_rate': 6.301192579612192e-07, 'epoch': 0.89}
[2025-12-10 02:34:53,876] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step18500 is about to be saved!
[2025-12-10 02:34:54,373] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18500/global_step18500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-10 02:34:54,374] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18500/global_step18500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-10 02:34:54,527] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18500/global_step18500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-10 02:34:54,529] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18500/global_step18500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-10 02:35:43,276] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18500/global_step18500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-10 02:35:43,286] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-18500/global_step18500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-10 02:35:43,317] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step18500 is ready now!
{'loss': 0.7308, 'learning_rate': 6.274009445506268e-07, 'epoch': 0.89}
{'loss': 0.6431, 'learning_rate': 6.246883172751405e-07, 'epoch': 0.89}
{'loss': 0.7268, 'learning_rate': 6.219813777804451e-07, 'epoch': 0.89}
{'loss': 0.7352, 'learning_rate': 6.192801277087779e-07, 'epoch': 0.89}
{'loss': 0.8107, 'learning_rate': 6.165845686989269e-07, 'epoch': 0.89}
{'loss': 0.7494, 'learning_rate': 6.138947023862208e-07, 'epoch': 0.89}
{'loss': 0.7886, 'learning_rate': 6.112105304025373e-07, 'epoch': 0.89}
{'loss': 0.712, 'learning_rate': 6.08532054376303e-07, 'epoch': 0.89}
{'loss': 0.7413, 'learning_rate': 6.058592759324866e-07, 'epoch': 0.89}
{'loss': 0.8114, 'learning_rate': 6.031921966925979e-07, 'epoch': 0.89}
{'loss': 0.7429, 'learning_rate': 6.005308182746906e-07, 'epoch': 0.89}
{'loss': 0.8022, 'learning_rate': 5.978751422933626e-07, 'epoch': 0.89}
{'loss': 0.7666, 'learning_rate': 5.952251703597489e-07, 'epoch': 0.89}
{'loss': 0.7865, 'learning_rate': 5.925809040815233e-07, 'epoch': 0.89}
{'loss': 0.7797, 'learning_rate': 5.899423450629027e-07, 'epoch': 0.89}
{'loss': 0.7192, 'learning_rate': 5.873094949046387e-07, 'epoch': 0.89}
{'loss': 0.6765, 'learning_rate': 5.84682355204016e-07, 'epoch': 0.89}
{'loss': 0.7291, 'learning_rate': 5.820609275548627e-07, 'epoch': 0.89}
{'loss': 0.8294, 'learning_rate': 5.794452135475326e-07, 'epoch': 0.89}
{'loss': 0.778, 'learning_rate': 5.768352147689227e-07, 'epoch': 0.89}
{'loss': 0.7478, 'learning_rate': 5.742309328024565e-07, 'epoch': 0.89}
{'loss': 0.7712, 'learning_rate': 5.716323692280868e-07, 'epoch': 0.9}
{'loss': 0.807, 'learning_rate': 5.690395256223047e-07, 'epoch': 0.9}
{'loss': 0.6914, 'learning_rate': 5.664524035581276e-07, 'epoch': 0.9}
{'loss': 0.8084, 'learning_rate': 5.638710046050988e-07, 'epoch': 0.9}
{'loss': 0.7516, 'learning_rate': 5.612953303292934e-07, 'epoch': 0.9}
{'loss': 0.6597, 'learning_rate': 5.587253822933136e-07, 'epoch': 0.9}
{'loss': 0.7888, 'learning_rate': 5.561611620562857e-07, 'epoch': 0.9}
{'loss': 0.7553, 'learning_rate': 5.536026711738606e-07, 'epoch': 0.9}
{'loss': 0.773, 'learning_rate': 5.510499111982148e-07, 'epoch': 0.9}
{'loss': 0.7938, 'learning_rate': 5.485028836780482e-07, 'epoch': 0.9}
{'loss': 0.7998, 'learning_rate': 5.459615901585836e-07, 'epoch': 0.9}
{'loss': 0.7347, 'learning_rate': 5.43426032181561e-07, 'epoch': 0.9}
{'loss': 0.8034, 'learning_rate': 5.408962112852445e-07, 'epoch': 0.9}
{'loss': 0.7835, 'learning_rate': 5.383721290044197e-07, 'epoch': 0.9}
{'loss': 0.7923, 'learning_rate': 5.35853786870385e-07, 'epoch': 0.9}
{'loss': 0.7994, 'learning_rate': 5.333411864109617e-07, 'epoch': 0.9}
{'loss': 0.6921, 'learning_rate': 5.308343291504814e-07, 'epoch': 0.9}
{'loss': 0.7766, 'learning_rate': 5.283332166097987e-07, 'epoch': 0.9}
{'loss': 0.7925, 'learning_rate': 5.258378503062788e-07, 'epoch': 0.9}
{'loss': 0.7506, 'learning_rate': 5.233482317538007e-07, 'epoch': 0.9}
{'loss': 0.7286, 'learning_rate': 5.208643624627596e-07, 'epoch': 0.9}
{'loss': 0.7678, 'learning_rate': 5.183862439400589e-07, 'epoch': 0.9}
{'loss': 0.7896, 'learning_rate': 5.159138776891148e-07, 'epoch': 0.9}
{'loss': 0.8613, 'learning_rate': 5.134472652098521e-07, 'epoch': 0.9}
{'loss': 0.7088, 'learning_rate': 5.109864079987104e-07, 'epoch': 0.9}
{'loss': 0.7023, 'learning_rate': 5.085313075486309e-07, 'epoch': 0.9}
{'loss': 0.7434, 'learning_rate': 5.060819653490645e-07, 'epoch': 0.9}
{'loss': 0.7623, 'learning_rate': 5.036383828859726e-07, 'epoch': 0.9}
{'loss': 0.8126, 'learning_rate': 5.012005616418158e-07, 'epoch': 0.9}
{'loss': 0.7522, 'learning_rate': 4.987685030955658e-07, 'epoch': 0.9}
{'loss': 0.7731, 'learning_rate': 4.963422087226944e-07, 'epoch': 0.9}
{'loss': 0.7128, 'learning_rate': 4.939216799951751e-07, 'epoch': 0.9}
{'loss': 0.7625, 'learning_rate': 4.91506918381488e-07, 'epoch': 0.9}
{'loss': 0.7629, 'learning_rate': 4.890979253466121e-07, 'epoch': 0.9}
{'loss': 0.7936, 'learning_rate': 4.866947023520241e-07, 'epoch': 0.9}
{'loss': 0.785, 'learning_rate': 4.842972508557064e-07, 'epoch': 0.9}
{'loss': 0.6718, 'learning_rate': 4.819055723121346e-07, 'epoch': 0.9}
{'loss': 0.6552, 'learning_rate': 4.795196681722835e-07, 'epoch': 0.9}
{'loss': 0.7605, 'learning_rate': 4.771395398836243e-07, 'epoch': 0.9}
{'loss': 0.7679, 'learning_rate': 4.7476518889012725e-07, 'epoch': 0.9}
{'loss': 0.8319, 'learning_rate': 4.723966166322536e-07, 'epoch': 0.9}
{'loss': 0.7737, 'learning_rate': 4.7003382454696044e-07, 'epoch': 0.9}
{'loss': 0.7212, 'learning_rate': 4.676768140676957e-07, 'epoch': 0.91}
{'loss': 0.7266, 'learning_rate': 4.653255866244066e-07, 'epoch': 0.91}
{'loss': 0.7153, 'learning_rate': 4.629801436435255e-07, 'epoch': 0.91}
{'loss': 0.8325, 'learning_rate': 4.606404865479763e-07, 'epoch': 0.91}
{'loss': 0.7824, 'learning_rate': 4.583066167571737e-07, 'epoch': 0.91}
{'loss': 0.7416, 'learning_rate': 4.55978535687025e-07, 'epoch': 0.91}
{'loss': 0.8503, 'learning_rate': 4.5365624474991933e-07, 'epoch': 0.91}
{'loss': 0.7504, 'learning_rate': 4.5133974535473633e-07, 'epoch': 0.91}
{'loss': 0.8221, 'learning_rate': 4.490290389068408e-07, 'epoch': 0.91}
{'loss': 0.765, 'learning_rate': 4.4672412680808574e-07, 'epoch': 0.91}
{'loss': 0.7637, 'learning_rate': 4.4442501045680595e-07, 'epoch': 0.91}
{'loss': 0.7537, 'learning_rate': 4.421316912478202e-07, 'epoch': 0.91}
{'loss': 0.8109, 'learning_rate': 4.3984417057243433e-07, 'epoch': 0.91}
{'loss': 0.7741, 'learning_rate': 4.3756244981843055e-07, 'epoch': 0.91}
{'loss': 0.7342, 'learning_rate': 4.352865303700748e-07, 'epoch': 0.91}
{'loss': 0.747, 'learning_rate': 4.33016413608115e-07, 'epoch': 0.91}
{'loss': 0.7609, 'learning_rate': 4.3075210090977814e-07, 'epoch': 0.91}
{'loss': 0.7547, 'learning_rate': 4.2849359364876885e-07, 'epoch': 0.91}
{'loss': 0.7338, 'learning_rate': 4.2624089319526883e-07, 'epoch': 0.91}
{'loss': 0.7396, 'learning_rate': 4.2399400091594154e-07, 'epoch': 0.91}
{'loss': 0.6988, 'learning_rate': 4.217529181739188e-07, 'epoch': 0.91}
{'loss': 0.8083, 'learning_rate': 4.1951764632881864e-07, 'epoch': 0.91}
{'loss': 0.7876, 'learning_rate': 4.17288186736724e-07, 'epoch': 0.91}
{'loss': 0.7483, 'learning_rate': 4.150645407501952e-07, 'epoch': 0.91}
{'loss': 0.7713, 'learning_rate': 4.1284670971826755e-07, 'epoch': 0.91}
{'loss': 0.7492, 'learning_rate': 4.1063469498644705e-07, 'epoch': 0.91}
{'loss': 0.7763, 'learning_rate': 4.08428497896709e-07, 'epoch': 0.91}
{'loss': 0.7633, 'learning_rate': 4.0622811978750396e-07, 'epoch': 0.91}
{'loss': 0.7968, 'learning_rate': 4.040335619937474e-07, 'epoch': 0.91}
{'loss': 0.7707, 'learning_rate': 4.018448258468266e-07, 'epoch': 0.91}
{'loss': 0.7802, 'learning_rate': 3.9966191267459596e-07, 'epoch': 0.91}
{'loss': 0.7531, 'learning_rate': 3.974848238013773e-07, 'epoch': 0.91}
{'loss': 0.8053, 'learning_rate': 3.9531356054796076e-07, 'epoch': 0.91}
{'loss': 0.7875, 'learning_rate': 3.931481242315993e-07, 'epoch': 0.91}
{'loss': 0.7035, 'learning_rate': 3.909885161660099e-07, 'epoch': 0.91}
{'loss': 0.6381, 'learning_rate': 3.88834737661381e-07, 'epoch': 0.91}
{'loss': 0.8335, 'learning_rate': 3.866867900243543e-07, 'epoch': 0.91}
[2025-12-10 03:00:11,953] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step19000 is about to be saved!
[2025-12-10 03:00:12,418] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19000/global_step19000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-10 03:00:12,419] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19000/global_step19000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-10 03:00:12,576] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19000/global_step19000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-10 03:00:12,578] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19000/global_step19000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-10 03:01:03,277] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19000/global_step19000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-10 03:01:03,280] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19000/global_step19000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-10 03:01:03,300] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step19000 is ready now!
{'loss': 0.7562, 'learning_rate': 3.8454467455804165e-07, 'epoch': 0.91}
{'loss': 0.6722, 'learning_rate': 3.8240839256201365e-07, 'epoch': 0.91}
{'loss': 0.7423, 'learning_rate': 3.8027794533230354e-07, 'epoch': 0.91}
{'loss': 0.6245, 'learning_rate': 3.7815333416140187e-07, 'epoch': 0.91}
{'loss': 0.7579, 'learning_rate': 3.760345603382609e-07, 'epoch': 0.92}
{'loss': 0.6931, 'learning_rate': 3.73921625148288e-07, 'epoch': 0.92}
{'loss': 0.7022, 'learning_rate': 3.718145298733566e-07, 'epoch': 0.92}
{'loss': 0.812, 'learning_rate': 3.697132757917876e-07, 'epoch': 0.92}
{'loss': 0.7587, 'learning_rate': 3.676178641783623e-07, 'epoch': 0.92}
{'loss': 0.6048, 'learning_rate': 3.655282963043205e-07, 'epoch': 0.92}
{'loss': 0.8071, 'learning_rate': 3.6344457343735265e-07, 'epoch': 0.92}
{'loss': 0.7743, 'learning_rate': 3.61366696841603e-07, 'epoch': 0.92}
{'loss': 0.6743, 'learning_rate': 3.59294667777671e-07, 'epoch': 0.92}
{'loss': 0.7662, 'learning_rate': 3.5722848750260886e-07, 'epoch': 0.92}
{'loss': 0.7877, 'learning_rate': 3.551681572699184e-07, 'epoch': 0.92}
{'loss': 0.7746, 'learning_rate': 3.53113678329553e-07, 'epoch': 0.92}
{'loss': 0.7678, 'learning_rate': 3.5106505192791684e-07, 'epoch': 0.92}
{'loss': 0.7642, 'learning_rate': 3.490222793078646e-07, 'epoch': 0.92}
{'loss': 0.7581, 'learning_rate': 3.4698536170869825e-07, 'epoch': 0.92}
{'loss': 0.7946, 'learning_rate': 3.4495430036616706e-07, 'epoch': 0.92}
{'loss': 0.7537, 'learning_rate': 3.4292909651246766e-07, 'epoch': 0.92}
{'loss': 0.7822, 'learning_rate': 3.409097513762438e-07, 'epoch': 0.92}
{'loss': 0.7573, 'learning_rate': 3.3889626618258563e-07, 'epoch': 0.92}
{'loss': 0.7018, 'learning_rate': 3.368886421530271e-07, 'epoch': 0.92}
{'loss': 0.7562, 'learning_rate': 3.3488688050554274e-07, 'epoch': 0.92}
{'loss': 0.7499, 'learning_rate': 3.328909824545601e-07, 'epoch': 0.92}
{'loss': 0.7755, 'learning_rate': 3.309009492109394e-07, 'epoch': 0.92}
{'loss': 0.7769, 'learning_rate': 3.289167819819872e-07, 'epoch': 0.92}
{'loss': 0.661, 'learning_rate': 3.269384819714538e-07, 'epoch': 0.92}
{'loss': 0.7631, 'learning_rate': 3.249660503795238e-07, 'epoch': 0.92}
{'loss': 0.7745, 'learning_rate': 3.2299948840282755e-07, 'epoch': 0.92}
{'loss': 0.6011, 'learning_rate': 3.2103879723442976e-07, 'epoch': 0.92}
{'loss': 0.6769, 'learning_rate': 3.1908397806383775e-07, 'epoch': 0.92}
{'loss': 0.7979, 'learning_rate': 3.1713503207699283e-07, 'epoch': 0.92}
{'loss': 0.8159, 'learning_rate': 3.1519196045627586e-07, 'epoch': 0.92}
{'loss': 0.7075, 'learning_rate': 3.1325476438049953e-07, 'epoch': 0.92}
{'loss': 0.6777, 'learning_rate': 3.113234450249192e-07, 'epoch': 0.92}
{'loss': 0.7938, 'learning_rate': 3.0939800356121985e-07, 'epoch': 0.92}
{'loss': 0.823, 'learning_rate': 3.0747844115751934e-07, 'epoch': 0.92}
{'loss': 0.6919, 'learning_rate': 3.055647589783717e-07, 'epoch': 0.92}
{'loss': 0.7565, 'learning_rate': 3.036569581847648e-07, 'epoch': 0.92}
{'loss': 0.7609, 'learning_rate': 3.0175503993411405e-07, 'epoch': 0.92}
{'loss': 0.7343, 'learning_rate': 2.998590053802697e-07, 'epoch': 0.92}
{'loss': 0.7726, 'learning_rate': 2.979688556735105e-07, 'epoch': 0.92}
{'loss': 0.763, 'learning_rate': 2.960845919605471e-07, 'epoch': 0.92}
{'loss': 0.7771, 'learning_rate': 2.942062153845171e-07, 'epoch': 0.92}
{'loss': 0.6646, 'learning_rate': 2.9233372708498577e-07, 'epoch': 0.93}
{'loss': 0.8429, 'learning_rate': 2.9046712819795096e-07, 'epoch': 0.93}
{'loss': 0.7276, 'learning_rate': 2.886064198558325e-07, 'epoch': 0.93}
{'loss': 0.7788, 'learning_rate': 2.867516031874773e-07, 'epoch': 0.93}
{'loss': 0.6638, 'learning_rate': 2.8490267931815864e-07, 'epoch': 0.93}
{'loss': 0.7819, 'learning_rate': 2.830596493695792e-07, 'epoch': 0.93}
{'loss': 0.748, 'learning_rate': 2.8122251445985793e-07, 'epoch': 0.93}
{'loss': 0.7979, 'learning_rate': 2.7939127570354216e-07, 'epoch': 0.93}
{'loss': 0.7463, 'learning_rate': 2.7756593421160104e-07, 'epoch': 0.93}
{'loss': 0.8285, 'learning_rate': 2.757464910914287e-07, 'epoch': 0.93}
{'loss': 0.7645, 'learning_rate': 2.739329474468355e-07, 'epoch': 0.93}
{'loss': 0.7775, 'learning_rate': 2.7212530437805696e-07, 'epoch': 0.93}
{'loss': 0.7182, 'learning_rate': 2.7032356298174576e-07, 'epoch': 0.93}
{'loss': 0.736, 'learning_rate': 2.6852772435097873e-07, 'epoch': 0.93}
{'loss': 0.799, 'learning_rate': 2.6673778957524876e-07, 'epoch': 0.93}
{'loss': 0.6907, 'learning_rate': 2.649537597404639e-07, 'epoch': 0.93}
{'loss': 0.7663, 'learning_rate': 2.631756359289561e-07, 'epoch': 0.93}
{'loss': 0.7824, 'learning_rate': 2.614034192194703e-07, 'epoch': 0.93}
{'loss': 0.6551, 'learning_rate': 2.5963711068716867e-07, 'epoch': 0.93}
{'loss': 0.7012, 'learning_rate': 2.5787671140362847e-07, 'epoch': 0.93}
{'loss': 0.7674, 'learning_rate': 2.5612222243684206e-07, 'epoch': 0.93}
{'loss': 0.8089, 'learning_rate': 2.543736448512191e-07, 'epoch': 0.93}
{'loss': 0.6127, 'learning_rate': 2.5263097970757767e-07, 'epoch': 0.93}
{'loss': 0.8067, 'learning_rate': 2.508942280631521e-07, 'epoch': 0.93}
{'loss': 0.7088, 'learning_rate': 2.491633909715918e-07, 'epoch': 0.93}
{'loss': 0.7797, 'learning_rate': 2.4743846948295124e-07, 'epoch': 0.93}
{'loss': 0.8359, 'learning_rate': 2.457194646437011e-07, 'epoch': 0.93}
{'loss': 0.684, 'learning_rate': 2.440063774967194e-07, 'epoch': 0.93}
{'loss': 0.8303, 'learning_rate': 2.422992090812981e-07, 'epoch': 0.93}
{'loss': 0.8153, 'learning_rate': 2.4059796043313653e-07, 'epoch': 0.93}
{'loss': 0.6685, 'learning_rate': 2.389026325843391e-07, 'epoch': 0.93}
{'loss': 0.7932, 'learning_rate': 2.3721322656342416e-07, 'epoch': 0.93}
{'loss': 0.7714, 'learning_rate': 2.35529743395313e-07, 'epoch': 0.93}
{'loss': 0.7637, 'learning_rate': 2.3385218410133526e-07, 'epoch': 0.93}
{'loss': 0.7807, 'learning_rate': 2.3218054969922687e-07, 'epoch': 0.93}
{'loss': 0.7823, 'learning_rate': 2.3051484120313105e-07, 'epoch': 0.93}
{'loss': 0.7092, 'learning_rate': 2.2885505962359055e-07, 'epoch': 0.93}
{'loss': 0.6981, 'learning_rate': 2.272012059675577e-07, 'epoch': 0.93}
{'loss': 0.7705, 'learning_rate': 2.2555328123838537e-07, 'epoch': 0.93}
{'loss': 0.6213, 'learning_rate': 2.239112864358317e-07, 'epoch': 0.93}
{'loss': 0.8141, 'learning_rate': 2.222752225560576e-07, 'epoch': 0.93}
{'loss': 0.767, 'learning_rate': 2.2064509059162243e-07, 'epoch': 0.94}
{'loss': 0.7022, 'learning_rate': 2.190208915314873e-07, 'epoch': 0.94}
{'loss': 0.7804, 'learning_rate': 2.174026263610196e-07, 'epoch': 0.94}
{'loss': 0.6496, 'learning_rate': 2.1579029606198065e-07, 'epoch': 0.94}
{'loss': 0.7524, 'learning_rate': 2.1418390161253356e-07, 'epoch': 0.94}
{'loss': 0.7596, 'learning_rate': 2.1258344398723875e-07, 'epoch': 0.94}
{'loss': 0.7247, 'learning_rate': 2.109889241570573e-07, 'epoch': 0.94}
{'loss': 0.6589, 'learning_rate': 2.0940034308934764e-07, 'epoch': 0.94}
{'loss': 0.7027, 'learning_rate': 2.0781770174786219e-07, 'epoch': 0.94}
{'loss': 0.7433, 'learning_rate': 2.0624100109275514e-07, 'epoch': 0.94}
{'loss': 0.6609, 'learning_rate': 2.0467024208057128e-07, 'epoch': 0.94}
{'loss': 0.7648, 'learning_rate': 2.0310542566425396e-07, 'epoch': 0.94}
{'loss': 0.7277, 'learning_rate': 2.0154655279313927e-07, 'epoch': 0.94}
[2025-12-10 03:26:08,092] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step19500 is about to be saved!
[2025-12-10 03:26:08,184] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19500/global_step19500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-10 03:26:08,185] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19500/global_step19500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-10 03:26:08,776] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19500/global_step19500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-10 03:26:08,785] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19500/global_step19500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-10 03:26:47,003] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19500/global_step19500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-10 03:26:47,006] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-19500/global_step19500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-10 03:26:52,195] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step19500 is ready now!
{'loss': 0.7388, 'learning_rate': 1.9999362441296077e-07, 'epoch': 0.94}
{'loss': 0.7147, 'learning_rate': 1.9844664146584258e-07, 'epoch': 0.94}
{'loss': 0.6992, 'learning_rate': 1.9690560489030285e-07, 'epoch': 0.94}
{'loss': 0.7273, 'learning_rate': 1.9537051562125152e-07, 'epoch': 0.94}
{'loss': 0.813, 'learning_rate': 1.9384137458999252e-07, 'epoch': 0.94}
{'loss': 0.6698, 'learning_rate': 1.923181827242182e-07, 'epoch': 0.94}
{'loss': 0.7406, 'learning_rate': 1.9080094094801493e-07, 'epoch': 0.94}
{'loss': 0.7753, 'learning_rate': 1.892896501818553e-07, 'epoch': 0.94}
{'loss': 0.7459, 'learning_rate': 1.8778431134260476e-07, 'epoch': 0.94}
{'loss': 0.7466, 'learning_rate': 1.862849253435184e-07, 'epoch': 0.94}
{'loss': 0.6886, 'learning_rate': 1.8479149309423627e-07, 'epoch': 0.94}
{'loss': 0.7412, 'learning_rate': 1.8330401550078924e-07, 'epoch': 0.94}
{'loss': 0.7343, 'learning_rate': 1.8182249346559655e-07, 'epoch': 0.94}
{'loss': 0.8028, 'learning_rate': 1.8034692788746034e-07, 'epoch': 0.94}
{'loss': 0.7386, 'learning_rate': 1.788773196615723e-07, 'epoch': 0.94}
{'loss': 0.7135, 'learning_rate': 1.7741366967950923e-07, 'epoch': 0.94}
{'loss': 0.7809, 'learning_rate': 1.759559788292331e-07, 'epoch': 0.94}
{'loss': 0.7825, 'learning_rate': 1.7450424799509093e-07, 'epoch': 0.94}
{'loss': 0.8339, 'learning_rate': 1.7305847805781373e-07, 'epoch': 0.94}
{'loss': 0.7209, 'learning_rate': 1.7161866989451548e-07, 'epoch': 0.94}
{'loss': 0.771, 'learning_rate': 1.701848243786941e-07, 'epoch': 0.94}
{'loss': 0.7927, 'learning_rate': 1.6875694238023042e-07, 'epoch': 0.94}
{'loss': 0.7722, 'learning_rate': 1.673350247653849e-07, 'epoch': 0.94}
{'loss': 0.5982, 'learning_rate': 1.6591907239680406e-07, 'epoch': 0.94}
{'loss': 0.8123, 'learning_rate': 1.645090861335119e-07, 'epoch': 0.94}
{'loss': 0.8136, 'learning_rate': 1.631050668309131e-07, 'epoch': 0.94}
{'loss': 0.8604, 'learning_rate': 1.6170701534079291e-07, 'epoch': 0.94}
{'loss': 0.8051, 'learning_rate': 1.6031493251131846e-07, 'epoch': 0.94}
{'loss': 0.7837, 'learning_rate': 1.5892881918703195e-07, 'epoch': 0.94}
{'loss': 0.7388, 'learning_rate': 1.5754867620885516e-07, 'epoch': 0.95}
{'loss': 0.7101, 'learning_rate': 1.5617450441408943e-07, 'epoch': 0.95}
{'loss': 0.7381, 'learning_rate': 1.5480630463641234e-07, 'epoch': 0.95}
{'loss': 0.78, 'learning_rate': 1.5344407770587765e-07, 'epoch': 0.95}
{'loss': 0.8164, 'learning_rate': 1.5208782444891656e-07, 'epoch': 0.95}
{'loss': 0.716, 'learning_rate': 1.5073754568833643e-07, 'epoch': 0.95}
{'loss': 0.7975, 'learning_rate': 1.4939324224331974e-07, 'epoch': 0.95}
{'loss': 0.728, 'learning_rate': 1.4805491492942415e-07, 'epoch': 0.95}
{'loss': 0.7217, 'learning_rate': 1.4672256455857902e-07, 'epoch': 0.95}
{'loss': 0.7579, 'learning_rate': 1.4539619193909338e-07, 'epoch': 0.95}
{'loss': 0.8267, 'learning_rate': 1.4407579787564353e-07, 'epoch': 0.95}
{'loss': 0.7681, 'learning_rate': 1.42761383169282e-07, 'epoch': 0.95}
{'loss': 0.7783, 'learning_rate': 1.414529486174332e-07, 'epoch': 0.95}
{'loss': 0.807, 'learning_rate': 1.4015049501389543e-07, 'epoch': 0.95}
{'loss': 0.7332, 'learning_rate': 1.3885402314883445e-07, 'epoch': 0.95}
{'loss': 0.787, 'learning_rate': 1.3756353380878994e-07, 'epoch': 0.95}
{'loss': 0.7419, 'learning_rate': 1.3627902777667123e-07, 'epoch': 0.95}
{'loss': 0.79, 'learning_rate': 1.3500050583175828e-07, 'epoch': 0.95}
{'loss': 0.7445, 'learning_rate': 1.337279687496995e-07, 'epoch': 0.95}
{'loss': 0.7936, 'learning_rate': 1.3246141730251293e-07, 'epoch': 0.95}
{'loss': 0.7254, 'learning_rate': 1.3120085225858614e-07, 'epoch': 0.95}
{'loss': 0.7807, 'learning_rate': 1.2994627438267514e-07, 'epoch': 0.95}
{'loss': 0.7129, 'learning_rate': 1.2869768443590224e-07, 'epoch': 0.95}
{'loss': 0.7919, 'learning_rate': 1.2745508317575704e-07, 'epoch': 0.95}
{'loss': 0.7549, 'learning_rate': 1.2621847135609656e-07, 'epoch': 0.95}
{'loss': 0.7823, 'learning_rate': 1.2498784972714395e-07, 'epoch': 0.95}
{'loss': 0.7553, 'learning_rate': 1.2376321903548872e-07, 'epoch': 0.95}
{'loss': 0.7489, 'learning_rate': 1.2254458002408544e-07, 'epoch': 0.95}
{'loss': 0.7465, 'learning_rate': 1.213319334322538e-07, 'epoch': 0.95}
{'loss': 0.7291, 'learning_rate': 1.2012527999567757e-07, 'epoch': 0.95}
{'loss': 0.7422, 'learning_rate': 1.1892462044640452e-07, 'epoch': 0.95}
{'loss': 0.7405, 'learning_rate': 1.177299555128475e-07, 'epoch': 0.95}
{'loss': 0.7923, 'learning_rate': 1.165412859197812e-07, 'epoch': 0.95}
{'loss': 0.6411, 'learning_rate': 1.1535861238834433e-07, 'epoch': 0.95}
{'loss': 0.7753, 'learning_rate': 1.1418193563603519e-07, 'epoch': 0.95}
{'loss': 0.7849, 'learning_rate': 1.1301125637671717e-07, 'epoch': 0.95}
{'loss': 0.7925, 'learning_rate': 1.1184657532061328e-07, 'epoch': 0.95}
{'loss': 0.6724, 'learning_rate': 1.1068789317430828e-07, 'epoch': 0.95}
{'loss': 0.7651, 'learning_rate': 1.0953521064074768e-07, 'epoch': 0.95}
{'loss': 0.6789, 'learning_rate': 1.0838852841923541e-07, 'epoch': 0.95}
{'loss': 0.7756, 'learning_rate': 1.0724784720543946e-07, 'epoch': 0.95}
{'loss': 0.7466, 'learning_rate': 1.061131676913818e-07, 'epoch': 0.95}
{'loss': 0.7944, 'learning_rate': 1.0498449056544624e-07, 'epoch': 0.96}
{'loss': 0.7055, 'learning_rate': 1.0386181651237504e-07, 'epoch': 0.96}
{'loss': 0.7548, 'learning_rate': 1.027451462132678e-07, 'epoch': 0.96}
{'loss': 0.684, 'learning_rate': 1.0163448034558266e-07, 'epoch': 0.96}
{'loss': 0.7692, 'learning_rate': 1.005298195831328e-07, 'epoch': 0.96}
{'loss': 0.6945, 'learning_rate': 9.943116459609214e-08, 'epoch': 0.96}
{'loss': 0.7289, 'learning_rate': 9.833851605098754e-08, 'epoch': 0.96}
{'loss': 0.8219, 'learning_rate': 9.725187461070207e-08, 'epoch': 0.96}
{'loss': 0.7928, 'learning_rate': 9.617124093447838e-08, 'epoch': 0.96}
{'loss': 0.6329, 'learning_rate': 9.509661567790874e-08, 'epoch': 0.96}
{'loss': 0.7561, 'learning_rate': 9.402799949294494e-08, 'epoch': 0.96}
{'loss': 0.7526, 'learning_rate': 9.296539302788953e-08, 'epoch': 0.96}
{'loss': 0.7849, 'learning_rate': 9.190879692740129e-08, 'epoch': 0.96}
{'loss': 0.6617, 'learning_rate': 9.08582118324941e-08, 'epoch': 0.96}
{'loss': 0.6982, 'learning_rate': 8.981363838053037e-08, 'epoch': 0.96}
{'loss': 0.7623, 'learning_rate': 8.877507720522982e-08, 'epoch': 0.96}
{'loss': 0.8142, 'learning_rate': 8.77425289366629e-08, 'epoch': 0.96}
{'loss': 0.7207, 'learning_rate': 8.671599420125188e-08, 'epoch': 0.96}
{'loss': 0.7367, 'learning_rate': 8.569547362177189e-08, 'epoch': 0.96}
{'loss': 0.8, 'learning_rate': 8.468096781734769e-08, 'epoch': 0.96}
{'loss': 0.8219, 'learning_rate': 8.367247740345808e-08, 'epoch': 0.96}
{'loss': 0.7772, 'learning_rate': 8.267000299192806e-08, 'epoch': 0.96}
{'loss': 0.7688, 'learning_rate': 8.167354519093562e-08, 'epoch': 0.96}
{'loss': 0.7318, 'learning_rate': 8.068310460500939e-08, 'epoch': 0.96}
{'loss': 0.7318, 'learning_rate': 7.969868183502649e-08, 'epoch': 0.96}
{'loss': 0.678, 'learning_rate': 7.872027747821142e-08, 'epoch': 0.96}
{'loss': 0.7152, 'learning_rate': 7.774789212814049e-08, 'epoch': 0.96}
{'loss': 0.8064, 'learning_rate': 7.678152637473624e-08, 'epoch': 0.96}
{'loss': 0.7216, 'learning_rate': 7.582118080427081e-08, 'epoch': 0.96}
[2025-12-10 03:51:38,654] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step20000 is about to be saved!
[2025-12-10 03:51:38,745] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20000/global_step20000/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-10 03:51:38,746] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20000/global_step20000/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-10 03:51:39,335] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20000/global_step20000/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-10 03:51:39,346] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20000/global_step20000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-10 03:52:12,597] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20000/global_step20000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-10 03:52:12,599] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20000/global_step20000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-10 03:52:25,111] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step20000 is ready now!
{'loss': 0.7792, 'learning_rate': 7.48668559993615e-08, 'epoch': 0.96}
{'loss': 0.7555, 'learning_rate': 7.391855253897739e-08, 'epoch': 0.96}
{'loss': 0.8051, 'learning_rate': 7.297627099842941e-08, 'epoch': 0.96}
{'loss': 0.7653, 'learning_rate': 7.204001194937915e-08, 'epoch': 0.96}
{'loss': 0.8083, 'learning_rate': 7.110977595983226e-08, 'epoch': 0.96}
{'loss': 0.7593, 'learning_rate': 7.018556359413953e-08, 'epoch': 0.96}
{'loss': 0.7098, 'learning_rate': 6.926737541300243e-08, 'epoch': 0.96}
{'loss': 0.6378, 'learning_rate': 6.835521197346096e-08, 'epoch': 0.96}
{'loss': 0.7066, 'learning_rate': 6.744907382890464e-08, 'epoch': 0.96}
{'loss': 0.7212, 'learning_rate': 6.654896152906487e-08, 'epoch': 0.96}
{'loss': 0.7946, 'learning_rate': 6.565487562002037e-08, 'epoch': 0.96}
{'loss': 0.7096, 'learning_rate': 6.476681664419171e-08, 'epoch': 0.96}
{'loss': 0.8283, 'learning_rate': 6.388478514034124e-08, 'epoch': 0.97}
{'loss': 0.792, 'learning_rate': 6.300878164357871e-08, 'epoch': 0.97}
{'loss': 0.7308, 'learning_rate': 6.213880668535455e-08, 'epoch': 0.97}
{'loss': 0.837, 'learning_rate': 6.127486079346212e-08, 'epoch': 0.97}
{'loss': 0.6586, 'learning_rate': 6.041694449203661e-08, 'epoch': 0.97}
{'loss': 0.8218, 'learning_rate': 5.9565058301555015e-08, 'epoch': 0.97}
{'loss': 0.7336, 'learning_rate': 5.8719202738838355e-08, 'epoch': 0.97}
{'loss': 0.7914, 'learning_rate': 5.787937831704615e-08, 'epoch': 0.97}
{'loss': 0.6899, 'learning_rate': 5.704558554567974e-08, 'epoch': 0.97}
{'loss': 0.7513, 'learning_rate': 5.6217824930582257e-08, 'epoch': 0.97}
{'loss': 0.7816, 'learning_rate': 5.5396096973937554e-08, 'epoch': 0.97}
{'loss': 0.7037, 'learning_rate': 5.458040217426686e-08, 'epoch': 0.97}
{'loss': 0.7451, 'learning_rate': 5.377074102643209e-08, 'epoch': 0.97}
{'loss': 0.7587, 'learning_rate': 5.2967114021639234e-08, 'epoch': 0.97}
{'loss': 0.7058, 'learning_rate': 5.216952164742717e-08, 'epoch': 0.97}
{'loss': 0.6761, 'learning_rate': 5.137796438767662e-08, 'epoch': 0.97}
{'loss': 0.6148, 'learning_rate': 5.0592442722606775e-08, 'epoch': 0.97}
{'loss': 0.7849, 'learning_rate': 4.981295712877643e-08, 'epoch': 0.97}
{'loss': 0.7522, 'learning_rate': 4.9039508079079535e-08, 'epoch': 0.97}
{'loss': 0.7581, 'learning_rate': 4.827209604274963e-08, 'epoch': 0.97}
{'loss': 0.7713, 'learning_rate': 4.7510721485358734e-08, 'epoch': 0.97}
{'loss': 0.8247, 'learning_rate': 4.6755384868812925e-08, 'epoch': 0.97}
{'loss': 0.7369, 'learning_rate': 4.600608665136008e-08, 'epoch': 0.97}
{'loss': 0.808, 'learning_rate': 4.5262827287578804e-08, 'epoch': 0.97}
{'loss': 0.7687, 'learning_rate': 4.452560722838839e-08, 'epoch': 0.97}
{'loss': 0.7669, 'learning_rate': 4.3794426921042185e-08, 'epoch': 0.97}
{'loss': 0.6937, 'learning_rate': 4.3069286809132026e-08, 'epoch': 0.97}
{'loss': 0.8066, 'learning_rate': 4.235018733258045e-08, 'epoch': 0.97}
{'loss': 0.6137, 'learning_rate': 4.16371289276507e-08, 'epoch': 0.97}
{'loss': 0.7581, 'learning_rate': 4.093011202693675e-08, 'epoch': 0.97}
{'loss': 0.7639, 'learning_rate': 4.0229137059369925e-08, 'epoch': 0.97}
{'loss': 0.7443, 'learning_rate': 3.953420445021561e-08, 'epoch': 0.97}
{'loss': 0.7597, 'learning_rate': 3.884531462107211e-08, 'epoch': 0.97}
{'loss': 0.708, 'learning_rate': 3.8162467989872885e-08, 'epoch': 0.97}
{'loss': 0.7875, 'learning_rate': 3.748566497088546e-08, 'epoch': 0.97}
{'loss': 0.7825, 'learning_rate': 3.681490597471027e-08, 'epoch': 0.97}
{'loss': 0.7596, 'learning_rate': 3.6150191408279576e-08, 'epoch': 0.97}
{'loss': 0.7225, 'learning_rate': 3.5491521674861914e-08, 'epoch': 0.97}
{'loss': 0.7378, 'learning_rate': 3.483889717405542e-08, 'epoch': 0.97}
{'loss': 0.7348, 'learning_rate': 3.419231830179337e-08, 'epoch': 0.97}
{'loss': 0.7324, 'learning_rate': 3.355178545033866e-08, 'epoch': 0.97}
{'loss': 0.7876, 'learning_rate': 3.291729900828822e-08, 'epoch': 0.97}
{'loss': 0.8233, 'learning_rate': 3.228885936056858e-08, 'epoch': 0.98}
{'loss': 0.7687, 'learning_rate': 3.166646688844144e-08, 'epoch': 0.98}
{'loss': 0.76, 'learning_rate': 3.105012196949697e-08, 'epoch': 0.98}
{'loss': 0.7715, 'learning_rate': 3.043982497765607e-08, 'epoch': 0.98}
{'loss': 0.6529, 'learning_rate': 2.983557628317257e-08, 'epoch': 0.98}
{'loss': 0.6276, 'learning_rate': 2.923737625262879e-08, 'epoch': 0.98}
{'loss': 0.6717, 'learning_rate': 2.8645225248939977e-08, 'epoch': 0.98}
{'loss': 0.7005, 'learning_rate': 2.8059123631349884e-08, 'epoch': 0.98}
{'loss': 0.817, 'learning_rate': 2.7479071755431853e-08, 'epoch': 0.98}
{'loss': 0.8295, 'learning_rate': 2.6905069973091058e-08, 'epoch': 0.98}
{'loss': 0.7703, 'learning_rate': 2.6337118632558945e-08, 'epoch': 0.98}
{'loss': 0.7595, 'learning_rate': 2.5775218078399888e-08, 'epoch': 0.98}
{'loss': 0.7823, 'learning_rate': 2.5219368651504537e-08, 'epoch': 0.98}
{'loss': 0.8179, 'learning_rate': 2.4669570689094258e-08, 'epoch': 0.98}
{'loss': 0.7007, 'learning_rate': 2.41258245247189e-08, 'epoch': 0.98}
{'loss': 0.739, 'learning_rate': 2.35881304882557e-08, 'epoch': 0.98}
{'loss': 0.7893, 'learning_rate': 2.30564889059115e-08, 'epoch': 0.98}
{'loss': 0.7794, 'learning_rate': 2.253090010022052e-08, 'epoch': 0.98}
{'loss': 0.7139, 'learning_rate': 2.2011364390044367e-08, 'epoch': 0.98}
{'loss': 0.7186, 'learning_rate': 2.149788209057424e-08, 'epoch': 0.98}
{'loss': 0.7753, 'learning_rate': 2.0990453513327625e-08, 'epoch': 0.98}
{'loss': 0.8201, 'learning_rate': 2.0489078966149378e-08, 'epoch': 0.98}
{'loss': 0.6996, 'learning_rate': 1.9993758753211746e-08, 'epoch': 0.98}
{'loss': 0.6676, 'learning_rate': 1.950449317501213e-08, 'epoch': 0.98}
{'loss': 0.7997, 'learning_rate': 1.902128252837865e-08, 'epoch': 0.98}
{'loss': 0.7712, 'learning_rate': 1.8544127106463473e-08, 'epoch': 0.98}
{'loss': 0.7433, 'learning_rate': 1.8073027198745042e-08, 'epoch': 0.98}
{'loss': 0.7722, 'learning_rate': 1.760798309102807e-08, 'epoch': 0.98}
{'loss': 0.6773, 'learning_rate': 1.7148995065444653e-08, 'epoch': 0.98}
{'loss': 0.8688, 'learning_rate': 1.6696063400450936e-08, 'epoch': 0.98}
{'loss': 0.7304, 'learning_rate': 1.6249188370832668e-08, 'epoch': 0.98}
{'loss': 0.7646, 'learning_rate': 1.5808370247695215e-08, 'epoch': 0.98}
{'loss': 0.6361, 'learning_rate': 1.5373609298473536e-08, 'epoch': 0.98}
{'loss': 0.7937, 'learning_rate': 1.4944905786927756e-08, 'epoch': 0.98}
{'loss': 0.7857, 'learning_rate': 1.452225997314205e-08, 'epoch': 0.98}
{'loss': 0.7837, 'learning_rate': 1.4105672113524648e-08, 'epoch': 0.98}
{'loss': 0.7317, 'learning_rate': 1.369514246081005e-08, 'epoch': 0.98}
{'loss': 0.7093, 'learning_rate': 1.329067126405792e-08, 'epoch': 0.98}
{'loss': 0.7685, 'learning_rate': 1.2892258768649746e-08, 'epoch': 0.98}
{'loss': 0.7404, 'learning_rate': 1.2499905216293295e-08, 'epoch': 0.98}
{'loss': 0.8352, 'learning_rate': 1.2113610845021495e-08, 'epoch': 0.98}
{'loss': 0.7186, 'learning_rate': 1.1733375889189102e-08, 'epoch': 0.99}
{'loss': 0.7568, 'learning_rate': 1.1359200579476038e-08, 'epoch': 0.99}
{'loss': 0.7774, 'learning_rate': 1.099108514288627e-08, 'epoch': 0.99}
{'loss': 0.6894, 'learning_rate': 1.0629029802744494e-08, 'epoch': 0.99}
{'loss': 0.751, 'learning_rate': 1.0273034778703894e-08, 'epoch': 0.99}
[2025-12-10 04:17:07,125] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step20500 is about to be saved!
[2025-12-10 04:17:07,610] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20500/global_step20500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2025-12-10 04:17:07,611] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20500/global_step20500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2025-12-10 04:17:07,761] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20500/global_step20500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2025-12-10 04:17:07,763] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20500/global_step20500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-12-10 04:17:45,913] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20500/global_step20500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-12-10 04:17:45,916] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /leonardo_scratch/large/userexternal/fgaragna/checkpoints/llava-v/llava-v_s2--last/tmp-checkpoint-20500/global_step20500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-12-10 04:17:46,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step20500 is ready now!
{'loss': 0.6264, 'learning_rate': 9.923100286736153e-09, 'epoch': 0.99}
{'loss': 0.7129, 'learning_rate': 9.57922653913923e-09, 'epoch': 0.99}
{'loss': 0.6665, 'learning_rate': 9.241413744532912e-09, 'epoch': 0.99}
{'loss': 0.7754, 'learning_rate': 8.90966210786215e-09, 'epoch': 0.99}
{'loss': 0.6803, 'learning_rate': 8.583971830389281e-09, 'epoch': 0.99}
{'loss': 0.7806, 'learning_rate': 8.264343109706252e-09, 'epoch': 0.99}
{'loss': 0.742, 'learning_rate': 7.950776139722394e-09, 'epoch': 0.99}
{'loss': 0.6644, 'learning_rate': 7.643271110671091e-09, 'epoch': 0.99}
{'loss': 0.8144, 'learning_rate': 7.34182820910978e-09, 'epoch': 0.99}
{'loss': 0.7502, 'learning_rate': 7.046447617916618e-09, 'epoch': 0.99}
{'loss': 0.7661, 'learning_rate': 6.757129516291594e-09, 'epoch': 0.99}
{'loss': 0.7592, 'learning_rate': 6.473874079756526e-09, 'epoch': 0.99}
{'loss': 0.8018, 'learning_rate': 6.196681480157285e-09, 'epoch': 0.99}
{'loss': 0.757, 'learning_rate': 5.925551885659353e-09, 'epoch': 0.99}
{'loss': 0.7239, 'learning_rate': 5.6604854607500425e-09, 'epoch': 0.99}
{'loss': 0.8094, 'learning_rate': 5.4014823662396074e-09, 'epoch': 0.99}
{'loss': 0.7325, 'learning_rate': 5.148542759259023e-09, 'epoch': 0.99}
{'loss': 0.7522, 'learning_rate': 4.901666793261095e-09, 'epoch': 0.99}
{'loss': 0.7679, 'learning_rate': 4.660854618019351e-09, 'epoch': 0.99}
{'loss': 0.7006, 'learning_rate': 4.4261063796280365e-09, 'epoch': 0.99}
{'loss': 0.7851, 'learning_rate': 4.197422220505453e-09, 'epoch': 0.99}
{'loss': 0.8182, 'learning_rate': 3.974802279386181e-09, 'epoch': 0.99}
{'loss': 0.7456, 'learning_rate': 3.758246691331069e-09, 'epoch': 0.99}
{'loss': 0.7517, 'learning_rate': 3.54775558771836e-09, 'epoch': 0.99}
{'loss': 0.7802, 'learning_rate': 3.3433290962470166e-09, 'epoch': 0.99}
{'loss': 0.6891, 'learning_rate': 3.1449673409389425e-09, 'epoch': 0.99}
{'loss': 0.7507, 'learning_rate': 2.9526704421356523e-09, 'epoch': 0.99}
{'loss': 0.7734, 'learning_rate': 2.766438516498271e-09, 'epoch': 0.99}
{'loss': 0.8207, 'learning_rate': 2.5862716770108654e-09, 'epoch': 0.99}
{'loss': 0.6131, 'learning_rate': 2.412170032973782e-09, 'epoch': 0.99}
{'loss': 0.8348, 'learning_rate': 2.2441336900125288e-09, 'epoch': 0.99}
{'loss': 0.7559, 'learning_rate': 2.082162750071115e-09, 'epoch': 0.99}
{'loss': 0.793, 'learning_rate': 1.9262573114109395e-09, 'epoch': 0.99}
{'loss': 0.6849, 'learning_rate': 1.7764174686185631e-09, 'epoch': 0.99}
{'loss': 0.8002, 'learning_rate': 1.6326433125979368e-09, 'epoch': 0.99}
{'loss': 0.8093, 'learning_rate': 1.4949349305726224e-09, 'epoch': 0.99}
{'loss': 0.7397, 'learning_rate': 1.3632924060880126e-09, 'epoch': 0.99}
{'loss': 0.7593, 'learning_rate': 1.2377158190068906e-09, 'epoch': 1.0}
{'loss': 0.7544, 'learning_rate': 1.1182052455160908e-09, 'epoch': 1.0}
{'loss': 0.8084, 'learning_rate': 1.0047607581176178e-09, 'epoch': 1.0}
{'loss': 0.7543, 'learning_rate': 8.973824256364172e-10, 'epoch': 1.0}
{'loss': 0.7902, 'learning_rate': 7.960703132170456e-10, 'epoch': 1.0}
{'loss': 0.6646, 'learning_rate': 7.008244823214494e-10, 'epoch': 1.0}
{'loss': 0.6214, 'learning_rate': 6.11644990735627e-10, 'epoch': 1.0}
{'loss': 0.7525, 'learning_rate': 5.285318925596361e-10, 'epoch': 1.0}
{'loss': 0.8453, 'learning_rate': 4.514852382186963e-10, 'epoch': 1.0}
{'loss': 0.7349, 'learning_rate': 3.805050744543071e-10, 'epoch': 1.0}
{'loss': 0.6607, 'learning_rate': 3.1559144432868893e-10, 'epoch': 1.0}
{'loss': 0.7574, 'learning_rate': 2.567443872225628e-10, 'epoch': 1.0}
{'loss': 0.7332, 'learning_rate': 2.0396393883737042e-10, 'epoch': 1.0}
{'loss': 0.8002, 'learning_rate': 1.5725013119416432e-10, 'epoch': 1.0}
{'loss': 0.751, 'learning_rate': 1.1660299263360764e-10, 'epoch': 1.0}
{'loss': 0.7409, 'learning_rate': 8.202254781486397e-11, 'epoch': 1.0}
{'loss': 0.7534, 'learning_rate': 5.350881771670757e-11, 'epoch': 1.0}
{'loss': 0.788, 'learning_rate': 3.106181963752342e-11, 'epoch': 1.0}
{'loss': 0.7721, 'learning_rate': 1.4681567196417333e-11, 'epoch': 1.0}
{'loss': 0.8335, 'learning_rate': 4.368070329885399e-12, 'epoch': 1.0}
{'loss': 0.8044, 'learning_rate': 1.2133529514457565e-13, 'epoch': 1.0}
{'train_runtime': 66951.2592, 'train_samples_per_second': 9.937, 'train_steps_per_second': 0.311, 'train_loss': 0.8200914050632441, 'epoch': 1.0}
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/fgaragna/llava/wandb/offline-run-20251209_095607-4cj16gvb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20251209_095607-4cj16gvb/logs[0m
